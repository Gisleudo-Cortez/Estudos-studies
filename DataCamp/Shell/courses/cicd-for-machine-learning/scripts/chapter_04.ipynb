{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nero/Documents/Estudos/DataCamp'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Adding metrics and plots to dvc.yaml\n",
    "\n",
    "In this exercise, your task is to complete the contents of dvc.yaml that defines a model training workflow.\n",
    "\n",
    "Here preprocess_dataset.py and train.py are the files that perform data preprocessing and model training by taking weather.csv as input in the raw_dataset folder. As output, the model training code generates a predictions.csv file that contains the predictions and the ground truth, and metrics.json file containing structured metrics data. The former would be used to generate a normalized confusion matrix plot for comparing it with previous commits.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Set the metrics target to the output metrics file.\n",
    "\n",
    "    Set the plot target to the output file containing predictions data.\n",
    "\n",
    "    Set the plot template to confusion_normalized to plot the normalized confusion matrix.\n",
    "\n",
    "    Set the correct value for cache key to track plots in Git repository instead of DVC remote.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "stages:\n",
    "  preprocess:\n",
    "    cmd: python3 preprocess_dataset.py\n",
    "    deps:\n",
    "    - preprocess_dataset.py\n",
    "    - raw_dataset/weather.csv\n",
    "    - utils_and_constants.py\n",
    "    outs:\n",
    "    - processed_dataset/weather.csv\n",
    "  train:\n",
    "    cmd: python3 train.py\n",
    "    deps:\n",
    "    - metrics_and_plots.py\n",
    "    - model.py\n",
    "    - processed_dataset/weather.csv\n",
    "    - train.py\n",
    "    - utils_and_constants.py\n",
    "    metrics:\n",
    "      # Specify the metrics file as target\n",
    "      - metrics.json:\n",
    "          cache: false\n",
    "    plots:\n",
    "      # Set the target to the file containing predictions data\n",
    "      - predictions.csv:\n",
    "          # Write the plot template\n",
    "          template: confusion_normalized\n",
    "          x: predicted_label\n",
    "          y: true_label\n",
    "          x_label: 'Predicted label'\n",
    "          y_label: 'True label'\n",
    "          title: Confusion matrix\n",
    "          # Set the cache parameter to store\n",
    "          # plot data in git repository\n",
    "          cache: false\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice! A normalized confusion matrix would display the relative proportion of true positives, false positives, etc., instead of the raw numbers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Comparing metrics across Git branches\n",
    "\n",
    "In this exercise, you will use DVC for querying and comparing metrics across different branches. This functionality of DVC is helpful in making decisions about the quality of a machine learning model.\n",
    "\n",
    "You will start in the main branch, where a DVC pipeline has already been executed and results committed in Git. Your task would entail querying metrics in the main branch. Then, you'll switch to a new training branch, change a hyperparameter, and execute the pipeline again, followed by comparing metrics with the main branch.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Query the metrics in the main branch by running dvc metrics show command in the terminal.\n",
    "\n",
    "    Checkout a new branch named train.\n",
    "\n",
    "    Change RFC_FOREST_DEPTH to 4 in the opened utils_and_constants.py file, and execute the DVC pipeline.\n",
    "\n",
    "    Compare the changed metrics with the main branch using dvc metrics diff main --md | tee metrics_diff.md command.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "dvc metrics show\n",
    "\n",
    "git checkout -b train\n",
    "\n",
    "dvc metrics show\n",
    "\n",
    "dvc repro\n",
    "\n",
    "dvc metrics diff main --md | tee metrics_diff.md\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! You can also compare metrics against previous Git commit by providing the SHA id of the commit in place of the branch name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Run DVC pipeline in GitHub Actions\n",
    "\n",
    "In this exercise, you will use CML GitHub Action to run a DVC pipeline and compare metrics between the training branch and main. The pipeline will trigger when you open a PR against the main branch.\n",
    "\n",
    "The output from running train.py is a metrics.json file containing model metrics that will provide the source data for comparing metrics across branches.\n",
    "\n",
    "Your task is to finish the scaffolded .github/workflows/dvc_cml.yaml to formulate a high-level model training flow. Scroll down to Line 24 to make changes. \n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Setup DVC GitHub Action iterative/setup-dvc@v1.\n",
    "\n",
    "    Run DVC pipeline in Run DVC pipeline step.\n",
    "\n",
    "    Compare metrics with main branch and write the markdown report in the Write CML report step.\n",
    "\n",
    "    Write the correct file in cml comment create command to create a comment in the PR.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "name: dvc-pipeline\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: main\n",
    "\n",
    "permissions: write-all\n",
    "\n",
    "jobs:\n",
    "  train_and_report_eval_performance:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - name: Checkout \n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: 3.9\n",
    "\n",
    "      - name: Setup CML\n",
    "        uses: iterative/setup-cml@v1\n",
    "          \n",
    "      # Setup DVC GitHub Action\n",
    "      - name: Setup DVC\n",
    "        uses: iterative/setup-dvc@v1\n",
    "          \n",
    "      # Run DVC pipeline\n",
    "      - name: Run DVC pipeline\n",
    "        run: dvc repro\n",
    "\n",
    "      - name: Write CML report\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          # Compare metrics with main branch\n",
    "          git fetch --prune\n",
    "          dvc metrics diff --md main >> metrics_compare.md\n",
    "          \n",
    "          # Create comment from markdown report\n",
    "          cml comment create metrics_compare.md\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Excellent work! Using CML and DVC in conjunction with each other results in a very concise workflow.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Adding Hyperparameter tuning to dvc.yaml\n",
    "\n",
    "In this exercise, your task is to define a hyperparameter tuning workflow. The python file hp_tuning.py is the script for hyperparameter training and takes the hyperparameter configuration file hp_config.json as an input to produce rfc_best_params.json as an output.\n",
    "\n",
    "The dvc.yaml file outlines the DVC workflow orchestrating the hyperparameter tuning and lists commands, dependencies, and outputs.\n",
    "\n",
    "NOTE: This exercise involves changing both hp_tuning.py and dvc.yaml. Both files have been opened for you in the editor.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Set the hyperparameter tuning command running the python script hp_tuning.py in dvc.yaml.\n",
    "\n",
    "    Specify the hyperparameter configuration hp_config.json in dvc.yaml, and in hp_tuning.py.\n",
    "\n",
    "    Specify the hyperparameter training file hp_tuning.py in dvc.yaml as a dependency.\n",
    "\n",
    "    Perform Grid Search Cross Validation on training data in hp_tuning.py.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# dvc.yaml\n",
    "\n",
    "stages:\n",
    "  preprocess:\n",
    "    cmd: python3 preprocess_dataset.py\n",
    "    deps:\n",
    "    - preprocess_dataset.py\n",
    "    - raw_dataset/weather.csv\n",
    "    - utils_and_constants.py\n",
    "    outs:\n",
    "    - processed_dataset/weather.csv\n",
    "  hp_tune:\n",
    "    # Set the hyperparameter tuning command\n",
    "    cmd: python3 hp_tuning.py\n",
    "    deps:\n",
    "    - processed_dataset/weather.csv\n",
    "    # Specify the hyperparameter configuration as dependency\n",
    "    - hp_config.json\n",
    "    # Specify the hyperparameter script as dependency\n",
    "    - hp_tuning.py\n",
    "    - utils_and_constants.py\n",
    "    outs:\n",
    "      - hp_tuning_results.md:\n",
    "          cache: false\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# hp_tuning.py\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from utils_and_constants import PROCESSED_DATASET, get_hp_tuning_results, load_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = load_data(PROCESSED_DATASET)\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, random_state=1993)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    # Read the config file to define the hyperparameter search space\n",
    "    param_grid = json.load(open(\"hp_config.json\", \"r\"))\n",
    "\n",
    "    # Perform Grid Search Cross Validation on training data\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(\"====================Best Hyperparameters==================\")\n",
    "    print(json.dumps(best_params, indent=2))\n",
    "    print(\"==========================================================\")\n",
    "\n",
    "    with open(\"rfc_best_params.json\", \"w\") as outfile:\n",
    "        json.dump(best_params, outfile)\n",
    "\n",
    "    markdown_table = get_hp_tuning_results(grid_search)\n",
    "    with open(\"hp_tuning_results.md\", \"w\") as markdown_file:\n",
    "        markdown_file.write(markdown_table)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work! Not tracking the output requires us to force run the DVC pipeline to ensure outputs are always up to date.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Running Hyperparameter tuning DVC pipelines\n",
    "\n",
    "In this exercise, you will run the hyperparameter training and model training targets outlined in the dvc.yaml pipeline. The dvc.yaml file outlines the DVC workflow orchestrating the jobs and lists commands, dependencies, and outputs.\n",
    "\n",
    "You will experiment with running these pipelines independently and observe the interaction between the two via the best parameter configuration file rfc_best_params.json.\n",
    "\n",
    "In your design, this file is meant to be edited manually for training jobs or, alternatively, as an output of a hyperparameter tuning job.\n",
    "\n",
    "The dvc.yaml file outlines the DVC workflow orchestrating the hyperparameter tuning and listings commands, dependencies, and outputs.\n",
    "\n",
    "NOTE: You will start working on the main branch. Git and DVC are already initialized for you. \n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Run DVC training pipeline (target name train) and observe changes in metrics.json (values should be populated).\n",
    "\n",
    "    Commit changes with git add . && git commit -m \"train on main\".\n",
    "\n",
    "    Checkout new branch git checkout -b hp_tune_and_train and force run DVC hyperparameter tuning pipeline (target name hp_tune); results file hp_tuning_results.md should now appear in file browser.\n",
    "\n",
    "    Run DVC training pipeline again, and compare metrics with main branch using DVC using dvc metrics diff command\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "dvc repro train\n",
    "\n",
    "git add . && git commit -m \"train on main\"\n",
    "\n",
    "git checkout -b hp_tune_and_train\n",
    "\n",
    "dvc repro -f hp_tune\n",
    "\n",
    "dvc repro train\n",
    "\n",
    "dvc metrics diff main\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work! Using DVC pipelines sets the stage for GitHub Actions integration, which you will learn next.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loose Coupling\n",
    "\n",
    "Why is loose coupling between the hyperparameter tuning job and training job useful in GitHub Actions DVC pipelines?\n",
    "\n",
    "### Possible Answers\n",
    "Select one answer\n",
    "\n",
    "    To ensure that hyperparameter tuning can only be triggered manually.\n",
    "    \n",
    "    \n",
    "    To maximize the performance of the machine learning model.\n",
    "    \n",
    "    \n",
    "    To allow model training to occur without searching for the best parameters. {Answer}\n",
    "    \n",
    "    \n",
    "    To minimize the impact of upstream dataset changes on both jobs.\n",
    "\n",
    "**Perfect! Inputs to the model training job can be provided in two ways, as an output of HP tuning job, or manually editing the best parameter configuration file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Setup Hyperparameter Tuning in GitHub Actions\n",
    "\n",
    "Imagine a repository with the structure shown in the editor. Your task is to finish the scaffolded .github/workflows/hp_cml.yaml to accomplish the hyperparameter tuning and open a new pull request from a new training branch to main that will run the training pipeline by reading best hyperparameters from rfc_best_params.json.\n",
    "\n",
    "By convention, hyperparameter tuning branches start with hp_tune/ and training branches start with train/. \n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Guard the hyperparameter tuning job so that it only gets triggered from the correct head branch prefix hp_tune/.\n",
    "\n",
    "    Write the correct cml subcommand to create a pull request.\n",
    "\n",
    "    Write the correct prefix for the new head (model training) branch and target branch (where code is merged) in the cml subcommand.\n",
    "\n",
    "    Write the JSON output file from the hyperparameter tuning job in the cml subcommand.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "name: hp-tuning\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: main\n",
    "\n",
    "permissions: write-all\n",
    "\n",
    "jobs:\n",
    "  hp_tune:\n",
    "    # Only run job if the current repository\n",
    "    # starts with the right prefix\n",
    "    if: startsWith(github.head_ref, 'hp_tune/')\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - name: Checkout \n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: 3.9\n",
    "\n",
    "      - name: Setup DVC\n",
    "        uses: iterative/setup-dvc@v1\n",
    "\n",
    "      - name: Setup CML\n",
    "        uses: iterative/setup-cml@v1\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Run DVC pipeline\n",
    "        run: |\n",
    "          dvc repro -f hp_tune\n",
    "      \n",
    "      - name: Create training branch\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          # Finish the create pull request command\n",
    "          cml pr create \\\n",
    "          --user-email hp-bot@cicd.ai \\\n",
    "          --user-name HPBot \\\n",
    "          --message \"HP tuning\" \\\n",
    "          # Write the new head branch name\n",
    "          --branch train/${{ github.sha }} \\\n",
    "          # Write the target branch name\n",
    "          --target-branch main \\\n",
    "          # Commit the hyperparameter job output file\n",
    "          rfc_best_params.json\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Excellent work! Recall that opening any pull request using GITHUB_TOKEN will not trigger any workflow. You'll need to amend the last commit and force push instead to trigger those manually.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
