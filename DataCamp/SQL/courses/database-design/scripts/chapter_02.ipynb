{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running from star to snowflake\n",
    "\n",
    "Remember your running database from last chapter?\n",
    "\n",
    "![ROUTE_DIM](/home/nero/Documents/Estudos/DataCamp/SQL/courses/database-design/dim_model.png)\n",
    "\n",
    "After learning about the snowflake schema, you convert the current star schema into a snowflake schema. To do this, you normalize route_dim and week_dim. Which option best describes the resulting new tables after doing this?\n",
    "\n",
    "The tables runs_fact, route_dim, and week_dim have been loaded.\n",
    "\n",
    "### Possible answers\n",
    "    \n",
    "    week_dim is extended two dimensions with new tables for month and year. route_dim is extended one dimension with a new table for city.\n",
    "    \n",
    "    week_dim is extended two dimensions with new tables for month and year. route_dim is extended two dimensions with new tables for city and park. {Answer}\n",
    "    \n",
    "    week_dim is extended three dimensions with new tables for week, month and year. route_dim is extended one dimension with new tables for city and park.\n",
    "\n",
    "**Nice! month, year, city, and park are indeed repeated often. year and city would extend month and park, respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ADD_KEYS](/home/nero/Documents/Estudos/DataCamp/SQL/courses/database-design/book-star.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nero/Documents/Estudos/DataCamp'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Adding foreign keys\n",
    "\n",
    "Foreign key references are essential to both the snowflake and star schema. When creating either of these schemas, correctly setting up the foreign keys is vital because they connect dimensions to the fact table. They also enforce a one-to-many relationship, because unless otherwise specified, a foreign key can appear more than once in a table and primary key can appear only once.\n",
    "\n",
    "The fact_booksales table has three foreign keys: book_id, time_id, and store_id. In this exercise, the four tables that make up the star schema below have been loaded. However, the foreign keys still need to be added. \n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    In the constraint called sales_book, set book_id as a foreign key.\n",
    "    In the constraint called sales_time, set time_id as a foreign key.\n",
    "    In the constraint called sales_store, set store_id as a foreign key.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Add the book_id foreign key\n",
    "ALTER TABLE fact_booksales ADD CONSTRAINT sales_book\n",
    "    FOREIGN KEY (book_id) REFERENCES dim_book_star (book_id);\n",
    "    \n",
    "-- Add the time_id foreign key\n",
    "ALTER TABLE fact_booksales ADD CONSTRAINT sales_time\n",
    "    FOREIGN KEY (time_id) REFERENCES dim_time_star (time_id);\n",
    "    \n",
    "-- Add the store_id foreign key\n",
    "ALTER TABLE fact_booksales ADD CONSTRAINT sales_store\n",
    "    FOREIGN KEY (store_id) REFERENCES dim_store_star (store_id);\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! The foreign keys have been added so now we can ensure data consistency whenever new data is inserted to the database.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BOOK_DIM](/home/nero/Documents/Estudos/DataCamp/SQL/courses/database-design/dim_book_sf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Extending the book dimension\n",
    "\n",
    "In the video, we saw how the book dimension differed between the star and snowflake schema. The star schema's dimension table for books, dim_book_star, has been loaded and below is the snowflake schema of the book dimension.\n",
    "\n",
    "In this exercise, you are going to extend the star schema to meet part of the snowflake schema's criteria. Specifically, you will create dim_author from the data provided in dim_book_star.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create dim_author with a column for author.\n",
    "    Insert all the distinct authors from dim_book_star into dim_author.\n",
    "---\n",
    "\n",
    "    Alter dim_author to have a primary key called author_id.\n",
    "    Output all the columns of dim_author.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Create a new table for dim_author with an author column\n",
    "CREATE TABLE dim_author (\n",
    "    author varchar(256)  NOT NULL\n",
    ");\n",
    "\n",
    "-- Insert authors \n",
    "INSERT INTO dim_author\n",
    "SELECT DISTINCT author FROM dim_book_star;\n",
    "\n",
    "-- Add a primary key \n",
    "ALTER TABLE dim_author ADD COLUMN author_id SERIAL PRIMARY KEY;\n",
    "\n",
    "-- Output the new table\n",
    "SELECT * FROM dim_author;\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Awesome! You've created a dimension table that succesfully meets the schema criteria - it has all the authors with no repeats and unique author_ids. If we were to continue completing the star schema, we would need to create tables for the other dimensions using similar code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![STAR_SCHEMA](/home/nero/Documents/Estudos/DataCamp/SQL/courses/database-design/book-star.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Querying the star schema\n",
    "\n",
    "The novel genre hasn't been selling as well as your company predicted. To help remedy this, you've been tasked to run some analytics on the novel genre to find which areas the Sales team should target. To begin, you want to look at the total amount of sales made in each state from books in the novel genre.\n",
    "\n",
    "Luckily, you've just finished setting up a data warehouse with the following star schema:\n",
    "\n",
    "The tables from this schema have been loaded. Note that you should not use aliases in FROM and JOIN statements.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Select state from the appropriate table and the total sales_amount.\n",
    "    \n",
    "    Complete the JOIN on book_id.\n",
    "    \n",
    "    Complete the JOIN to connect the dim_store_star table\n",
    "    \n",
    "    Conditionally select for books with the genre novel.\n",
    "    \n",
    "    Group the results by state.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Output each state and their total sales_amount\n",
    "SELECT dim_store_star.state, SUM(sales_amount)\n",
    "FROM fact_booksales\n",
    "\t-- Join to get book information\n",
    "    JOIN dim_book_star ON dim_book_star.book_id = fact_booksales.book_id\n",
    "\t-- Join to get store information\n",
    "    JOIN dim_store_star ON dim_store_star.store_id = fact_booksales.store_id\n",
    "-- Get all books with in the novel genre\n",
    "WHERE  \n",
    "    dim_book_star.genre = 'novel'\n",
    "-- Group results by state\n",
    "GROUP BY\n",
    "    dim_store_star.state;\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Quality query! We now have a nice list of the amount of money made from novels in each state. Note that it took only two joins to run this query.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SNOW_SCHEMA](/home/nero/Documents/Estudos/DataCamp/SQL/courses/database-design/book-snowflake-copy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Querying the snowflake schema\n",
    "\n",
    "Imagine that you didn't have the data warehouse set up. Instead, you'll have to run this query on the company's operational database, which means you'll have to rewrite the previous query with the following snowflake schema:\n",
    "\n",
    "The tables in this schema have been loaded. Remember, our goal is to find the amount of money made from the novel genre in each state.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Select state from the appropriate table and the total sales_amount.\n",
    "    Complete the two JOINS to get the genre_id's.\n",
    "    Complete the three JOINS to get the state_id's.\n",
    "    Conditionally select for books with the genre novel.\n",
    "    Group the results by state.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Output each state and their total sales_amount\n",
    "SELECT dim_state_sf.state, SUM(sales_amount)\n",
    "FROM fact_booksales\n",
    "    -- Joins for genre\n",
    "    JOIN dim_book_sf on dim_book_sf.book_id = fact_booksales.book_id\n",
    "    JOIN dim_genre_sf on dim_genre_sf.genre_id = dim_book_sf.genre_id\n",
    "    -- Joins for state \n",
    "    JOIN dim_store_sf on dim_store_sf.store_id = fact_booksales.store_id \n",
    "    JOIN dim_city_sf on dim_city_sf.city_id = dim_store_sf.city_id\n",
    "\tJOIN dim_state_sf on  dim_state_sf.state_id = dim_city_sf.state_id\n",
    "-- Get all books with in the novel genre and group the results by state\n",
    "WHERE  \n",
    "    dim_genre_sf.genre = 'novel'\n",
    "GROUP BY\n",
    "    dim_state_sf.state;\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! This query was definitely more work than the previous one. It wouldn't be practical to have to think about all these joins if you're doing a lot of analytics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Updating countries\n",
    "\n",
    "Going through the company data, you notice there are some inconsistencies in the store addresses. These probably occurred during data entry, where people fill in fields using different naming conventions. This can be especially seen in the country field, and you decide that countries should be represented by their abbreviations. The only countries in the database are Canada and the United States, which should be represented as USA and CA.\n",
    "\n",
    "In this exercise, you will compare the records that need to be updated in order to do this task on the star and snowflake schema. dim_store_star and dim_country_sf have been loaded.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Output all the records that need to be updated in the star schema so that countries are represented by their abbreviations.\n",
    "---\n",
    "Question\n",
    "\n",
    "How many records would need to be updated in the snowflake schema?\n",
    "Possible answers:\n",
    "    \n",
    "    18 records \n",
    "    \n",
    "    2 records\n",
    "    \n",
    "    1 record {Answer}\n",
    "    \n",
    "    0 records\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Output records that need to be updated in the star schema\n",
    "SELECT * FROM dim_store_star\n",
    "WHERE country != 'USA' AND country !='CA';\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's right! Only one record needs to be changed - Canada to CA. Updating is typically simpler in a snowflake schema because there are less records to update because redundant values are minimized to their own table (e.g., countries have their own table, dim_country_sf). Snowflake schemas are also better at enforcing naming conventions due to referential integrity. Note how there weren't any variations in how Canada and USA were referred to in the snowflake schema.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Extending the snowflake schema\n",
    "\n",
    "The company is thinking about extending their business beyond bookstores in Canada and the US. Particularly, they want to expand to a new continent. In preparation, you decide a continent field is needed when storing the addresses of stores.\n",
    "\n",
    "Luckily, you have a snowflake schema in this scenario. As we discussed in the video, the snowflake schema is typically faster to extend while ensuring data consistency. Along with dim_country_sf, a table called dim_continent_sf has been loaded. It contains the only continent currently needed, North America, and a primary key. In this exercise, you'll need to extend dim_country_sf to reference dim_continent_sf.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Add a continent_id column to dim_country_sf with a default value of 1. Note thatNOT NULL DEFAULT(1) constrains a value from being null and defaults its value to 1.\n",
    "    Make that new column a foreign key reference to dim_continent_sf's continent_id.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Add a continent_id column with default value of 1\n",
    "ALTER TABLE dim_country_sf\n",
    "ADD continent_id int NOT NULL DEFAULT(1);\n",
    "\n",
    "-- Add the foreign key constraint\n",
    "ALTER TABLE dim_country_sf ADD CONSTRAINT country_continent\n",
    "   FOREIGN KEY (continent_id) REFERENCES dim_continent_sf(continent_id);\n",
    "\n",
    "-- Output updated table\n",
    "SELECT * FROM dim_country_sf;\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! We have successfully extended the snowflake schema to have continents. That wasn't too bad as it only required altering one table and we can be sure of data consistency. This type of extension is a big benefit of the snowflake schema.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Converting to 1NF\n",
    "\n",
    "In the next three exercises, you'll be working through different tables belonging to a car rental company. Your job is to explore different schemas and gradually increase the normalization of these schemas through the different normal forms. At this stage, we're not worried about relocating the data, but rearranging the tables.\n",
    "\n",
    "A table called customers has been loaded, which holds information about customers and the cars they have rented.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "Does the customers table meet 1NF criteria?\n",
    "Possible answers:\n",
    "    \n",
    "    Yes, all the records are unique.\n",
    "    \n",
    "    No, because there are multiple values in cars_rented and invoice_id {Answer}\n",
    "    \n",
    "    No, because the non-key columns such as don't depend on customer_id, the primary key.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Create a new table to hold the cars rented by customers\n",
    "CREATE TABLE cust_rentals (\n",
    "  customer_id INT NOT NULL,\n",
    "  car_id VARCHAR(128) NULL,\n",
    "  invoice_id VARCHAR(128) NULL\n",
    ");\n",
    "\n",
    "-- Drop a column from customers table to satisfy 1NF\n",
    "ALTER TABLE customers\n",
    "DROP COLUMN cars_rented,\n",
    "DROP COLUMN invoice_id;\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! We now have two tables: (1) customers which holds customer information and (2) cust_rentals which holds the car_ids rented by different customer_ids. This satisfies 1NF. In a real situation, we would need to fill the new table before dropping any columns.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Converting to 2NF\n",
    "\n",
    "Let's try normalizing a bit more. In the last exercise, you created a table holding customer_ids and car_ids. This has been expanded upon and the resulting table, customer_rentals, has been loaded for you. Since you've got 1NF down, it's time for 2NF.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "Why doesn't customer_rentals meet 2NF criteria?\n",
    "Possible answers:\n",
    "    \n",
    "    Because the end_date doesn't depend on all the primary keys.\n",
    "    \n",
    "    Because there can only be at most two primary keys.\n",
    "    \n",
    "    Because there are non-key attributes describing the car that only depend on one primary key, car_id. {Answer}\n",
    "---\n",
    "\n",
    "    Create a new table for the non-key columns that were conflicting with 2NF criteria.\n",
    "    Drop those non-key columns from customer_rentals.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Create a new table to satisfy 2NF\n",
    "CREATE TABLE cars (\n",
    "  car_id VARCHAR(256) NULL,\n",
    "  model VARCHAR(128),\n",
    "  manufacturer VARCHAR(128),\n",
    "  type_car VARCHAR(128),\n",
    "  condition VARCHAR(128),\n",
    "  color VARCHAR(128)\n",
    ");\n",
    "\n",
    "-- Drop columns in customer_rentals to satisfy 2NF\n",
    "ALTER TABLE customer_rentals\n",
    "DROP COLUMN model,\n",
    "DROP COLUMN manufacturer, \n",
    "DROP COLUMN type_car,\n",
    "DROP COLUMN condition,\n",
    "DROP COLUMN color;\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "There we go! model, manufacturer, type_car, conditions, and colors depend on car_id, but are independent of the other two primary keys, customer_id and start_date. The customer or start date cannot change these attributes. Hence, we have put these columns in a new table and dropped them from customer_rentals.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Converting to 3NF\n",
    "\n",
    "Last, but not least, we are at 3NF. In the last exercise, you created a table holding car_idss and car attributes. This has been expanded upon. For example, car_id is now a primary key. The resulting table, rental_cars, has been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "Why doesn't rental_cars meet 3NF criteria?\n",
    "Possible answers:\n",
    "    \n",
    "    Because there are two columns that depend on the non-key column, model. {Answer}\n",
    "    \n",
    "    Because there are two columns that depend on the non-key column, color.\n",
    "    \n",
    "    Because 2NF criteria isn't satisfied\n",
    "---\n",
    "\n",
    "    Create a new table for the non-key columns that were conflicting with 3NF criteria.\n",
    "    Drop those non-key columns from rental_cars.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "-- Create a new table to satisfy 3NF\n",
    "CREATE TABLE car_model(\n",
    "  model VARCHAR(128),\n",
    "  manufacturer VARCHAR(128),\n",
    "  type_car VARCHAR(128)\n",
    ");\n",
    "\n",
    "-- Drop columns in rental_cars to satisfy 3NF\n",
    "ALTER TABLE rental_cars\n",
    "DROP COLUMN manufacturer, \n",
    "DROP COLUMN type_car;\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! You did it - the first three normal forms! Can you see how these 3NF tables help reduce data redundancy and potential data anomalies?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
