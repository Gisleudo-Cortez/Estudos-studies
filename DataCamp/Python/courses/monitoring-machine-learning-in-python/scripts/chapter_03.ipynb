{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying relevant drifts\n",
    "\n",
    "Recall the Green Taxi dataset example from Chapter 2, where the model was predicting the tip amount. In this exercise, we've prepared a comparison plot that illustrates the daily values of the reconstruction error obtained from the multivariate drift detection method, shown in light blue, alongside the realized performance calculated using the MAE metric, which is plotted in dark blue.\n",
    "\n",
    "Your task now is to identify the day when an alerted drift overlaps with an alert in the model's performance.\n",
    "\n",
    "![image](images/Lesson_3_1_exercise_plot.png)\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    31st of December\n",
    "    \n",
    "    \n",
    "    27th of December\n",
    "    \n",
    "    \n",
    "    25th of December {Answer}\n",
    "    \n",
    "    \n",
    "    18th of December\n",
    "\n",
    "**Great job! As you can see, there are a lot of false alerts, and only one of the drift actually negatively impacts the performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nero/Documents/Estudos/DataCamp'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Drift in hotel booking dataset\n",
    "\n",
    "In the previous chapter, you calculated the business value and ROC AUC performance for a model that predicts booking cancellations. You noticed a few alerts in the resulting plots, which is why you need to investigate the presence of drift in the analysis data.\n",
    "\n",
    "In this exercise, you will initialize the multivariate drift detection method and compare its results with the performance results calculated in the previous chapter.\n",
    "\n",
    "StandardDeviationThreshold is already imported along with business value, and ROC AUC results stored in the perf_results variable and feature_column_names are already defined.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Initialize the StandardDeviationThreshold method and set std_lower_multiplier to 2 and std_upper_multiplier parameters to 1.\n",
    "\n",
    "    Add the following feature names country, lead_time, parking_spaces, and hotel. Retain their order.\n",
    "\n",
    "    Pass previously defined thresholds and feature names to the DataReconstructionDriftCalculator.\n",
    "\n",
    "    Show the comparison plot featuring both the multivariate drift detection results(mv_results) and the performance results(perf_results).\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create standard deviation thresholds\n",
    "stdt = StandardDeviationThreshold(std_lower_multiplier=2, std_upper_multiplier=1)\n",
    "\n",
    "# Define feature columns\n",
    "feature_column_names = ['country', 'lead_time', 'parking_spaces', 'hotel']\n",
    "\n",
    "# Intialize, fit, and show results of multivariate drift calculator\n",
    "mv_calc = nannyml.DataReconstructionDriftCalculator(\n",
    "    column_names=feature_column_names,\n",
    "\tthreshold = stdt,\n",
    "    timestamp_column_name='timestamp',\n",
    "    chunk_period='m')\n",
    "mv_calc.fit(reference)\n",
    "mv_results = mv_calc.calculate(analysis)\n",
    "mv_results.filter(period='analysis').compare(perf_results).plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! It's important to observe that two of the alerted drifts had a significant impact, resulting in a large decrease and increase in the business value. Additionally, the alert in the ROC AUC value appears to be linked to these drifts. In the next video, we will delve into tools to explain these findings!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Univariate drift detection for hotel booking dataset\n",
    "\n",
    "In the previous exercises, we established using the multivariate drift detection method that the shift in data in January is responsible for the alert in the ROC AUC metric and the negative business value of the model.\n",
    "\n",
    "In this exercise, you will use a univariate drift detection method to find the feature and explanation behind the drift.\n",
    "\n",
    "The reference and analysis sets are already pre-loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Specify Wasserstein and Jensen-Shannon method for continuous methods and L-inifity and Chi2 for categorical.\n",
    "\n",
    "    Fit the reference and calculate results on the analysis set.\n",
    "\n",
    "    Plot the results.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Intialize the univariate drift calculator\n",
    "uv_calc = nannyml.UnivariateDriftCalculator(\n",
    "    column_names=feature_column_names,\n",
    "    timestamp_column_name='timestamp',\n",
    "    chunk_period='m',\n",
    "    continuous_methods=['wasserstein', 'jensen_shannon'],\n",
    "    categorical_methods=['l_infinity', 'chi2'],\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "uv_calc.fit(reference)\n",
    "uv_results = uv_calc.calculate(analysis)\n",
    "uv_results.plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great work! Notice we got 8 different plots, some of them have a lot of alerts some of them not at all. To make the results more insightful let's rank the results by the number of alerts and its correlation to performance!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Ranking the univariate results\n",
    "\n",
    "In the previous exercises, you ended up with eight plots. In this exercise your task is to rank them based on the number of the alerts and the correlation with the ROC AUC performance.\n",
    "\n",
    "The univariate results are pre-loaded and stored in uv_results variable, and performance results are stored in perf_results variable.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Initialize AlertCountRanker without any initial parameters.\n",
    "    Call .rank() method and pass the filtered uv_results for Wasserstein and L-infinity methods.\n",
    "---\n",
    "\n",
    "    Initialize CorrelationRanker without any initial parameters.\n",
    "    Fit correlation ranker with filtered perf_results for reference period.\n",
    "    Use rank method and pass there filtered uv_results for Wasserstein and L-infinity methods and perf_results.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Initialize the alert count ranker\n",
    "\n",
    "alert_count_ranker = nannyml.AlertCountRanker()\n",
    "alert_count_ranked_features = alert_count_ranker.rank(\n",
    "    uv_results.filter(methods=['wasserstein', 'l_infinity']))\n",
    "\n",
    "display(alert_count_ranked_features)\n",
    "\n",
    "# Initialize the correlation ranker\n",
    "correlation_ranker = nannyml.CorrelationRanker()\n",
    "correlation_ranker.fit(perf_results.filter(period='reference'))\n",
    "\n",
    "correlation_ranked_features = correlation_ranker.rank(\n",
    "    uv_results.filter(methods=['wasserstein', 'l_infinity']),\n",
    "    perf_results)\n",
    "display(correlation_ranked_features)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! The count-based alert appears to have a high number of false alerts for parking spaces and lead time. According to the correlation ranker, it seems that drifts in the hotel and country features are the ones affecting the performance. Now, let's visualize the drift and distribution values for these features!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Visualizing drifting features\n",
    "\n",
    "After ranking the univariate results, you know that drift hotel and country features are impacting the model's performance the most. In this exercise, you will look at the drift results and distribution plots of them to determine the root cause of the problem.\n",
    "\n",
    "The results from the univariate drift calculator are stored in the uv_results variable.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Set period argument to analysis for drift_results.\n",
    "\n",
    "    Pass hotel and country to column_names for drift_results.\n",
    "\n",
    "    Set kind argument in .plot() method to \"drift\".\n",
    "\n",
    "    Do the same for distribution_results, except for setting the kind argument in .plot() method to \"distribution\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Filter and create drift plots\n",
    "drift_results = uv_results.filter(\n",
    "    period='analysis',\n",
    "    column_names=['hotel', 'country']\n",
    "    ).plot(kind='drift')\n",
    "\n",
    "# Filter and create distribution plots\n",
    "distribution_results = uv_results.filter(\n",
    "    period='analysis',\n",
    "    column_names=['hotel', 'country']\n",
    "    ).plot(kind='distribution')\n",
    "\n",
    "# Show the plots\n",
    "drift_results.show()\n",
    "distribution_results.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic work! It's now evident that the country distribution is notably shifting, particularly in January, which provides a clear explanation for the performance drops. The root cause appears to be an increase in international travelers during the winter season, attracted by Portugal's warm climate.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Data quality checks\n",
    "\n",
    "As you learned in the previous video, missing values can result in a loss of valuable information and potentially lead to incorrect interpretations. Similarly, the presence of unseen values can also affect your model's confidence.\n",
    "\n",
    "In this exercise, your goal is to explore whether the hotel booking dataset contains missing values and identify any unseen values. The reference and analysis datasets are already loaded, along with the nannyml library.\n",
    "\n",
    "A quick reminder, if you can't recall the column types, you can easily explore the data using the .head() method.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Initialize the missing value calculator, passing the selected columns to column_names and setting the chunk_period to monthly.\n",
    "---\n",
    "    Add two categorical column names country and hotel, initialize the unseen values calculator, and pass the categorical_columns to column names.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Define analyzed columns\n",
    "selected_columns = ['country', 'lead_time', 'parking_spaces', 'hotel']\n",
    "\n",
    "# Intialize missing values calculator\n",
    "ms_calc = nannyml.MissingValuesCalculator(\n",
    "    column_names=selected_columns,\n",
    "    chunk_period='m',\n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "ms_calc.fit(reference)\n",
    "ms_results = ms_calc.calculate(analysis)\n",
    "ms_results.plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Define analyzed categorical columns\n",
    "categorical_columns = ['country', 'hotel']\n",
    "\n",
    "# Intialize unseen values calculator\n",
    "us_calc = nannyml.UnseenValuesCalculator(\n",
    "  \tcolumn_names=categorical_columns, \n",
    "  \tchunk_period='m', \n",
    "  \ttimestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "us_calc.fit(reference)\n",
    "us_results = us_calc.calculate(analysis)\n",
    "us_results.filter(period='analysis').plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You got it! The country is the only feature with unseen values. The highest number of occurrences is in January, and that's when we also observed the most significant drop in performance. In our next exercise, we'll take a closer look at the statistical summary of our continuous features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Summary statistics\n",
    "\n",
    "Recall from the previous lesson that NannyML provides five methods for tracking statistical changes in your features.\n",
    "\n",
    "In this exercise, you will focus on examining the lead_time feature from the Hotel Booking dataset, which indicates how many days in advance a booking was made. By using summation, median, and standard deviation statistics, you can gain valuable insights into how customer booking behavior has evolved over time.\n",
    "\n",
    "It's important to note that both the reference and analysis sets, as well as the nannyml library, are already pre-loaded and ready for use.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Define analyzed column to lead time, initialize SummaryStatsSumCalculator, Pass analyzed_column to the column names parameter.\n",
    "---\n",
    "    Initialize SummaryStatsMedianCalculator, pass analyzed_column to the column names parameter, filter results for the only analysis period.\n",
    "---\n",
    "    Initialize SummaryStatsStdCalculator.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Define analyzed column\n",
    "analyzed_column = ['lead_time']\n",
    "\n",
    "# Intialize sum values calculator\n",
    "sum_calc = nannyml.SummaryStatsSumCalculator(\n",
    "    column_names=analyzed_column, \n",
    "    chunk_period='m', \n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "sum_calc.fit(reference)\n",
    "sum_calc_res = sum_calc.calculate(analysis)\n",
    "sum_calc_res.plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Define analyzed column\n",
    "analyzed_column = ['lead_time']\n",
    "\n",
    "# Intialize median values calculator\n",
    "med_calc = nannyml.SummaryStatsMedianCalculator(\n",
    "    column_names=analyzed_column, \n",
    "    chunk_period='m', \n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "med_calc.fit(reference)\n",
    "med_calc_res = med_calc.calculate(analysis)\n",
    "med_calc_res.filter(period='analysis').plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Define analyzed column\n",
    "analyzed_column = ['lead_time']\n",
    "\n",
    "# Intialize standard deviation values calculator\n",
    "std_calc = nannyml.SummaryStatsStdCalculator(\n",
    "    column_names=analyzed_column, \n",
    "    chunk_period='m', \n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "std_calc.fit(reference)\n",
    "std_calc_res = std_calc.calculate(analysis)\n",
    "std_calc_res.filter(period=\"analysis\").plot().show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! For January, the standard deviation of lead times drops below the threshold. A low standard deviation suggests that lead times in January are relatively consistent and clustered around the mean. This typically makes predictions more straightforward. However, it's worth noting that the substantial shift in the country feature had such a significant impact that it resulted in a decrease in model performance. Now, let's see how we can resolve these problems!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the resolution?\n",
    "\n",
    "Imagine a scenario where a company launched an app to help people take notes on their tablets. Internally, the app runs an ML model to recognize handwritten characters and help users do a text search across their notes.\n",
    "\n",
    "The company notices that the more people interact with the app, the worse the ML model becomes. After a careful examination, the company realizes that after a while of writing in the app, the users start getting more comfortable, and their handwriting becomes more clumsy and less readable.\n",
    "\n",
    "What would be the issue resolution in that case?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    Do nothing\n",
    "    \n",
    "    \n",
    "    Revert back to the previous model\n",
    "    \n",
    "    \n",
    "    Retrain the model with new data{Answer}\n",
    "    \n",
    "    \n",
    "    Change the downstream processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should you do nothing or not?\n",
    "\n",
    "Let's picture a real estate company that primarily buys houses at fair prices, renovates them, and then sells them at higher prices.\n",
    "\n",
    "Lately, the model has overestimated few prices, resulting in huge profit reductions. This means that the model's predictions have a significant impact on the company's bottom line.\n",
    "\n",
    "Is it a viable solution to do nothing in this scenario, and why?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    Yes, because overestimating prices doesn't significantly affect the business's bottom line.\n",
    "    \n",
    "    \n",
    "    No, because the model's consistent overestimations could potentially result in a loss for the business. {Answer}\n",
    "    \n",
    "    \n",
    "    No, because the model could also underestimate prices, which would reduce profits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Implementing a monitoring workflow\n",
    "\n",
    "Throughout the course, you've learned about the monitoring workflow. The first step is performance monitoring. If there are negative changes, the next steps involve multivariate drift detection to identify if drift caused the performance drop, followed by univariate drift detection to pinpoint the cause in individual features. Once the investigation results are in, you can take steps to resolve the issue.\n",
    "\n",
    "To solidify this knowledge, in the exercise, you'll apply this process to the US Consensus dataset. The reference and analysis datasets are pre-loaded, and you have access to the CBPE estimator, uv_calc univariate calculator, and an alert_count_ranker for feature drift ranking.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Fit the reference set to the estimator, estimate results on analysis set, and show the results.\n",
    "---\n",
    "\n",
    "    Set the chunk_size parameter to 5000 for DataReconstructionDriftCalculator. Next, filter the mv_results for analysis period, then compare them with the estimated_results.\n",
    "---\n",
    "Question\n",
    "\n",
    "The top drifting feature is AGEP, which represents the person's age. Your task is to use the distribution plot and explain the drift that happens in Chunk 27 and 28, which was responsible for the performance drop.\n",
    "\n",
    "Possible answers:\n",
    "    \n",
    "    During that period, there is an increased number of old individuals in the data.\n",
    "    \n",
    "    During that period, there is a greater presence of younger individuals in the data. {Answer}\n",
    "    \n",
    "    In that period, a higher number of middle age individuals is in the data.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "estimator.fit(reference)\n",
    "estimated_performance = estimator.estimate(analysis)\n",
    "mv_calc = nannyml.DataReconstructionDriftCalculator(column_names=features, chunk_size=5000)\n",
    "mv_calc.fit(reference)\n",
    "mv_results = mv_calc.calculate(analysis)\n",
    "\n",
    "# Calculate univariate drift\n",
    "uv_calculator.fit(reference)\n",
    "uv_results = uv_calculator.calculate(analysis)\n",
    "\n",
    "# Check the most drifting features\n",
    "alert_count_ranked_features = alert_count_ranker.rank(uv_results)\n",
    "display(alert_count_ranked_features.head())\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Congratulations! The shift in the distribution in Chunks 27 and 28 is primarily centered around younger individuals, many of whom are students without families. This change caused a drop in the model's performance because it had limited exposure to this particular demographic.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
