{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNot necessarily! A Decision Tree model is unfortunately a greedy algorithm, not guaranteed to return the optimal tree whether or not it's cross-validated. You're better off to combine cross-validation with a bootstrap method.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Validating model performance\n",
    "\n",
    "How do you ensure your model will perform well against test (unseen) data?\n",
    "\n",
    "Select the answer that is false:\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Perform K-fold cross-validation to tune hyperparameters during machine learning model training.\n",
    "\n",
    "\n",
    "Use a bootstrapping method, where a subset of the data is selected with replacement, so that the output of averaged predictions produces a more accurate model from the reduction in variance.\n",
    "\n",
    "\n",
    "Create a Random Forest using GridSearchCV to find the best hyperparameters and create a final model with them before evaluating on the test data.\n",
    "\n",
    "\n",
    "Create a cross-validated Decision Tree model, then evaluate its performance on the test set.(Answer)\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Not necessarily! A Decision Tree model is unfortunately a greedy algorithm, not guaranteed to return the optimal tree whether or not it's cross-validated. You're better off to combine cross-validation with a bootstrap method.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan Status</th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Years in current job</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>...</th>\n",
       "      <th>Purpose_EducationalExpenses</th>\n",
       "      <th>Purpose_HomeImprovements</th>\n",
       "      <th>Purpose_HomePurchase</th>\n",
       "      <th>Purpose_MajorPurchase</th>\n",
       "      <th>Purpose_MedicalBills</th>\n",
       "      <th>Purpose_Moving</th>\n",
       "      <th>Purpose_Other</th>\n",
       "      <th>Purpose_RenewableEnergyPurchase</th>\n",
       "      <th>Purpose_Vacation</th>\n",
       "      <th>Purpose_Wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loan Status  Current Loan Amount  Credit Score  Years in current job  \\\n",
       "0            1                 2.00          0.84                 -0.48   \n",
       "1            1                 0.32          0.49                  0.91   \n",
       "2            1                -1.06          1.10                 -1.31   \n",
       "3            1                -0.87         -0.63                  1.19   \n",
       "4            0                 1.06         -1.31                 -0.20   \n",
       "\n",
       "   Years of Credit History  Months since last delinquent  \\\n",
       "0                     0.84                          0.29   \n",
       "1                    -1.97                          0.77   \n",
       "2                    -1.46                         -0.48   \n",
       "3                     2.00                          1.47   \n",
       "4                     0.07                          1.53   \n",
       "\n",
       "   Number of Open Accounts  Number of Credit Problems  Current Credit Balance  \\\n",
       "0                     0.18                      -0.34                    0.82   \n",
       "1                     1.79                      -0.34                    0.56   \n",
       "2                    -0.83                      -0.34                   -0.70   \n",
       "3                     0.58                      -0.34                   -0.08   \n",
       "4                    -0.83                      -0.34                   -0.21   \n",
       "\n",
       "   Maximum Open Credit  ...  Purpose_EducationalExpenses  \\\n",
       "0                 0.19  ...                            0   \n",
       "1                 1.05  ...                            0   \n",
       "2                -0.55  ...                            0   \n",
       "3                -0.22  ...                            0   \n",
       "4                -0.38  ...                            0   \n",
       "\n",
       "   Purpose_HomeImprovements  Purpose_HomePurchase  Purpose_MajorPurchase  \\\n",
       "0                         0                     0                      0   \n",
       "1                         0                     0                      0   \n",
       "2                         0                     0                      0   \n",
       "3                         1                     0                      0   \n",
       "4                         0                     0                      0   \n",
       "\n",
       "   Purpose_MedicalBills  Purpose_Moving  Purpose_Other  \\\n",
       "0                     0               0              0   \n",
       "1                     0               0              0   \n",
       "2                     0               0              1   \n",
       "3                     0               0              0   \n",
       "4                     0               0              0   \n",
       "\n",
       "   Purpose_RenewableEnergyPurchase  Purpose_Vacation  Purpose_Wedding  \n",
       "0                                0                 0                0  \n",
       "1                                0                 0                0  \n",
       "2                                0                 0                0  \n",
       "3                                0                 0                0  \n",
       "4                                0                 0                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loan_data = pd.read_csv(path_data+'loans_dti.csv')\n",
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loan_data.drop('Loan Status', axis=1)\n",
    "y = loan_data['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6197333333333334\n",
      "Tuned Decision Tree Parameter: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Tuned Decision Tree Accuracy: 0.7168857142857142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNice work! K-fold cross-validation improved the accuracy of a decision tree model by more than 10 percent!\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Decision tree\n",
    "\n",
    "In the last three chapters, you've learned a range of techniques that help you tackle many aspects of the machine learning interview. In this chapter, you'll be introduced to various ways to make sure any model you're asked to create or discuss in a machine learning interview is generalizable, evaluated correctly, and properly selected from among other possible models.\n",
    "\n",
    "In this exercise, you will delve into hyperparameter tuning for a decision tree on the loan_data dataset. Here you'll tune min_samples_split, which is the minimum number of samples required to create an additional binary split, and max_depth, which is how deep you want to grow the tree. The deeper a tree, the more splits and therefore captures more information about the data.\n",
    "\n",
    "The feature matrix X and the target label y have been imported for you.\n",
    "\n",
    "Note that you're once again performing all of the steps in the machine learning pipeline!\n",
    "\n",
    "Machine learning pipeline\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the correct function for a decision tree classifier and split the data into train and test sets.\n",
    "    Instantiate a decision tree classifier, fit, predict, and print accuracy.\n",
    "---\n",
    "    Import the correct function to perform cross-validated grid search.\n",
    "    Instantiate a decision tree classifier and use it with the parameter grid to perform a cross-validated grid-search.\n",
    "    Fit and print model evaluation metrics\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "\n",
    "# Instantiate, Fit, Predict\n",
    "loans_clf = DecisionTreeClassifier() \n",
    "loans_clf.fit(X_train, y_train)\n",
    "y_pred = loans_clf.predict(X_test)\n",
    "\n",
    "# Evaluation metric\n",
    "print(\"Decision Tree Accuracy: {}\".format(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Import modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "param_grid = {\"criterion\": [\"gini\"], \"min_samples_split\": [2, 10, 20], \n",
    "              \"max_depth\": [None, 2, 5, 10]}\n",
    "\n",
    "# Instantiate classifier and GridSearchCV, fit\n",
    "loans_clf = DecisionTreeClassifier()\n",
    "dtree_cv = GridSearchCV(loans_clf, param_grid=param_grid, cv=5)\n",
    "fit = dtree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Decision Tree Parameter: {}\".format(dtree_cv.best_params_))\n",
    "print(\"Tuned Decision Tree Accuracy: {}\".format(dtree_cv.best_score_))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice work! K-fold cross-validation improved the accuracy of a decision tree model by more than 10 percent!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7178666666666667\n",
      "Tuned Random Forest Parameter: {'criterion': 'gini', 'max_depth': 5, 'max_features': 10, 'min_samples_split': 20}\n",
      "Tuned Random Forest Accuracy: 0.720114276277468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat job! Although k-fold cross-validation did not improve a random forest model as much as it did for the decision tree, it had a 7 percent improvement over the baseline!\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "A forest of decision trees\n",
    "\n",
    "For this exercise, you'll practice using the bootstrapped Decision Tree, otherwise known as the Random Forest. As you did in the previous exercise, you'll then compare its accuracy to a model where you've tuned hyperparameters with cross-validation.\n",
    "\n",
    "This time, you'll tune an additional hyperparameter, max_features, which lets your model decide how many features to use. When it is not set specifically, then it defaults to auto. Something to keep in mind for an interview is that Decision Trees consider all features by default, whereas Random Forests usually consider the square root of the number of features.\n",
    "\n",
    "The feature matrix X, target label y, and train_test_split from sklearn.model_selection have been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the correct function for a random forest classifier and split the data into train and test sets.\n",
    "    Instantiate a random forest classifier, fit, predict, and print accuracy.\n",
    "---\n",
    "    Import the correct function to perform cross-validated grid search.\n",
    "    Perform the same steps, this time while performing cross-validated grid-search.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "\n",
    "# Instantiate, Fit, Predict\n",
    "loans_rf = RandomForestClassifier() \n",
    "loans_rf.fit(X_train, y_train)\n",
    "y_pred = loans_rf.predict(X_test)\n",
    "\n",
    "# Evaluation metric\n",
    "print(\"Random Forest Accuracy: {}\".format(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Import modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "param_grid = {\"criterion\": [\"gini\"], \"min_samples_split\": [2, 10, 20], \n",
    "              \"max_depth\": [None, 2, 5, 10],\"max_features\": [10, 20, 30]}\n",
    "\n",
    "# Instantiate classifier and GridSearchCV, fit\n",
    "loans_rf = RandomForestClassifier(n_estimators=10)\n",
    "rf_cv = GridSearchCV(loans_rf, param_grid=param_grid, cv=3)\n",
    "fit = rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Random Forest Parameter: {}\".format(rf_cv.best_params_))\n",
    "print(\"Tuned Random Forest Accuracy: {}\".format(rf_cv.best_score_))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! Although k-fold cross-validation did not improve a random forest model as much as it did for the decision tree, it had a 7 percent improvement over the baseline!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIndeed! A low precision score indicates that there are too many false positives, bringing the calculation down. Seeking to reduce the number of false positives to increase the precision can be accomplished with trying different classification algorithms and/or resampling techniques.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "X-ray weapon detection\n",
    "\n",
    "You are given a dataset on detecting weapons at major US airports and have built a classification model with an accuracy of 99%. Why should you question the performance of the model? How should you proceed to ensure the model is indeed performing well?\n",
    "\n",
    "Select the answer that is true:\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "When a dataset has imbalanced classes, a high recall score indicates a high number of false negatives, so continue to tune hyperparameters.\n",
    "\n",
    "\n",
    "When a dataset has imbalanced classes, a low precision score indicates a high number of false positives, so consider trying different classification algorithms and/or resampling techniques to improve precision.(Answer)\n",
    "\n",
    "\n",
    "When a dataset has imbalanced classes, a low f1 score indicates indicates a good balance between precision and recall, from which it is calculated, so nothing more is needed for model improvement.\n",
    "\n",
    "\n",
    "When a dataset has imbalanced classes, a high accuracy score indicates the model will generalize well, so no adjustments need to be made to improve the model.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Indeed! A low precision score indicates that there are too many false positives, bringing the calculation down. Seeking to reduce the number of false positives to increase the precision can be accomplished with trying different classification algorithms and/or resampling techniques.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  367  3868]\n",
      " [  318 10447]]\n",
      "Accuracy: 0.7209333333333333\n",
      "Precision: 0.7297939224589591\n",
      "Recall: 0.9704598235020901\n",
      "F1: 0.8330940988835726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nNice job! The metrics aren't actually too bad. Precision of 0.72 means there might be a high number of false positives than you really want to see. Let's see if you can improve them in the next exercise with some resampling techniques!\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Imbalanced class metrics\n",
    "\n",
    "Class imbalance is something that can hamper your model's performance in any machine learning context. This is especially relevant in a machine learning interview if you are asked what to do if you are given a dataset with an imbalanced class, as some data is imbalanced by design such as insurance fraud data.\n",
    "\n",
    "In this exercise you'll use sklearn to create a logistic regression model and print the confusion matrix along with several evaluation metrics to get a better understanding of how to interpret Machine Learning models from datasets that have a class imbalance.\n",
    "\n",
    "Recall the class imbalance you saw previously in loan_data. The number of observations with Loan Status of Fully Paid far outweighs those that are Charged Off:\n",
    "\n",
    "Class imbalance\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the necessary modules to create a logistic regression model as well as confusion matrix, accuracy, precision, recall, and F1-scores.\n",
    "---\n",
    "\n",
    "    Instantiate a logistic regression object, fit and predict.\n",
    "---\n",
    "\n",
    "    Print the confusion matrix and accuracy score.\n",
    "---\n",
    "\n",
    "    Print the precision, recall, and F1-scores.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice job! The metrics aren't actually too bad. Precision of 0.72 means there might be a high number of false positives than you really want to see. Let's see if you can improve them in the next exercise with some resampling techniques!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train,y_train], axis=1)\n",
    "deny = train[train['Loan Status'] == 0]\n",
    "approve = train[train['Loan Status'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[2327 1908]\n",
      " [3672 7093]]\n",
      "Accuracy: 0.628\n",
      "Precision: 0.7880235529385624\n",
      "Recall: 0.658894565722248\n",
      "F1: 0.7176970555499341\n",
      "Confusion matrix:\n",
      " [[2324 1911]\n",
      " [3584 7181]]\n",
      "Accuracy: 0.6336666666666667\n",
      "Precision: 0.7898152221733392\n",
      "Recall: 0.6670692057594054\n",
      "F1: 0.7232713904416578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAmazing! Using both upsampling and downsampling techniques improved the precision score significantly, meaning there are less false positives. That is definitely a good thing!\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Resampling techniques\n",
    "\n",
    "In the last exercise, you saw how class imbalance can impact the results of your confusion matrix. In this exercise, you'll practice resampling techniques to explore the different results that alternative resampling styles can have on a dataset with class imbalance like that seen with loan_data. Using sklearn's resample() function, matching the number of rows in the majority class is called upsampling, while matching the number of rows in the minority class is called downsampling.\n",
    "\n",
    "You will create both an upsampled and downsampled version of the loan_data dataset, apply a logistic regression on both of them and then evaluate your performance. The training data and its labels that correspond to deny are subset to contain only the minority class and to approve that correspond to the majority.\n",
    "\n",
    "A train/test split testing object for making predictions has been saved to the workspace as X_test for your use in the exercises.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create an upsampled minority class the length of the majority class and concatenate (done for you).\n",
    "    Create a downsampled majority class the length of the minority class and concatenate (done for you).\n",
    "---\n",
    "    Create an upsampled feature matrix and target array.\n",
    "    Instantiate a logistic regression model object, fit, and predict with X_test.\n",
    "    Print the evaluation metrics.\n",
    "---\n",
    "    Create a downsampled feature matrix and target array.\n",
    "    Instantiate a logistic regression model object, fit, and predict with X_test.\n",
    "    Print the evaluation metrics.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.utils import resample\n",
    "# Upsample minority and combine with majority\n",
    "loans_upsampled = resample(deny, replace=True, n_samples=len(approve), random_state=123)\n",
    "upsampled = pd.concat([approve, loans_upsampled])\n",
    "\n",
    "# Downsample majority and combine with minority\n",
    "loans_downsampled = resample(approve, replace = False,  n_samples = len(deny), random_state = 123)\n",
    "downsampled = pd.concat([loans_downsampled, deny])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Upsampled feature matrix and target array\n",
    "X_train_up = upsampled.drop('Loan Status', axis=1)\n",
    "y_train_up = upsampled['Loan Status']\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "loan_lr_up = LogisticRegression(solver='liblinear')\n",
    "loan_lr_up.fit(X_train_up, y_train_up)\n",
    "upsampled_y_pred = loan_lr_up.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, upsampled_y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, upsampled_y_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, upsampled_y_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, upsampled_y_pred)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, upsampled_y_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Downsampled feature matrix and target array\n",
    "X_train_down = downsampled.drop('Loan Status', axis=1)\n",
    "y_train_down = downsampled['Loan Status']\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "loan_lr_down = LogisticRegression(solver='liblinear')\n",
    "loan_lr_down.fit(X_train_down, y_train_down)\n",
    "downsampled_y_pred = loan_lr_down.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, downsampled_y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, downsampled_y_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, downsampled_y_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, downsampled_y_pred)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, downsampled_y_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Amazing! Using both upsampling and downsampling techniques improved the precision score significantly, meaning there are less false positives. That is definitely a good thing!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAlmost! While you can remove ONE of the variables when they show a high degree of correlation, you wouldn't want to remove all of them.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Addressing multicollinearity\n",
    "\n",
    "After careful exploratory data analysis, you realize that your baseline regression model suffers from multicollinearity. How would you check if that is true or not? Without losing any information, can you build a better baseline model?\n",
    "\n",
    "Select the answer that is false:\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Create a correlation matrix and/or heatmap, then engineer features to combine multicollinear independent variables, making sure to remove the individual features used to create any new features.\n",
    "\n",
    "\n",
    "Create a correlation matrix and/or heatmap, then perform Ridge regression to penalize multicollinear independent variables and perform feature selection for modeling.\n",
    "\n",
    "\n",
    "Create a correlation matrix and/or heatmap, then perform PCA to combine multicollinear independent variables as new principal components.\n",
    "\n",
    "\n",
    "Create a correlation matrix and/or heatmap, then remove the multicollinear independent variables.(Answer)\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Almost! While you can remove ONE of the variables when they show a high degree of correlation, you wouldn't want to remove all of them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(path_data+'diabetes.csv')\n",
    "\n",
    "X = diabetes.drop('progression', axis=1)\n",
    "y = diabetes['progression']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [  10.45384922 -261.16601105  538.84541221  280.72544466 -855.21447839\n",
      "  472.17305267  166.51881384  309.88763264  684.0489522   102.37723262]\n",
      "Mean squared error: 2926.80\n",
      "R_squared score: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  age       sex       bmi        bp        s1        s2  \\\n",
      "age          1.000000  0.173737  0.185085  0.335427  0.260061  0.219243   \n",
      "sex          0.173737  1.000000  0.088161  0.241013  0.035277  0.142637   \n",
      "bmi          0.185085  0.088161  1.000000  0.395415  0.249777  0.261170   \n",
      "bp           0.335427  0.241013  0.395415  1.000000  0.242470  0.185558   \n",
      "s1           0.260061  0.035277  0.249777  0.242470  1.000000  0.896663   \n",
      "s2           0.219243  0.142637  0.261170  0.185558  0.896663  1.000000   \n",
      "s3          -0.075181 -0.379090 -0.366811 -0.178761  0.051519 -0.196455   \n",
      "s4           0.203841  0.332115  0.413807  0.257653  0.542207  0.659817   \n",
      "s5           0.270777  0.149918  0.446159  0.393478  0.515501  0.318353   \n",
      "s6           0.301731  0.208133  0.388680  0.390429  0.325717  0.290600   \n",
      "progression  0.187889  0.043062  0.586450  0.441484  0.212022  0.174054   \n",
      "\n",
      "                   s3        s4        s5        s6  progression  \n",
      "age         -0.075181  0.203841  0.270777  0.301731     0.187889  \n",
      "sex         -0.379090  0.332115  0.149918  0.208133     0.043062  \n",
      "bmi         -0.366811  0.413807  0.446159  0.388680     0.586450  \n",
      "bp          -0.178761  0.257653  0.393478  0.390429     0.441484  \n",
      "s1           0.051519  0.542207  0.515501  0.325717     0.212022  \n",
      "s2          -0.196455  0.659817  0.318353  0.290600     0.174054  \n",
      "s3           1.000000 -0.738493 -0.398577 -0.273697    -0.394789  \n",
      "s4          -0.738493  1.000000  0.617857  0.417212     0.430453  \n",
      "s5          -0.398577  0.617857  1.000000  0.464670     0.565883  \n",
      "s6          -0.273697  0.417212  0.464670  1.000000     0.382483  \n",
      "progression -0.394789  0.430453  0.565883  0.382483     1.000000  \n",
      "Index(['age', 'sex', 'bmi', 'bp', 's3', 's4', 's5', 's6', 'progression',\n",
      "       's1_s2'],\n",
      "      dtype='object')\n",
      "Coefficients: \n",
      " [  -2.33325625 -250.45569362  541.16674251  260.86592129 -338.13983816\n",
      "  -47.01999461  430.98561453   94.21041896 -283.69973876]\n",
      "Mean squared error: 2910.42\n",
      "R_squared score: 0.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThat's great! Now you know how to get metrics from your baseline model, how to explore relationships visually, and how to use feature engineering to reduce multicollinearity. You got the same R-squared score, but the MSE was slightly lower! Trying different combinations of feature engineering would likely continue to improve the model.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Multicollinearity techniques - feature engineering\n",
    "\n",
    "Multicollinearity is a common issue that might affect your performance in any machine learning context. Knowing how to discuss this small detail could take your explanation of modeling from good to great and really set you apart in an interview.\n",
    "\n",
    "In this exercise, you'll practice creating a baseline model using Linear Regression on the diabetes dataset and explore some of the output metrics. Then you'll practice techniques to visually explore the correlation between the independent variables before finally perform feature engineering on 2 variables that are highly correlated.\n",
    "\n",
    "For the first two steps, use X_train, X_test, y_train, and y_test which have been imported to your workspace.\n",
    "\n",
    "Additionally, all relevant packages have been imported for you: pandas as pd, train_test_split from sklearn.model_selection, LinearRegression from sklearn.linear_model, mean_squared_error and r2_score from sklearn.metrics, matplotlib.pyplot as plt and seaborn as sns.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Instantiate, fit, and predict a Linear Regression.\n",
    "    Print the model coefficients, MSE, and r-squared.\n",
    "---\n",
    "    Create a correlation matrix, plot it to a heatmap.\n",
    "    Print the matrix to explore the independent variable relationships.\n",
    "---\n",
    "    Engineer a new feature by combining s1 and s2 from diabetes, then remove them.\n",
    "    Split your data into training and testing data with 30% test size and print the column names.\n",
    "---\n",
    "    Instantiate, fit, and predict a Linear Regression.\n",
    "    Print the model coefficients, MSE, and r-squared.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "lin_mod = LinearRegression()\n",
    "lin_mod.fit(X_train, y_train)\n",
    "y_pred = lin_mod.predict(X_test)\n",
    "\n",
    "# Coefficient estimates\n",
    "print('Coefficients: \\n', lin_mod.coef_)\n",
    "\n",
    "# Mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score\n",
    "print('R_squared score: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Correlation matrix\n",
    "diab_corr = diabetes.corr()\n",
    "\n",
    "# Generate correlation heatmap\n",
    "ax = sns.heatmap(diab_corr, center=0, cmap=sns.diverging_palette(20,220, n=256), square=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()\n",
    "\n",
    "# Print correlations\n",
    "print(diab_corr)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Feature engineering\n",
    "diabetes['s1_s2'] = diabetes['s1'] * diabetes['s2']\n",
    "diabetes = diabetes.drop(['s1','s2'], axis=1)\n",
    "\n",
    "# Print variable names\n",
    "print(diabetes.columns)\n",
    "\n",
    "# Train/test split\n",
    "X2 = diabetes.drop('progression', axis=1)\n",
    "y2 = diabetes['progression']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=123)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "lin_mod2 = LinearRegression()\n",
    "lin_mod2.fit(X_train2, y_train2)\n",
    "y_pred2 = lin_mod2.predict(X_test2)\n",
    "\n",
    "# Coefficient estimates\n",
    "print('Coefficients: \\n', lin_mod2.coef_)\n",
    "\n",
    "# Mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test2, y_pred2))\n",
    "\n",
    "# Explained variance score\n",
    "print('R_squared score: %.2f' % r2_score(y_test2, y_pred2))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's great! Now you know how to get metrics from your baseline model, how to explore relationships visually, and how to use feature engineering to reduce multicollinearity. You got the same R-squared score, but the MSE was slightly lower! Trying different combinations of feature engineering would likely continue to improve the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(path_data+'diabetes.csv')\n",
    "\n",
    "X = diabetes.drop('progression', axis=1)\n",
    "y = diabetes['progression']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [  431.83041038  -293.77173602   253.57573406   568.70922969\n",
      "   -67.51943277  -186.26488336    71.89012557    47.21891689\n",
      "    93.98511769 -1130.48023791]\n",
      "Mean squared error: 2926.80\n",
      "Variance score: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1             2             3             4  \\\n",
      "0  1.000000e+00 -6.700378e-17  3.830167e-16 -4.969697e-18 -5.001632e-16   \n",
      "1 -6.700378e-17  1.000000e+00 -3.489999e-16  1.467519e-17  5.213561e-16   \n",
      "2  3.830167e-16 -3.489999e-16  1.000000e+00 -2.382251e-16 -1.880648e-16   \n",
      "3 -4.969697e-18  1.467519e-17 -2.382251e-16  1.000000e+00  1.091299e-15   \n",
      "4 -5.001632e-16  5.213561e-16 -1.880648e-16  1.091299e-15  1.000000e+00   \n",
      "5 -1.111740e-16  4.502436e-16 -2.162073e-16 -1.641921e-17  3.627956e-16   \n",
      "6 -3.030570e-16  4.853571e-16  5.693614e-17  2.280214e-16  3.169028e-16   \n",
      "7  4.115512e-16  8.435845e-17 -9.755924e-17 -3.155859e-17 -1.521029e-16   \n",
      "8  3.095395e-16  1.101857e-16 -1.255598e-16 -4.763529e-16  3.455301e-16   \n",
      "9  4.262689e-15  4.345410e-15 -8.876019e-16  3.753690e-16  1.688105e-16   \n",
      "\n",
      "              5             6             7             8             9  \n",
      "0 -1.111740e-16 -3.030570e-16  4.115512e-16  3.095395e-16  4.262689e-15  \n",
      "1  4.502436e-16  4.853571e-16  8.435845e-17  1.101857e-16  4.345410e-15  \n",
      "2 -2.162073e-16  5.693614e-17 -9.755924e-17 -1.255598e-16 -8.876019e-16  \n",
      "3 -1.641921e-17  2.280214e-16 -3.155859e-17 -4.763529e-16  3.753690e-16  \n",
      "4  3.627956e-16  3.169028e-16 -1.521029e-16  3.455301e-16  1.688105e-16  \n",
      "5  1.000000e+00 -3.192134e-16  2.804541e-16 -9.394643e-17 -2.307699e-16  \n",
      "6 -3.192134e-16  1.000000e+00 -6.107129e-16  2.938652e-16 -8.885853e-16  \n",
      "7  2.804541e-16 -6.107129e-16  1.000000e+00 -5.171577e-16  0.000000e+00  \n",
      "8 -9.394643e-17  2.938652e-16 -5.171577e-16  1.000000e+00 -1.647345e-15  \n",
      "9 -2.307699e-16 -8.885853e-16  0.000000e+00 -1.647345e-15  1.000000e+00  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nFantastic! This simple change, although it didn't improve your metrics, removed all of the multicollinearity in the diabetes dataset!\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Multicollinearity techniques - PCA\n",
    "\n",
    "In the last exercise you used feature engineering to combine the s1 and s2 independent variables as s1_s2 since they displayed the highest correlation in the diabetes dataset.\n",
    "\n",
    "In this exercise, you'll perform PCA on diabetes to remove multicollinearity before you apply Linear Regression to it. Then, you'll compare the output metrics to those from the last exercise. Finally, you'll visualize what the correlation matrix and heatmap of the dataset looks like since PCA completely removes multicollinearity.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the necessary modules to perform PCA.\n",
    "    Instantiate and fit.\n",
    "    Transform train and test separately.\n",
    "---\n",
    "    Instantiate, fit, and predict a Linear Regression to PCA transformed dataset.\n",
    "    Print the model coefficients, MSE, and r-squared.\n",
    "---\n",
    "    Create a correlation matrix, plot it to a heatmap.\n",
    "    Print the matrix to explore the independent variable relationships.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instantiate\n",
    "pca = PCA()\n",
    "\n",
    "# Fit on train\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Transform train and test\n",
    "X_trainPCA = pca.transform(X_train)\n",
    "X_testPCA = pca.transform(X_test)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "LinRegr = LinearRegression()\n",
    "LinRegr.fit(X_trainPCA, y_train)\n",
    "predictions = LinRegr.predict(X_testPCA)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', LinRegr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predictions))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, predictions))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Correlation matrix\n",
    "X_trainPCA = pd.DataFrame(X_trainPCA)\n",
    "diab_corrPCA = X_trainPCA.corr()\n",
    "\n",
    "# Generate correlation heatmap\n",
    "ax = sns.heatmap(diab_corrPCA, center=0, cmap=sns.diverging_palette(20,220, n=256), square=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()\n",
    "\n",
    "# Print correlations\n",
    "print(diab_corrPCA)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! This simple change, although it didn't improve your metrics, removed all of the multicollinearity in the diabetes dataset!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThat's correct! While GB can use any algorithm, RF uses decision trees!\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "Random forest vs gradient boosting\n",
    "\n",
    "What are the main similarities and differences of Random Forest (RF) and Gradient Boosting (GB)algorithms?\n",
    "\n",
    "Select the answer that is false:\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Random Forest and Gradient Boosting machine learning techniques create multiple random samples that are used to produce a final prediction model.\n",
    "\n",
    "\n",
    "Random Forest uses the bootstrapping method while Gradient Boosting uses weights given to incorrectly predicted observations from a previous sample applied to subsequent samples.\n",
    "\n",
    "\n",
    "Random Forest and Gradient Boosting can use any algorithm, not just decision trees.(Answer)\n",
    "\n",
    "\n",
    "The final prediction of Random Forest uses a decision tree and is an average of all generated bootstrap samples, while the final prediction of Gradient Boosting is a weighted average of the generated weak learners and can use any algorithm.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's correct! While GB can use any algorithm, RF uses decision trees!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loan_data.drop('Loan Status', axis=1)\n",
    "y = loan_data['Loan Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7154\n",
      "Confusion matrix:\n",
      " [[  674  3561]\n",
      " [  708 10057]]\n",
      "Precision: 0.7385078572477604\n",
      "Recall: 0.9342313051555968\n",
      "F1: 0.8249190009432802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nAmazing! Now you'll compare these metrics to a Gradient Boosting model in the next exercise!\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 11\n",
    "\n",
    "\"\"\"\n",
    "Random forest ensemble\n",
    "\n",
    "Questions about ensemble models are common in a machine learning interview. If you're provided with a dataset and asked to build a highly accurate model, you will likely want to consider these more complex models.\n",
    "\n",
    "Your challenge in the remainder of this last lesson in the course is to create and compare two different ensemble models for loan_data.\n",
    "\n",
    "In this exercise, you will create a Random Forest Classifier model and compare its performance metrics to the model in the next exercise.\n",
    "\n",
    "The data has already been split is available in your workspace as X_train, X_test, y_train, and y_test.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the modules to create a Random Forest model and create a confusion matrix, accuracy, precision, recall, and F1-scores.\n",
    "    Instantiate a RF classifier and set the appropriate argument to generate 50 estimators.\n",
    "---\n",
    "\n",
    "    Fit the data to the instantiated Random Forest Classifier model object.\n",
    "---\n",
    "\n",
    "    Create predictions using the trained model object.\n",
    "---\n",
    "\n",
    "    Evaluate the model fit.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=123, oob_score = True)\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Random Forest Accuracy: {}\".format(accuracy_score(y_test, rf_pred)))\n",
    "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, rf_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, rf_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, rf_pred)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, rf_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Amazing! Now you'll compare these metrics to a Gradient Boosting model in the next exercise!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7176666666666667\n",
      "Confusion matrix:\n",
      " [[    0  4235]\n",
      " [    0 10765]]\n",
      "Precision: 0.7176666666666667\n",
      "Recall: 1.0\n",
      "F1: 0.8356297302542208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nOutstanding! You've learned how to effectively deal with missing data, avoid under or overfitting, apply transformations, among many other best practices in the step-by-step process of creating the best machine learning models. With continued practice, you will be able to ace your next Machine Learning Interview! Congratulations!\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 12\n",
    "\n",
    "\"\"\"\n",
    "Gradient boosting ensemble\n",
    "\n",
    "Boosting is a technique where the error of one predictor is passed as input to the next in a sequential manner. Gradient Boosting uses a gradient descent procedure to minimize the log loss for each subsequent classification tree added one at a time that, on their own, are weak decision models. Gradient Boosting for regression is similar, but uses a loss function such as mean squared error applied to gradient descent.\n",
    "\n",
    "In this exercise, you will create a Gradient Boosting Classifier model and compare its performance to the Random Forest from the previous exercise, which had an accuracy score of 72.5%.\n",
    "\n",
    "The loan_data DataFrame has already been split is available in your workspace as X_train, X_test, y_train, and y_test.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the modules to create a Gradient Boosting model and print out the confusion matrix, accuracy, precision, recall, and F1-scores.\n",
    "    Instantiate a GB classifier and set the appropriate argument to generate 50 estimators and with a learning rate of 0.01.\n",
    "---\n",
    "\n",
    "    Fit the data and create predictions.\n",
    "---\n",
    "\n",
    "    Evaluate the model fit by printing trained model evaluation metrics.\n",
    "---\n",
    "Question\n",
    "\n",
    "Pick the ensemble model that had the best accuracy.\n",
    "(RF)\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Instantiate, fit, predict\n",
    "gb_model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.01,random_state=123)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Gradient Boosting Accuracy: {}\".format(accuracy_score(y_test, gb_pred)))\n",
    "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, gb_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, gb_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, gb_pred)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, gb_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Outstanding! You've learned how to effectively deal with missing data, avoid under or overfitting, apply transformations, among many other best practices in the step-by-step process of creating the best machine learning models. With continued practice, you will be able to ace your next Machine Learning Interview! Congratulations!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
