{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How frequently is a function tested?\n",
    "\n",
    "Many data scientists do not think much about testing, and just do it in the manual way when necessary. But once you see the big picture i.e. the life cycle of a function over the entire project, you appreciate how important testing really is and how frequently you need to test things.\n",
    "\n",
    "Which of the following is true about testing?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    A function is tested just once during its life cycle, which is right after the first implementation.\n",
    "    \n",
    "    \n",
    "    A function is tested after the first implementation and then any time the function is modified, and this happens mainly when new bugs are found.\n",
    "    \n",
    "    \n",
    "    A function is tested after the first implementation and then any time the function is modified, which happens mainly when new bugs are found, new features are implemented or the code is refactored. {Answer}\n",
    "    \n",
    "    \n",
    "    A function is tested every time the function is executed.\n",
    "\n",
    "**Exactly! If the project goes on for a few years, you may end up testing the same function over a hundred times because of new bugs, new feature requests and refactoring!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_list(row):\n",
    "    row = row.rstrip()\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2:\n",
    "        return separated_entries\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_list_bugfix(row):\n",
    "    row = row.rstrip()\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2 and \"\" not in separated_entries:\n",
    "        return separated_entries    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_to_list\n",
      "['2,081', '314,942']\n",
      "['', '293,410']\n",
      "None\n",
      "\n",
      "row_to_list_bugfix\n",
      "['2,081', '314,942']\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWell done! Did you notice how manual testing involves repeating the same steps over and over in the IPython console? In this exercise, you just went through a single bug discovery and fixing phase. Just imagine doing this a hundred times over the entire life cycle of row_to_list(), including new feature implementation and refactoring phases! Unit testing can automate these repetitive steps, so that testing becomes easier, and you will learn it in the next lesson ;-)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Manual testing\n",
    "\n",
    "The function row_to_list(), which you met in the video lesson, has the following expected return values for the arguments listed below.\n",
    "Argument \tExpected return value \tExplanation\n",
    "\n",
    "\"2,081\\t314,942\\n\" \t[\"2,081\", \"314,942\"] \tCorrect row format\n",
    "\"\\t293,410\\n\" \tNone \tMissing area\n",
    "\"1,463238,765\\n\" \tNone \tMissing tab separator\n",
    "\n",
    "row_to_list() has been defined and imported for you. Your job is to test the function manually in the IPython console.\n",
    "\n",
    "While testing manually, notice how many times you have to repeat the same steps! The point is to experience the inefficiency of manual testing.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "Call row_to_list() in the IPython console on the three arguments listed in the table. Do the actual return values match the expected return values listed in the table?\n",
    "Possible answers :\n",
    "    \n",
    "    Yes, the implementation returns the expected value in each case.\n",
    "    \n",
    "    No, the function returns None for the argument \"2,081\\t314,942\\n\" instead of the expected return value [\"2,081\", \"314,942\"].\n",
    "    \n",
    "    No. the function returns [\"\", \"293,410\"] for the argument \"\\t293,410\\n\" instead of the expected return value None. {Answer}\n",
    "    \n",
    "    No, the function returns False for the argument \"1,463238,765\\n\" instead of the expected return value None.\n",
    "---\n",
    "Question\n",
    "\n",
    "In the last step, you discovered a bug in our implementation of row_to_list(). Good job!\n",
    "\n",
    "We have implemented a corresponding bug fix in a new function row_to_list_bugfix(). Call row_to_list_bugfix() in the IPython console on the three arguments listed in the table. Do the actual return values now match the expected return values listed in the table?\n",
    "\n",
    "Possible answers:\n",
    "\n",
    "    Yes, the implementation returns the expected value in each case. {answer}\n",
    "    \n",
    "    No, the function returns None for the argument \"2,081\\t314,942\\n\" instead of the expected return value [\"2,081\", \"314,942\"].\n",
    "    \n",
    "    No. the function returns [\"\", \"293,410\"] for the argument \"\\t293,410\\n\" instead of the expected return value None.\n",
    "    \n",
    "    No, the function returns False for the argument \"1,463238,765\\n\" instead of the expected return value None..\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "values = [\"2,081\\t314,942\\n\", \"\\t293,410\\n\", \"1,463238,765\\n\"]\n",
    "\n",
    "print(\"row_to_list\")\n",
    "for i in values:\n",
    "    print(row_to_list(i))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "print(\"\\nrow_to_list_bugfix\")\n",
    "for i in values:\n",
    "    print(row_to_list_bugfix(i))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! Did you notice how manual testing involves repeating the same steps over and over in the IPython console? In this exercise, you just went through a single bug discovery and fixing phase. Just imagine doing this a hundred times over the entire life cycle of row_to_list(), including new feature implementation and refactoring phases! Unit testing can automate these repetitive steps, so that testing becomes easier, and you will learn it in the next lesson ;-)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou just wrote your first unit test using pytest. Congratulations! A unit test takes 5 minutes to write, but saves you many hours in the future.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Your first unit test using pytest\n",
    "\n",
    "The data file containing housing area and prices uses commas as thousands separators, e.g. \"2,081\" or \"314,942\", as you can see in the IPython Shell.\n",
    "\n",
    "The convert_to_int() function takes a comma separated integer string as argument, and returns the integer. Therefore, the expected return value of convert_to_int(\"2,081\") is the integer 2081.\n",
    "\n",
    "This function is defined in the module preprocessing_helpers.py. But it is not known if the function is working properly.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the pytest package.\n",
    "---\n",
    "\n",
    "    Import the function convert_to_int().\n",
    "---\n",
    "\n",
    "    Complete the name of the unit test by adding the prefix which pytest uses to distinguish unit tests from ordinary functions.\n",
    "---\n",
    "\n",
    "    Complete the assert statement to check if convert_to_int() returns the expected value for the argument \"2,081\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import the pytest package\n",
    "import pytest\n",
    "\n",
    "# Import the function convert_to_int()\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "# Complete the unit test name by adding a prefix\n",
    "def test_on_string_with_one_comma():\n",
    "  # Complete the assert statement\n",
    "  assert convert_to_int(\"2,081\") == 2081\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You just wrote your first unit test using pytest. Congratulations! A unit test takes 5 minutes to write, but saves you many hours in the future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What causes a unit test to fail?\n",
    "\n",
    "In the test result report, the character ., as shown below, stands for a passing test. A passing test is good news as it means that your function works as expected. The character F stands for a failing test. A failing test is bad news as this means that something is broken.\n",
    "\n",
    "test_row_to_list.py .F.                                                  [100%]\n",
    "\n",
    "Which of the following describes best why a unit test fails?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    The assert statement passes.\n",
    "    \n",
    "    \n",
    "    The assert statement cannot be run because an exception is raised while running the unit test code.\n",
    "    \n",
    "    \n",
    "    The assert statement raises an AssertionError.\n",
    "    \n",
    "    \n",
    "    An exception is raised when running the unit test. This could be an AssertionError raised by the assert statement or another exception, e.g. NameError, which is raised before the assert statement can run. {Answer}\n",
    "\n",
    "**Exactly! If you get an AssertionError, this means the function has a bug and you should fix it. If you get another exception, e.g. NameError, this means that something else is wrong with the unit test code and you should fix it so that the assert statement can actually run.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0\n",
      "rootdir: /home/nero/Documents/Estudos/DataCamp/Python/courses/unit-testing-for-data-science-in-python/scripts\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_convert_to_int.py \u001b[31mF\u001b[0m\u001b[31m                                                 [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________ test_on_string_with_one_comma _________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_on_string_with_one_comma\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">     \u001b[94massert\u001b[39;49;00m convert_to_int(\u001b[33m\"\u001b[39;49;00m\u001b[33m2,081\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[94m2081\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE     AssertionError: assert '2081' == 2081\u001b[0m\n",
      "\u001b[1m\u001b[31mE      +  where '2081' = convert_to_int('2,081')\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_convert_to_int.py\u001b[0m:6: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_convert_to_int.py::\u001b[1mtest_on_string_with_one_comma\u001b[0m - AssertionError: assert '2081' == 2081\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.04s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood work! Your boss and colleagues are going to really appreciate your new skill of reading test result reports, and then spotting and fixing the bugs, because this would mean fewer bugs in the code base in the long term.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Spotting and fixing bugs\n",
    "\n",
    "To find bugs in functions, you need to follow a four step procedure.\n",
    "\n",
    "    1.Write unit tests.\n",
    "    2.Run them.\n",
    "    3.Read the test result report and spot the bugs.\n",
    "    4.Fix the bugs.\n",
    "\n",
    "In a previous exercise, you wrote a unit test for the function convert_to_int(), which is supposed to convert a comma separated integer string like \"2,081\" to the integer 2081. You also ran the unit test and discovered that it is failing.\n",
    "\n",
    "In this exercise, you will read the test result report from that exercise in detail, and then spot and fix the bug. This would equip you with all basic skills to start using unit tests for your projects.\n",
    "\n",
    "The convert_to_int() function is defined in the file preprocessing_helpers.py. The unit test is available in the test module test_convert_to_int.py.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "Run the unit test in the test module test_convert_to_int.py in the IPython console. Read the test result report and spot the bug.\n",
    "\n",
    "Which of the following describes the bug in the function convert_to_int(), if any?\n",
    "Possible answers:\n",
    "\n",
    "    convert_to_int(\"2,081\") is expected to return the string \"2081\", but it is actually returning the integer 2081.\n",
    "\n",
    "    convert_to_int(\"2,081\") is expected to return the integer 2081, but it is actually returning the string \"2081\". {Answer}\n",
    "    \n",
    "    convert_to_int(\"2,081\") is expected to return the integer 2081, but it is actually returning the string \"2,081\".\n",
    "    \n",
    "    The function convert_to_int() does not have a bug.\n",
    "---\n",
    "\n",
    "    Fix the convert_to_int() function so that it returns the integer 2081 instead of the string \"2081\" for the argument \"2,081\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "!pytest test_convert_to_int.py\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "def convert_to_int(string_with_comma):\n",
    "    # Fix this line so that it returns an int, not a str\n",
    "    return int(string_with_comma.replace(\",\", \"\"))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work! Your boss and colleagues are going to really appreciate your new skill of reading test result reports, and then spotting and fixing the bugs, because this would mean fewer bugs in the code base in the long term.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of unit testing\n",
    "\n",
    "You have been invited to a meeting where company executives are discussing whether developers should write unit tests. The CEO is unsure, and asks you about the benefits that unit testing might bring. In your response, which of the following benefits should you include?\n",
    "\n",
    "    Time savings, leading to faster development of new features.\n",
    "    Better user experience due to faster code execution.\n",
    "    Improved documentation, which will help new colleagues understand the code base better.\n",
    "    More user trust in the software product.\n",
    "    Better user experience due to improved visualizations.\n",
    "    Better user experience due to reduced downtime.\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    1, 2, 4 and 6.\n",
    "    \n",
    "    \n",
    "    1, 2, 3, 4 and 5.\n",
    "    \n",
    "    \n",
    "    1, 3, 4 and 6. {Answer}\n",
    "    \n",
    "    \n",
    "    All of them i.e. 1-6.\n",
    "\n",
    "**You steered the CEO in the right direction! Time savings and reduced downtime are the major benefits of unit testing, while improved documentation and more user trust are great side effects.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests as documentation\n",
    "\n",
    "Assume that you are a new collaborator of our linear regression project on housing area and prices.\n",
    "\n",
    "While inspecting the project, you come across a function mystery_function() in the feature module. You want to figure out what this function does. As you know, reading the unit tests might give you the answer quickly!\n",
    "\n",
    "The unit tests for the function is available in the test module test_mystery_function.py. You can read it, and any other file that you encounter, by using the !cat command in the IPython shell.\n",
    "\n",
    "Having read the unit tests, can you guess what mystery_function() does?\n",
    "\n",
    "### Possible answers\n",
    "It converts data in a data file into a NumPy array. {Answer}\n",
    "It slices a NumPy array and returns the first two rows.\n",
    "It checks if data in a data file is clean. If clean, it returns True. If dirty, it returns False.\n",
    "\n",
    "**You guessed it right and you didn't even take a look at the function definition! This is why - when onboarding new colleagues - it is a good idea to tell them to look at the unit tests if they are not sure about a function's purpose. In Chapter 2, you will see more functions from the feature and models module, and write more advanced unit tests using new pytest features.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
