{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThat's right! It is a lot easier to understand the custom message that you wrote than the automatic messages that pytest prints. Therefore, it is recommended that you add custom failure messages to all assert statements that you write in the future.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Write an informative test failure message\n",
    "\n",
    "The test result reports become a lot easier to read when you make good use of the optional message argument of the assert statement.\n",
    "\n",
    "In a previous exercise, you wrote a test for the convert_to_int() function. The function takes an integer valued string with commas as thousand separators e.g. \"2,081\" as argument and should return the integer 2081.\n",
    "\n",
    "In this exercise, you will rewrite the test called test_on_string_with_one_comma() so that it prints an informative message if the test fails.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Format the message string so that it shows the actual return value.\n",
    "---\n",
    "\n",
    "    Write the assert statement that checks if actual is equal to expected and prints the message message if they are not equal.\n",
    "---\n",
    "Question\n",
    "\n",
    "The test that you wrote was written to a test module called test_convert_to_int.py. Run the test in the IPython console and read the test result report.\n",
    "\n",
    "Which of the following is true?\n",
    "Possible answers\n",
    "\n",
    "    The test passes.\n",
    "    \n",
    "    The test fails because convert_to_int(\"2,081\") returns the string \"2081\" and not the integer 2081.\n",
    "    \n",
    "    The test fails because convert_to_int(\"2,081\") returns None and not the integer 2081. {Answer}\n",
    "    \n",
    "    The test fails because of a SyntaxError in the test code.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "def test_on_string_with_one_comma():\n",
    "    test_argument = \"2,081\"\n",
    "    expected = 2081\n",
    "    actual = convert_to_int(test_argument)\n",
    "    # Format the string with the actual return value\n",
    "    message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
    "    # Write the assert statement which prints message on failure\n",
    "    assert actual == expected, message\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's right! It is a lot easier to understand the custom message that you wrote than the automatic messages that pytest prints. Therefore, it is recommended that you add custom failure messages to all assert statements that you write in the future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWell done! The pytest.approx() function not only works for NumPy arrays containing floats, but also for lists and dictionaries containing floats.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Testing float return values\n",
    "\n",
    "The get_data_as_numpy_array() function (which was called mystery_function() in one of the previous exercises) takes two arguments: the path to a clean data file and the number of data columns in the file . An example file has been printed out in the IPython console. It contains three rows.\n",
    "\n",
    "The function converts the data into a 3x2 NumPy array with dtype=float64. The expected return value has been stored in a variable called expected. Print it out to see it.\n",
    "\n",
    "The housing areas are in the first column and the housing prices are in the second column. This array will be the features that will be fed to the linear regression model for learning.\n",
    "\n",
    "The return value contains floats. Therefore you have to be especially careful when writing unit tests for this function.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the assert statement to check if get_data_as_numpy_array() returns expected, when called on example_clean_data_file.txt with num_columns set to 2.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "from as_numpy import get_data_as_numpy_array\n",
    "\n",
    "def test_on_clean_file():\n",
    "  expected = np.array([[2081.0, 314942.0],\n",
    "                       [1059.0, 186606.0],\n",
    "  \t\t\t\t\t   [1148.0, 206186.0]\n",
    "                       ]\n",
    "                      )\n",
    "  actual = get_data_as_numpy_array(\"example_clean_data.txt\", num_columns=2)\n",
    "  message = \"Expected return value: {0}, Actual return value: {1}\".format(expected, actual)\n",
    "  # Complete the assert statement\n",
    "  assert actual == pytest.approx(expected), message\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! The pytest.approx() function not only works for NumPy arrays containing floats, but also for lists and dictionaries containing floats.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWell done! You seem to have mastered the art of writing assert statements. This test will pass only if both assertions pass. It will fail if any one of them raises an AssertionError.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Testing with multiple assert statements\n",
    "\n",
    "You're now going to test the function split_into_training_and_testing_sets() from the models module.\n",
    "\n",
    "It takes a n x 2 NumPy array containing housing area and prices as argument. To see an example argument, print the variable example_argument in the IPython console.\n",
    "\n",
    "The function returns a 2-tuple of NumPy arrays (training_set, testing_set). The training set contains int(0.75 * n) (approx. 75%) randomly selected rows of the argument array. The testing set contains the remaining rows.\n",
    "\n",
    "Print the variable expected_return_value in the IPython console. example_argument had 6 rows. Therefore the training array has int(0.75 * 6) = 4 of its rows and the testing array has the remaining 2 rows.\n",
    "\n",
    "numpy as np, pytest and split_into_training_and_testing_sets have been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Calculate the expected number of rows of the training array using the formula int(0.75*n), where n is the number of rows in example_argument, and assign the variable expected_training_array_num_rows to this number.\n",
    "---\n",
    "\n",
    "    Calculate the expected number of rows of the testing array using the formula n - int(0.75*n), where n is the number of rows in example_argument, and assign the variable expected_testing_array_num_rows to this number.\n",
    "---\n",
    "\n",
    "    Write an assert statement that checks if training array has expected_training_array_num_rows rows.\n",
    "---\n",
    "\n",
    "    Write an assert statement that checks if testing array has expected_testing_array_num_rows rows.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def test_on_six_rows():\n",
    "    example_argument = np.array([[2081.0, 314942.0], [1059.0, 186606.0],\n",
    "                                 [1148.0, 206186.0], [1506.0, 248419.0],\n",
    "                                 [1210.0, 214114.0], [1697.0, 277794.0]]\n",
    "                                )\n",
    "    # Fill in with training array's expected number of rows\n",
    "    expected_training_array_num_rows = 4\n",
    "    # Fill in with testing array's expected number of rows\n",
    "    expected_testing_array_num_rows = 2\n",
    "    actual = split_into_training_and_testing_sets(example_argument)\n",
    "    # Write the assert statement checking training array's number of rows\n",
    "    assert actual[0].shape[0] == expected_training_array_num_rows, \"The actual number of rows in the training array is not {}\".format(expected_training_array_num_rows)\n",
    "    # Write the assert statement checking testing array's number of rows\n",
    "    assert actual[1].shape[0] == expected_testing_array_num_rows, \"The actual number of rows in the testing array is not {}\".format(expected_testing_array_num_rows)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! You seem to have mastered the art of writing assert statements. This test will pass only if both assertions pass. It will fail if any one of them raises an AssertionError.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest raised an exception because no OSError was raised in the context.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWell done! In the next exercise, you will apply our knowledge of pytest.raises() to write a unit test for a function in the example linear regression project.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Practice the context manager\n",
    "\n",
    "In pytest, you can test whether a function raises an exception by using a context manager. Let's practice your understanding of this important context manager, the with statement and the as clause.\n",
    "\n",
    "At any step, feel free to run the code by pressing the \"Run Code\" button and check if the output matches your expectations.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the with statement by filling in with a context manager that will silence the ValueError raised in the context.\n",
    "---\n",
    "    Complete the with statement with a context manager that raises Failed if no OSError is raised in the context.\n",
    "---\n",
    "    Extend the with statement so that any raised ValueError is stored in the variable exc_info.\n",
    "---\n",
    "    Write an assert statement to check if the raised ValueError contains the message \"Silence me!\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import pytest\n",
    "\n",
    "# Fill in with a context manager that will silence the ValueError\n",
    "with pytest.raises(ValueError):\n",
    "    raise ValueError\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "import pytest\n",
    "\n",
    "try:\n",
    "    # Fill in with a context manager that raises Failed if no OSError is raised\n",
    "    with pytest.raises(OSError):\n",
    "        raise ValueError\n",
    "except:\n",
    "    print(\"pytest raised an exception because no OSError was raised in the context.\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "import pytest\n",
    "\n",
    "# Store the raised ValueError in the variable exc_info\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    raise ValueError(\"Silence me!\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "import pytest\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    raise ValueError(\"Silence me!\")\n",
    "# Check if the raised ValueError contains the correct message\n",
    "assert exc_info.match(\"Silence me!\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! In the next exercise, you will apply our knowledge of pytest.raises() to write a unit test for a function in the example linear regression project.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0\n",
      "rootdir: /home/nero/Documents/Estudos/DataCamp/Python/courses/unit-testing-for-data-science-in-python/scripts\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_split_into_training_and_testing_sets.py \u001b[32m.\u001b[0m\u001b[32m                           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.10s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThat's correct! Congratulations on writing your first unit test that checks for exceptions. In the next lesson, you will find out that it is good practice to include a few tests of this type for every function that you test.\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Unit test a ValueError\n",
    "\n",
    "Sometimes, you want a function to raise an exception when called on bad arguments. This prevents the function from returning nonsense results or hard-to-interpret exceptions. This is an important behavior which should be unit tested.\n",
    "\n",
    "Remember the function split_into_training_and_testing_sets()? It takes a NumPy array containing housing area and prices as argument. The function randomly splits the array row wise into training and testing arrays in the ratio 3:1, and returns the resulting arrays in a tuple.\n",
    "\n",
    "If the argument array has only 1 row, the testing array will be empty. To avoid this situation, you want the function to not return anything, but raise a ValueError with the message \"Argument data_array must have at least 2 rows, it actually has just 1\".\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Fill in with the correct context manager that checks if split_into_training_and_testing_sets() raises a ValueError when called on test_argument, which is a NumPy array with a single row.\n",
    "---\n",
    " \n",
    "    Complete the with statement so that information about any raised ValueError will be stored in the variable exc_info.\n",
    "---\n",
    "\n",
    "    Write an assert statement to check if the raised ValueError contains the correct message stored in the variable expected_error_msg.\n",
    "---\n",
    "Question\n",
    "\n",
    "The test test_on_one_row() was written to the test module test_split_into_training_and_testing_sets.py. Run the test in the IPython console and read the test result report. Does the test pass or fail?\n",
    "Possible answers\n",
    "\n",
    "    The test passes. {Answer}\n",
    "    \n",
    "    The test fails because no ValueError is raised when split_into_training_and_testing_sets() is called on a NumPy array with 1 row.\n",
    "    \n",
    "    The test fails because the ValueError does not contain the correct error message.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\"\"\"import numpy as np\n",
    "import pytest\n",
    "from train import split_into_training_and_testing_sets\n",
    "\n",
    "def test_on_one_row():\n",
    "    test_argument = np.array([[1382.0, 390167.0]])\n",
    "    # Store information about raised ValueError in exc_info\n",
    "    with pytest.raises(ValueError) as exc_info:\n",
    "      split_into_training_and_testing_sets(test_argument)\n",
    "    expected_error_msg = \"Argument data_array must have at least 2 rows, it actually has just 1\"\n",
    "    # Check if the raised ValueError contains the correct message\n",
    "    assert exc_info.match(expected_error_msg)\"\"\"\n",
    "\n",
    "!pytest test_split_into_training_and_testing_sets.py\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's correct! Congratulations on writing your first unit test that checks for exceptions. In the next lesson, you will find out that it is good practice to include a few tests of this type for every function that you test.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFantastic! You just wrote tests for all the boundary values of row_to_list(). In the next exercise, you will write tests for some special values of row_to_list().\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Testing well: Boundary values\n",
    "\n",
    "Remember row_to_list()? It takes a row containing housing area and prices e.g. \"2,041\\t123,781\\n\" and returns the data as a list e.g. [\"2,041\", \"123,781\"].\n",
    "\n",
    "A row can be mapped to a 2-tuple (m, n), where m is the number of tab separators. n is 1 if the row has any missing values, and 0 otherwise.\n",
    "\n",
    "For example,\n",
    "\n",
    "    \"123\\t456\\n\" \n",
    "\n",
    "(1, 0).\n",
    "\"\\t456\\n\"\n",
    "(1, 1).\n",
    "\"\\t456\\t\\n\"\n",
    "\n",
    "    (2, 1).\n",
    "\n",
    "The function only returns a list for arguments mapping to (1, 0). All other tuples correspond to invalid rows, with either more than one tab or missing values. The function returns None in all these cases. See the plot.\n",
    "\n",
    "This mapping shows that the function has normal behavior at (1, 0), and special behavior everywhere else.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "Which are the boundary values for this function, according to the plot?\n",
    "Possible answers\n",
    "(1, 0).\n",
    "(0, 0) and (2, 0).\n",
    "(0, 0), (2, 0) and (1, 1). {Answer}\n",
    "(3, 0) and (3, 1).\n",
    "\n",
    "---\n",
    "\n",
    "    Assign actual to the return value of row_to_list() on the argument \"123\\n\", which is an instance of the boundary value (0, 0).\n",
    "---\n",
    "\n",
    "    Complete the assert statement to check if row_to_list() indeed returns None for the instance \"123\\t4,567\\t89\\n\" of the boundary value (2, 0).\n",
    "---\n",
    "\n",
    "    In the test test_on_one_tab_with_missing_value(), format the failure message with the actual return value.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import *\n",
    "\n",
    "def test_on_no_tab_no_missing_value():    # (0, 0) boundary value\n",
    "    # Assign actual to the return value for the argument \"123\\n\"\n",
    "    actual = row_to_list(\"123\\n\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_two_tabs_no_missing_value():    # (2, 0) boundary value\n",
    "    actual = row_to_list(\"123\\t4,567\\t89\\n\")\n",
    "    # Complete the assert statement\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_one_tab_with_missing_value():    # (1, 1) boundary value\n",
    "    actual = row_to_list(\"\\t4,567\\n\")\n",
    "    # Format the failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! You just wrote tests for all the boundary values of row_to_list(). In the next exercise, you will write tests for some special values of row_to_list().\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nKudos! You have now written tests for both boundary values and values triggering special logic for row_to_list(). In the next exercise, you will test normal arguments and then declare this function well tested!\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Testing well: Values triggering special logic\n",
    "\n",
    "Look at the plot. The boundary values of row_to_list() are now marked in orange. The normal argument is marked in green and the values triggering special behavior are marked in blue.\n",
    "\n",
    "In the last exercise, you wrote tests for boundary values. In this exercise, you are going to write tests for values triggering special behavior, in particular, (0, 1) and (2, 1). These are values triggering special logic since the function returns None instead of a list.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Assign the variable actual to the actual return value for \"\\n\".\n",
    "    \n",
    "    Complete the assert statement for test_on_no_tab_with_missing_value(),    \n",
    "    making sure to format the failure message appropriately.\n",
    "    \n",
    "    Assign the variable actual to the actual return value for \"123\\t\\t89\\n\".\n",
    "    \n",
    "    Complete the assert statement for test_on_two_tabs_with_missing_value(), \n",
    "    making sure to format the failure message appropriately.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import *\n",
    "\n",
    "def test_on_no_tab_with_missing_value():    # (0, 1) case\n",
    "    # Assign to the actual return value for the argument \"\\n\"\n",
    "    actual = row_to_list(\"\\n\")\n",
    "    # Write the assert statement with a failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_two_tabs_with_missing_value():    # (2, 1) case\n",
    "    # Assign to the actual return value for the argument \"123\\t\\t89\\n\"\n",
    "    actual = row_to_list(\"123\\t\\t89\\n\")\n",
    "    # Write the assert statement with a failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Kudos! You have now written tests for both boundary values and values triggering special logic for row_to_list(). In the next exercise, you will test normal arguments and then declare this function well tested!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWell done! You tested the function row_to_list() on boundary values, values triggering special behavior and normal arguments. All the tests are passing. So you can be quite confident that the function is correctly coded! Note that this function does not have bad arguments, so you did not write any tests for that. Also note how mapping the arguments to tuples enabled us to categorize the arguments easily. Use this trick for other functions whenever applicable ;-)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Testing well: Normal arguments\n",
    "\n",
    "This time, you will test row_to_list() with normal arguments i.e. arguments mapping to the tuple (1, 0). The plot is provided to you for reference.\n",
    "\n",
    "Remembering that the best practice is to test for two to three normal arguments, you will write two tests in this exercise.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Question\n",
    "\n",
    "How many normal arguments is it recommended to test?\n",
    "Possible answers\n",
    "    One.\n",
    "    \n",
    "    At least two or three.{Answer}\n",
    "    \n",
    "    None.\n",
    "---\n",
    "\n",
    "    Assign the variable expected to the expected return value for the normal argument \"123\\t4,567\\n\".\n",
    "---\n",
    "\n",
    "    Complete the correct assert statement for test_on_normal_argument_2(), making sure to format the failure message appropriately.\n",
    "---\n",
    "Question\n",
    "\n",
    "The tests for boundary values, values triggering special behavior and normal arguments have been written to a test module test_row_to_list.py. Run the tests in the IPython shell. Which bugs does the function have?\n",
    "Possible answers\n",
    "\n",
    "    The function does not have any bugs. {Answer}\n",
    "    \n",
    "    The function returns [\"\", \"4,567\"] for the boundary value \"\\t4,567\\n\" instead of None.\n",
    "    \n",
    "    The function raises a SyntaxError for the special value \"\\n\" instead of returning None.\n",
    "    \n",
    "    The function returns None for the normal argument \"123\\t4,567\\n\" instead of returning a list.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import *\n",
    "\n",
    "def test_on_normal_argument_1():\n",
    "    actual = row_to_list(\"123\\t4,567\\n\")\n",
    "    # Fill in with the expected return value for the argument \"123\\t4,567\\n\"\n",
    "    expected = [\"123\", \"4,567\"]\n",
    "    assert actual == expected, \"Expected: {0}, Actual: {1}\".format(expected, actual)\n",
    "    \n",
    "def test_on_normal_argument_2():\n",
    "    actual = row_to_list(\"1,059\\t186,606\\n\")\n",
    "    expected = [\"1,059\", \"186,606\"]\n",
    "    # Write the assert statement along with a failure message\n",
    "    assert actual == expected, \"Expected: {0}, Actual: {1}\".format(expected, actual)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! You tested the function row_to_list() on boundary values, values triggering special behavior and normal arguments. All the tests are passing. So you can be quite confident that the function is correctly coded! Note that this function does not have bad arguments, so you did not write any tests for that. Also note how mapping the arguments to tuples enabled us to categorize the arguments easily. Use this trick for other functions whenever applicable ;-)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAwesome! You wrote three tests for normal arguments of convert_to_int(). But wait...what happens if the arguments are not normal? The boss didn't say anything about that! Let's find out in the next exercise.\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "TDD: Tests for normal arguments\n",
    "\n",
    "In this and the following exercises, you will implement the function convert_to_int() using Test Driven Development (TDD). In TDD, you write the tests first and implement the function later.\n",
    "\n",
    "Normal arguments for convert_to_int() are integer strings with comma as thousand separators. Since the best practice is to test a function for two to three normal arguments, here are three examples with no comma, one comma and two commas respectively.\n",
    "Argument value \tExpected return value\n",
    "\"756\" \t756\n",
    "\"2,081\" \t2081\n",
    "\"1,034,891\" \t1034891\n",
    "\n",
    "Since the convert_to_int() function does not exist yet, you won't be able to import it. But you will use it in the tests anyway. That's how TDD works.\n",
    "\n",
    "pytest has already been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the assert statement for test_with_no_comma() by inserting the correct boolean expression.\n",
    "    \n",
    "    Complete the assert statement for test_with_one_comma() by inserting the correct boolean expression.\n",
    "    \n",
    "    Complete the assert statement for test_with_two_commas() by inserting the correct boolean expression.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def test_with_no_comma():\n",
    "    actual = convert_to_int(\"756\")\n",
    "    # Complete the assert statement\n",
    "    assert actual == 756, \"Expected: 756, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_with_one_comma():\n",
    "    actual = convert_to_int(\"2,081\")\n",
    "    # Complete the assert statement\n",
    "    assert actual == 2081, \"Expected: 2081, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_with_two_commas():\n",
    "    actual = convert_to_int(\"1,034,891\")\n",
    "    # Complete the assert statement\n",
    "    assert actual == 1034891, \"Expected: 1034891, Actual: {0}\".format(actual)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Awesome! You wrote three tests for normal arguments of convert_to_int(). But wait...what happens if the arguments are not normal? The boss didn't say anything about that! Let's find out in the next exercise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYes! In TDD, the first run of the tests always fails with a NameError or ImportError because the function does not exist yet. In the next exercise, you will implement the function and fix this. But before you move on, notice how thinking about special and bad arguments crystallized the requirements for the function. This will help us immensely in implementing the function in the coming exercise.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "TDD: Requirement collection\n",
    "\n",
    "What should convert_to_int() do if the arguments are not normal? In particular, there are three special argument types:\n",
    "\n",
    "   1. Arguments that are missing a comma e.g. \"178100,301\".\n",
    "   2. Arguments that have the comma in the wrong place e.g. \"12,72,891\".\n",
    "   3. Float valued strings e.g. \"23,816.92\".\n",
    "\n",
    "Also, should convert_to_int() raise an exception for specific argument values?\n",
    "\n",
    "When your boss asked you to implement the function, she didn't say anything about these cases! But since you want to write tests for special and bad arguments as a part of TDD, you go and ask your boss.\n",
    "\n",
    "She says that convert_to_int() should return None for every special argument and there are no bad arguments for this function.\n",
    "\n",
    "pytest has been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Give a name to the test by using the standard name prefix that pytest expects followed by on_string_with_missing_comma.\n",
    "    Assign actual to the actual return value for the argument \"12,72,891\".\n",
    "    Complete the assert statement.\n",
    "---\n",
    "Question\n",
    "\n",
    "The tests for normal and special arguments have been written to a test module test_convert_to_int.py. Run it in the IPython console and read the test result report. What happens?\n",
    "Possible answers\n",
    "\n",
    "    All tests are passing.\n",
    "    \n",
    "    The test test_on_string_with_two_commas() is failing because the convert_to_int(\"1,034,891\") returns None instead of the correct integer 1034891.\n",
    "    \n",
    "    All tests are failing with a NameError since convert_to_int() has not been implemented yet. {Answer}\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Give a name to the test for an argument with missing comma\n",
    "def test_on_string_with_missing_comma():\n",
    "    actual = convert_to_int(\"178100,301\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_string_with_incorrectly_placed_comma():\n",
    "    # Assign to the actual return value for the argument \"12,72,891\"\n",
    "    actual = convert_to_int(\"12,72,891\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_float_valued_string():\n",
    "    actual = convert_to_int(\"23,816.92\")\n",
    "    # Complete the assert statement\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Yes! In TDD, the first run of the tests always fails with a NameError or ImportError because the function does not exist yet. In the next exercise, you will implement the function and fix this. But before you move on, notice how thinking about special and bad arguments crystallized the requirements for the function. This will help us immensely in implementing the function in the coming exercise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYes! All tests are passing and you nailed the implementation! Congratulations are also due on finshing Chapter 2. You've learned a lot, and in the next Chapter, you will learn several best practices that will take your testing to the next level.\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 11\n",
    "\n",
    "\"\"\"\n",
    "TDD: Implement the function\n",
    "\n",
    "convert_to_int() returns None for the following:\n",
    "\n",
    "    Arguments with missing thousands comma e.g. \"178100,301\". If you split the string at the comma using \"178100,301\".split(\",\"), then the resulting list [\"178100\", \"301\"] will have at least one entry with length greater than 3 e.g. \"178100\".\n",
    "\n",
    "    Arguments with incorrectly placed comma e.g. \"12,72,891\". If you split this at the comma, then the resulting list is [\"12\", \"72\", \"891\"]. Note that the first entry is allowed to have any length between 1 and 3. But if any other entry has a length other than 3, like \"72\", then there's an incorrectly placed comma.\n",
    "\n",
    "    Float valued strings e.g. \"23,816.92\". If you remove the commas and call int() on this string i.e. int(\"23816.92\"), you will get a ValueError.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the if statement that checks if the i-th element of comma_separated_parts has length greater than 3.\n",
    "---\n",
    "\n",
    "    Complete the if statement that checks if any entry other than the 0-th entry of comma_separated_parts has a length not equal to 3.\n",
    "---\n",
    "\n",
    "    Fill in the except clause with a ValueError, which is raised when trying to convert float valued strings e.g. 23816.92 to an integer.\n",
    "---\n",
    "Question\n",
    "\n",
    "Now that you have implemented the convert_to_int() function, let's run the tests in the test module test_convert_to_int.py again. Run it the IPython console and read the test result report. Did you implement the function correctly, or are there any bugs?\n",
    "Possible answers\n",
    "    All tests are passing and the implementation does not have a bug. {Answer}\n",
    "    \n",
    "    The test test_on_string_with_incorrectly_placed_comma() is failing because the convert_to_int(\"12,72,891\") is returning 1272891 instead of None.\n",
    "    \n",
    "    All tests are failing with a NameError since convert_to_int() has not been implemented yet.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def convert_to_int(integer_string_with_commas):\n",
    "    comma_separated_parts = integer_string_with_commas.split(\",\")\n",
    "    for i in range(len(comma_separated_parts)):\n",
    "        # Write an if statement for checking missing commas\n",
    "        if len(comma_separated_parts[i]) > 3:\n",
    "            return None\n",
    "        # Write the if statement for incorrectly placed commas\n",
    "        if i != 0 and len(comma_separated_parts[i]) != 3:\n",
    "            return None\n",
    "    integer_string_without_commas = \"\".join(comma_separated_parts)\n",
    "    try:\n",
    "        return int(integer_string_without_commas)\n",
    "    # Fill in with a ValueError\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Yes! All tests are passing and you nailed the implementation! Congratulations are also due on finshing Chapter 2. You've learned a lot, and in the next Chapter, you will learn several best practices that will take your testing to the next level.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
