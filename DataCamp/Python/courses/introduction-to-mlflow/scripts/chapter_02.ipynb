{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv(path_data+'50_Startups.csv')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "X['State'] = encoder.fit_transform(X['State'])\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X,y, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore the FutureWarning and UserWarning warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/07 08:25:45 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '79411bbb14d24e4887cd50676525ac90', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58446.4113765]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nAwesome! Packaging an ML model using MLflow is simple. It's even more simple if you use a built-in flavor that supports autologging.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Package a machine learning model\n",
    "\n",
    "In this exercise, you will train a LinearRegression model from scikit-learn to predict profit of a Unicorn Company.\n",
    "\n",
    "You will use MLflow's built-in scikit-learn Flavor to package the model. You will use the Flavor's auto logging function to automatically log metrics, parameters and the model to MLflow Tracking when the fit estimator is called.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Import the sklearn Flavor from the mlflow module.\n",
    "    Set the Experiment to \"Sklearn Model\".\n",
    "    Use auto logging from the flavor to package your model.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import Scikit-learn flavor\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set the experiment to \"Sklearn Model\"\n",
    "mlflow.set_experiment(\"Sklearn Model\")\n",
    "\n",
    "# Set Auto logging for Scikit-learn flavor \n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Get a prediction from test data\n",
    "print(lr.predict(X_test.iloc[[5]]))\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Awesome! Packaging an ML model using MLflow is simple. It's even more simple if you use a built-in flavor that supports autologging.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Format\n",
    "\n",
    "MLflow uses a specific storage format in order to standardize the way models are packaged. Which of the following artifacts can be found in the directory structure for MLflow's storage format? \n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "        MLmodel{Answer}\n",
    "\n",
    "\n",
    "        model.pkl{Answer}\n",
    "\n",
    "\n",
    "        mlflow_version.txt\n",
    "\n",
    "\n",
    "        python_env.yaml{Answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path: model\n",
      "flavors:\n",
      "  python_function:\n",
      "    env:\n",
      "      conda: conda.yaml\n",
      "      virtualenv: python_env.yaml\n",
      "    loader_module: mlflow.sklearn\n",
      "    model_path: model.pkl\n",
      "    predict_fn: predict\n",
      "    python_version: 3.12.3\n",
      "  sklearn:\n",
      "    code: null\n",
      "    pickled_model: model.pkl\n",
      "    serialization_format: cloudpickle\n",
      "    sklearn_version: 1.4.2\n",
      "mlflow_version: 2.12.1\n",
      "model_size_bytes: 609\n",
      "model_uuid: eded09afb08245108c43e46e1059c029\n",
      "run_id: 9dddc9eaff20448ea2e2fa462cea2ce6\n",
      "signature:\n",
      "  inputs: '[{\"type\": \"double\", \"name\": \"R&D Spend\", \"required\": true}, {\"type\": \"double\",\n",
      "    \"name\": \"Administration\", \"required\": true}, {\"type\": \"double\", \"name\": \"Marketing\n",
      "    Spend\", \"required\": true}, {\"type\": \"long\", \"name\": \"State\", \"required\": true}]'\n",
      "  outputs: '[{\"type\": \"tensor\", \"tensor-spec\": {\"dtype\": \"float64\", \"shape\": [-1]}}]'\n",
      "  params: null\n",
      "utc_time_created: '2024-05-07 11:19:38.433178'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat! MLmodel provides information about Python, the path to the model and Flavors used in order to load the model.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "What's in an MLmodel file?\n",
    "\n",
    "You learned that the MLmodel file is used to define specific information about how our models can be loaded and integrated with existing ML tools.\n",
    "\n",
    "An MLmodel file has been set to a variable called \"mlmodel\". Use the print(mlmodel) in the IPython Shell to view the contents of the file.\n",
    "\n",
    "Which of the following is information found within the MLmodel file?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    Cloud provider, hardware, ML libraries\n",
    "    \n",
    "    Python environment, model path, Flavors, Python version {Answer}\n",
    "    \n",
    "    Model version, model path, model author, Python version\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "with open('mlruns/562345919476994573/9dddc9eaff20448ea2e2fa462cea2ce6/artifacts/model/MLmodel') as file:\n",
    "    print(file.read())\n",
    "    file.close()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! MLmodel provides information about Python, the path to the model and Flavors used in order to load the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Saving and loading a model\n",
    "\n",
    "With the Model API, models can be shared between developers who may not have access to the same MLflow Tracking server by using a local filesystem.\n",
    "\n",
    "In this exercise, you will train a new LinearRegression model from an existing one using the Unicorn dataset. First, you will load an existing model from the local filesystem. Then you will train a new model from the existing model and save it back to the local filesystem.\n",
    "\n",
    "The existing model has been saved to the local filesystem in a directory called \"lr_local_v1\". The mlflow module will be imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Load the model from the local filesystem directory \"lr_local_v1\" using scikit-learn library from the MLflow module.\n",
    "\n",
    "    Using the scikit-learn library from the mlflow module, save the model locally to a directory called \"lr_local_v2\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Load model from local filesystem\n",
    "model = mlflow.sklearn.load_model(\"lr_local_v1\")\n",
    "\n",
    "# Training Data\n",
    "X = df[[\"R&D Spend\", \"Administration\", \"Marketing Spend\", \"State\"]]\n",
    "y = df[[\"Profit\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,random_state=0)\n",
    "# Train Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model to local filesystem\n",
    "mlflow.sklearn.save_model(model, \"lr_local_v2\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good! The save_model() function is used when saving a model locally and can provide a way for developers to share models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Logging and loading a model\n",
    "\n",
    "The Model API provides a way to interact with our models by logging and loading them directly from MLflow Tracking in a standardized manner. Being able to interact with models is crucial during the ML lifecycle for the Model Engineering and Model Evaluation steps.\n",
    "\n",
    "In this exercise you will create a Linear Regression model from scikit-learn using the Unicorn dataset. This model will be logged to MLflow Tracking and then loaded using the run_id used to log the artifact.\n",
    "\n",
    "First, you will log the model using the scikit-learn library from the MLflow module. Then you will load the model from MLflow Tracking using the run_id.\n",
    "\n",
    "The model will be trained and have the name lr_model.\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "The mlflow module will be imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Log the model to MLflow Tracking under the artifact path of \"lr_tracking\".\n",
    "\n",
    "    Create a variable called run that is set to the last run.\n",
    "\n",
    "    Create another variable called run_id that is set to the run_id of the run variable.\n",
    "\n",
    "    Load the model using the run_id and the artifact path used to log the model.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Log model to MLflow Tracking\n",
    "mlflow.sklearn.log_model(lr_model, \"lr_tracking\")\n",
    "\n",
    "# Get the last run\n",
    "run = mlflow.last_active_run()\n",
    "\n",
    "# Get the run_id of the above run\n",
    "run_id = run.info.run_id\n",
    "\n",
    "# Load model from MLflow Tracking\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{run_id}/lr_tracking\")\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great Job! The log_model() function is used to save a model to an MLflow Tracking server and can be loaded by its run_id.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Creating a custom Python Class\n",
    "\n",
    "MLflow provides a way to create custom models in order to provide a way to support a wide variety of use cases. To create custom models, MLflow allows for users to create a Python Class which inherits mlflow.pyfunc.PythonModel Class. The PythonModel Class provides customization by providing methods for custom inference logic and artifact dependencies.\n",
    "\n",
    "In this exercise, you will create a new Python Class for a custom model that loads a specific model and then decodes labels after inference. The mlflow module will be imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a Python Class with the name CustomPredict.\n",
    "\n",
    "    Define the load_context() method used for loading artifacts within a custom Class.\n",
    "\n",
    "    Define the predict() method for defining custom inference.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create Python Class\n",
    "class CustomPredict(mlflow.pyfunc.PythonModel):\n",
    "    # Set method for loading model\n",
    "    def load_context(self, context):\n",
    "        self.model = mlflow.sklearn.load_model(\"./lr_model/\")\n",
    "    # Set method for custom inference     \n",
    "    def predict(self, context, model_input):\n",
    "        predictions = self.model.predict(model_input)\n",
    "        decoded_predictions = []  \n",
    "        for prediction in predictions:\n",
    "            if prediction == 0:\n",
    "                decoded_predictions.append(\"female\")\n",
    "            else:\n",
    "                decoded_predictions.append(\"male\")\n",
    "        return decoded_predictions\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! Python Classes provide a blueprint for objects and allow for access to methods in order to manipulate them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Custom scikit-learn model\n",
    "\n",
    "In this exercise you are going to create a custom model using MLflow's pyfunc flavor. Using the insurance_charges dataset, the labels must be changed from female to 0 and male to 1 for classification during training. When using the model, the strings of female or male must be returned instead of 0 or 1.\n",
    "\n",
    "The custom model is a Classification model based on LogisticRegression and will use a Class called CustomPredict. The CustomPredict adds an additional step in the the predict method that sets your labels of 0 and 1 back to female and male when the model receives input. You will be using pyfunc flavor for logging and loading your model.\n",
    "\n",
    "Our insurance_charges dataset will be preprocessed and model will be trained using:\n",
    "\n",
    "lr_model = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "The MLflow module will be imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Use MLflow's pyfunc flavor to log the custom model.\n",
    "\n",
    "    Set pyfunc python_model argument to use the Custom Class CustomPredict().\n",
    "\n",
    "    Load the custom model using pyfunc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Log the pyfunc model \n",
    "mlflow.pyfunc.log_model(\n",
    "\tartifact_path=\"lr_pyfunc\", \n",
    "    # Set model to use CustomPredict Class\n",
    "\tpython_model=CustomPredict(), \n",
    "\tartifacts={\"lr_model\": \"lr_model\"}\n",
    ")\n",
    "\n",
    "run = mlflow.last_active_run()\n",
    "run_id = run.info.run_id\n",
    "\n",
    "# Load the model in python_function format\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/lr_pyfunc\")\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice job! Custom Python models allows for users to cover a much wider range of use cases and provides more flexibility.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Scikit-learn flavor and evaluation\n",
    "\n",
    "In this exercise you will train a classification model and evaluates its performance. The model uses your Insurance Charges dataset in order to classify if the charges were for a female or male.\n",
    "\n",
    "We will start by logging our model to MLflow Tracking using the scikit-learn flavor and finish by evaluating your model using an eval_data dataset.\n",
    "\n",
    "Your evaluation dataset is created as eval_data and our model trained with the name lr_class. The eval_data will consist of X_test and y_test as the training data was split using train_test_split() function from sklearn.\n",
    "\n",
    "# Model\n",
    "lr_class = LogisticRegression()\n",
    "lr_class.fit(X_train, y_train)\n",
    "\n",
    "The mlflow module is imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Log the lr_class model using scikit-learn \"built-in\" flavor.\n",
    "\n",
    "    Call the evaluate() function from mlflow module.\n",
    "\n",
    "    Evaluate the eval_data dataset and target the \"sex\" column.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Eval Data\n",
    "eval_data = X_test\n",
    "eval_data[\"sex\"] = y_test\n",
    "# Log the lr_class model using Scikit-Learn Flavor\n",
    "mlflow.sklearn.log_model(lr_class, \"model\")\n",
    "\n",
    "# Get run id\n",
    "run = mlflow.last_active_run()\n",
    "run_id = run.info.run_id\n",
    "\n",
    "# Evaluate the logged model with eval_data data\n",
    "mlflow.evaluate(f\"runs:/{run_id}/model\", \n",
    "        data=eval_data, \n",
    "        targets=\"sex\",\n",
    "        model_type=\"classifier\"\n",
    ")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! Evaluating your model plays an integral part in understandin gmodel performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a model\n",
    "\n",
    "Model deployment is another important step of the ML Lifecycle. The MLflow command line interface includes a command for serving models. Models can be deployed with MLflow from the local filesystem, from MLflow Tracking, and from several cloud providers such as AWS S3.\n",
    "\n",
    "To serve a model from MLflow Tracking using its run_id, which of the following commands is used to serve the model?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    mlflow serve models -m runs:/7de9bbe306224c2c9842beb11357d084/model\n",
    "    \n",
    "    \n",
    "    mlflow models serve -m runs:/7de9bbe306224c2c9842beb11357d084/model {Answer}\n",
    "    \n",
    "    \n",
    "    mlflow models serve -m run_id:/7de9bbe306224c2c9842beb11357d084/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score from a served model\n",
    "\n",
    "Once a model has been served with mlflow serve command line interface command, which of the following curl commands would be used to get retrieve a score for a JSON input using dataframe_split type?\n",
    "\n",
    "### Possible Answers\n",
    "Select one answer\n",
    "\n",
    "    curl -d '{\"dataframe_split\": {\"columns\": [\"x\"], \"data\": [[10]]}}' -H 'Content-Type: application/json' -X POST localhost:5000/ping\n",
    "    \n",
    "    \n",
    "    curl -d '{\"column\": [10]\"}' -H 'Content-Type: application/json' -X POST localhost:5000/inference\n",
    "    \n",
    "    \n",
    "    curl -d '{\"dataframe_split\": {\"columns\": [\"x\"], \"data\": [[10]]}}' -H 'Content-Type: application/json' -X POST localhost:5000/invocations {Answer}\n",
    "\n",
    "**Correct! Your input uses JSON and dataframe_split orientation as well as the correct invocations endpoint.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
