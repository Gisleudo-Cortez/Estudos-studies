{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of MLflow\n",
    "\n",
    "MLflow is a platform used to simplify the Machine Learning Lifecycle and consists of four major components. What are the four major components of MLflow?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "    MLflow Tracking{Answer}\n",
    "\n",
    "\n",
    "    MLflow Models{Answer}\n",
    "\n",
    "\n",
    "    MLflow Pipelines\n",
    "\n",
    "\n",
    "    MLflow Model Registry{Answer}\n",
    "\n",
    "\n",
    "    MLflow Projects{Answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGreat! Now that you have created an experiment in MLflow, the ML project will be well organized!\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "MLflow experiments\n",
    "\n",
    "MLflow experiments are used as a way to organize data from training runs in a way that can be easily searched and queried for our analysis later.\n",
    "\n",
    "In this exercise, you will use the MLflow module to create a new experiment called Unicorn Model for your new ML project. You will add useful information to the experiment by setting tags for the version. Finally, you will set the Unicorn Model experiment as your current experiment so when you begin tracking your data will be tracked within this particular experiment.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    Import the MLflow module.\n",
    "\n",
    "    Create a new experiment called \"Unicorn Model\".\n",
    "\n",
    "    On the Unicorn Model, set the set the tags as \"version\" and \"1.0\".\n",
    "\n",
    "    Set the experiment \"Unicorn Model\" as the current experiment for tracking.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import MLflow\n",
    "import mlflow\n",
    "\n",
    "# Create new experiment\n",
    "mlflow.create_experiment(\"Unicorn Model\")\n",
    "\n",
    "# Tag new experiment\n",
    "mlflow.set_experiment_tag(\"version\", \"1.0\")\n",
    "\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(\"Unicorn Model\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! Now that you have created an experiment in MLflow, the ML project will be well organized!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Starting a run\n",
    "\n",
    "MLflow uses the concept of a run as a way to organize model training. Before metrics, parameters or artifacts can be logged to MLflow Tracking, a run must become active. Each run must also belong to an existing experiment.\n",
    "\n",
    "In the following exercise, you will start a new run so that you can begin logging a model. You will also set the experiment in which you would like the run to be logged. The mlflow module will already be imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Set the experiment so that the active run tracks to \"Unicorn Sklearn Experiment\" experiment.\n",
    "    Start a new run with mlflow module.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(\"Unicorn Sklearn Experiment\")\n",
    "\n",
    "# Start a run\n",
    "mlflow.start_run() \n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! In order to begin logging to MLflow, a run must become active under a specified experiment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Logging a run\n",
    "\n",
    "In this exercise, you will train a model using scikit-learn's Linear Regression to predict profit from the Unicorn dataset. You have created an experiment called Unicorn Sklearn Experiment and started a new run. You will log metrics for r2_score and parameters for n_jobs as well as log the training code as an artifact.\n",
    "\n",
    "The Linear Regression model will be trained with n_jobs parameter set to 1. The r2_score metric will be produced using the r2_score() from scikit-learn based on y_pred variable which came from predictions of X_test.\n",
    "\n",
    "model = LinearRegression(n_jobs=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "The mlflow module as well as the LinearRegression, train_test_split, and metrics modules from scikit-learn will be imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Log the r2_score variable as a metric called \"r2_score\".\n",
    "\n",
    "    Log a parameter called \"n_jobs\" to the Tracking Server.\n",
    "\n",
    "    Log the \"train.py\" file as an artifact in the run.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "# Log the metric r2_score as \"r2_score\"\n",
    "mlflow.log_metric(\"r2_score\", r2_score)\n",
    "\n",
    "# Log parameter n_jobs as \"n_jobs\"\n",
    "mlflow.log_param(\"n_jobs\", n_jobs)\n",
    "\n",
    "# Log the training code\n",
    "mlflow.log_artifact(\"train.py\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Awesome work! The log_metric(), log_param() and log_artifact() functions make it very simple to log information to MLflow Tracking.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "How to retrieve active run data?\n",
    "\n",
    "MLflow uses the concept of runs to log metrics, parameters and artifacts to MLflow Tracking. Using the start_run() function from the mlflow module starts a new run and sets it to an active state. This is helpful if information such as run_id or artifact_uri needs to be retrieved.\n",
    "\n",
    "A run has been set to active using the following code:\n",
    "\n",
    "run = mlflow.start_run()\n",
    "\n",
    "If information about the current run is needed, which of the following attributes is used to retrieve metadata about an active run?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    run.current_run\n",
    "    \n",
    "    run.data\n",
    "    \n",
    "    run.info {Answer}\n",
    "    \n",
    "    run.info.run_id\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! It is often times helpful to retreive metadata about a current run.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search runs query options\n",
    "\n",
    "The search_runs() function from the mlflow module provides a way to query runs given a certain criteria. Runs are then returned as an output that can then be used to help perform further data analysis using a tool of choice.\n",
    "\n",
    "Which of the following choices are provided as an output and as an option to query using search_runs() function?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "    metrics and parameters{Answer}\n",
    "\n",
    "\n",
    "    experiment name\n",
    "\n",
    "\n",
    "    tags{Answer}\n",
    "\n",
    "\n",
    "    run_id{Answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Searching runs\n",
    "\n",
    "In this exercise, you will query experiment runs from multiple Unicorn experiments and return only runs that meet a certain desired criteria. This is helpful during the ML lifecycle if you need to compare runs data.\n",
    "\n",
    "First you will create a filter string to capture runs for R-squared metric greater than .70. Using the function from the mlflow module that searches runs, you will then order them in descending order and search only the experiments \"Unicorn Sklearn Experiments\" and \"Unicorn Other Experiments\".\n",
    "\n",
    "The experiments have already been created in MLflow along with the R-squared metrics. The MLflow module will be imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    For variable r_squared_filter, create a filter string to capture \"r2_score\" metrics \"> .70\".\n",
    "\n",
    "    Search runs for experiments \"Unicorn Sklearn Experiments\" and \"Unicorn Other Experiments\".\n",
    "\n",
    "    Order the results of R-squared in descending order.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a filter string for R-squared score\n",
    "r_squared_filter = \"metrics.r2_score > .70\"\n",
    "\n",
    "# Search runs\n",
    "mlflow.search_runs(experiment_names=[\"Unicorn Sklearn Experiments\", \"Unicorn Other Experiments\"], \n",
    "                   filter_string=r_squared_filter, \n",
    "                   order_by=[\"metrics.r2_score DESC\"])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! The search_runs() function provides a programmatic way to output run data of a desired criteria.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
