{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs intuition\n",
    "\n",
    "Which of the following best describes the fundamental principle behind Generative Adversarial Networks (GANs)?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    GANs utilize a single neural network that is trained to generate new data that matches the data from a training dataset.\n",
    "    \n",
    "    \n",
    "    GANs consist of a pair of neural networks that are trained in a collaborative manner to generate new data.\n",
    "    \n",
    "    \n",
    "    GANs employ two neural networks, the Generator and the Discriminator, that are trained simultaneously through adversarial training, with the objective to create new data that is indistinguishable from real data. {Answer}\n",
    "    \n",
    "    \n",
    "    GANs use a sequence of neural networks to transform raw data for easier analysis or visualization.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def gen_block(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, out_dim),\n",
    "        nn.BatchNorm1d(out_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThat's a neat generator! Once trained, it will accept random noise of size in_dim as input, and produce the generated image of size out_dim!\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Generator\n",
    "\n",
    "A GAN generator takes a random noise vector as input and produces a generated image. To make its architecture more reusable, you will pass both input and output shapes as parameters to the model. This way, you can use the same model with different sizes of input noise and images of varying shapes.\n",
    "\n",
    "You will find torch.nn imported already imported for you as nn. You can also access a custom gen_block() function which returns a block of: linear layer, batch norm, and ReLU activation. You will use it as a building block for the generator.\n",
    "\n",
    "def gen_block(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, out_dim),\n",
    "        nn.BatchNorm1d(out_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Define self.generator as a sequential model.\n",
    "\n",
    "    After the last gen_block, add a linear layer with the appropriate input size and the output size of out_dim.\n",
    "\n",
    "    Add a sigmoid activation after the linear layer.\n",
    "\n",
    "    In the forward() method, pass the model's input through self.generator.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        # Define generator block\n",
    "        self.generator = nn.Sequential(\n",
    "            gen_block(in_dim, 256),\n",
    "            gen_block(256, 512),\n",
    "            gen_block(512, 1024),\n",
    "          \t# Add linear layer\n",
    "            nn.Linear(1024, out_dim),\n",
    "            # Add activation\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      \t# Pass input through generator\n",
    "        return self.generator(x)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's a neat generator! Once trained, it will accept random noise of size in_dim as input, and produce the generated image of size out_dim!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_block(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, out_dim),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWell done, a perfect discriminator! You now have a good intuition about how GANs work. In the next video, we will see how to upgrade the generator and the discriminator to make them more suitable for images!\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Discriminator\n",
    "\n",
    "With the generator defined, the next step in building a GAN is to construct the discriminator. It takes the generator's output as input, and produces a binary prediction: is the input generated or real?\n",
    "\n",
    "You will find torch.nn imported already imported for you as nn. You can also access a custom disc_block() function which returns a block of a linear layer followed by a LeakyReLU activation. You will use it as a building block for the discriminator.\n",
    "\n",
    "def disc_block(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, out_dim),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Add the last discriminator block to the model, with the appropriate input size and the output of 256.\n",
    "\n",
    "    After the last discriminator block, add a linear layer to map the output to the size of 1.\n",
    "\n",
    "    Define the forward() method to pass the input image through the sequential block defined in __init__().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            disc_block(im_dim, 1024),\n",
    "            disc_block(1024, 512),\n",
    "            # Define last discriminator block\n",
    "            disc_block(512, 256),\n",
    "            # Add a linear layer\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward method\n",
    "        return self.disc(x)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done, a perfect discriminator! You now have a good intuition about how GANs work. In the next video, we will see how to upgrade the generator and the discriminator to make them more suitable for images!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_gen_block(in_dim, out_dim, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGood job, that's a perfect convolutional generator! Let's complete it with a convolutional discriminator next!\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Convolutional Generator\n",
    "\n",
    "Define a convolutional generator following the DCGAN guidelines discussed in the last video.\n",
    "\n",
    "torch.nn has been pre-imported as nn for your convenience. Additionally, a custom function dc_gen_block() is available, which eturns a block of a transposed convolution, batch norm, and ReLU activation. This function serves as a foundational component for constructing the convolutional generator. You can get familiar with dc_gen_block()'s definition below.\n",
    "\n",
    "def dc_gen_block(in_dim, out_dim, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Add the last generator block, mapping the size of the feature maps to 256.\n",
    " \n",
    "    Add a transposed convolution with the output size of 3.\n",
    " \n",
    "    Add the tanh activation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class DCGenerator(nn.Module):\n",
    "    def __init__(self, in_dim, kernel_size=4, stride=2):\n",
    "        super(DCGenerator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            dc_gen_block(in_dim, 1024, kernel_size, stride),\n",
    "            dc_gen_block(1024, 512, kernel_size, stride),\n",
    "            # Add last generator block\n",
    "            dc_gen_block(512, 256, kernel_size, stride),\n",
    "            # Add transposed convolution\n",
    "            nn.ConvTranspose2d(256, 3, kernel_size, stride=stride),\n",
    "            # Add tanh activation\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), self.in_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job, that's a perfect convolutional generator! Let's complete it with a convolutional discriminator next!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_disc_block(in_dim, out_dim, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGreat! You can now implement the DCGAN for image generation. In the next video, we will explore how to train it!\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Convolutional Discriminator\n",
    "\n",
    "With the DCGAN's generator ready, the last step before you can proceed to training it is to define the convolutional discriminator.\n",
    "\n",
    "torch.nn is imported for you under its usual alias. To build the convolutional discriminator, you will use a custom gc_disc_block() function which returns a block of a convolution followed by a batch norm and the leaky ReLU activation. You can inspect dc_disc_block()'s definition below.\n",
    "\n",
    "def dc_disc_block(in_dim, out_dim, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Add the first discriminator block using the custom dc_disc_block() function with 3 input feature maps and 512 output feature maps.\n",
    "   \n",
    "    Add the convolutional layer with the output size of 1.\n",
    "   \n",
    "    In the forward() method, pass the input through the sequential block you defined in __init__().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    def __init__(self, kernel_size=4, stride=2):\n",
    "        super(DCDiscriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "          \t# Add first discriminator block\n",
    "            dc_disc_block(3, 512, kernel_size, stride),\n",
    "            dc_disc_block(512, 1024, kernel_size, stride),\n",
    "          \t# Add a convolution\n",
    "            nn.Conv2d(1024, 1, kernel_size, stride=stride),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through sequential block\n",
    "        x = self.disc(x)\n",
    "        return x.view(len(x), -1)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! You can now implement the DCGAN for image generation. In the next video, we will explore how to train it!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWell done! The generator is rewarded if it succeeds to fool the discriminator!\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Generator loss\n",
    "\n",
    "Before you can train your GAN, you need to define loss functions for both the generator and the discriminator. You will start with the former.\n",
    "\n",
    "Recall that the generator's job is to produce such fake images that would fool the discriminator into classifying them as real. Therefore, the generator incurs a loss if the images it generated are classified by the discriminator as fake (label 0).\n",
    "\n",
    "Define the gen_loss() function that calculates the generator loss. It takes four arguments:\n",
    "\n",
    "    gen, the generator model\n",
    "    disc, the discriminator model\n",
    "    num_images, the number of images in batch\n",
    "    z_dim, the size of the input random noise\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Generate random noise of shape num_images by z_dim and assign it to noise.\n",
    "\n",
    "    Use the generator to generate a fake image from for noise and assign it to fake.\n",
    "\n",
    "    Get discriminator's prediction for the generated fake image.\n",
    "\n",
    "    Compute generators loss by calling criterion on discriminator's predictions and the a tensor of ones of the same shape.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def gen_loss(gen, disc, criterion, num_images, z_dim):\n",
    "    # Define random noise\n",
    "    noise = torch.randn(num_images, z_dim)\n",
    "    # Generate fake image\n",
    "    fake = gen(noise)\n",
    "    # Get discriminator's prediction on the fake image\n",
    "    disc_pred = disc(fake)\n",
    "    # Compute generator loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    gen_loss = criterion(disc_pred, torch.ones_like(disc_pred))\n",
    "    return gen_loss\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! The generator is rewarded if it succeeds to fool the discriminator!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGreat! The discriminator is rewarded it makes correct classifications: real images as real, and fake ones as fake!\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Discriminator loss\n",
    "\n",
    "It's time to define the loss for the discriminator. Recall that the discriminator's job is to classify images either real or fake. Therefore, the discriminator incurs a loss if it classifies generator's outputs as real (label 1) or the real images as fake (label 0).\n",
    "\n",
    "Define the disc_loss() function that calculates the discriminator loss. It takes five arguments:\n",
    "\n",
    "    gen, the generator model\n",
    "    disc, the discriminator model\n",
    "    real, a sample of real images from the training data\n",
    "    num_images, the number of images in batch\n",
    "    z_dim, the size of the input random noise\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Use the discriminator to classify fake images and assign the predictions to disc_pred_fake.\n",
    "\n",
    "    Compute the fake loss component by calling criterion on discriminator's predictions for fake images and the a tensor of zeros of the same shape.\n",
    "\n",
    "    Use the discriminator to classify real images and assign the predictions to disc_pred_real.\n",
    "\n",
    "    Compute the real loss component by calling criterion on discriminator's predictions for real images and the a tensor of ones of the same shape.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def disc_loss(gen, disc, real, num_images, z_dim):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    noise = torch.randn(num_images, z_dim)\n",
    "    fake = gen(noise)\n",
    "    # Get discriminator's predictions for fake images\n",
    "    disc_pred_fake = disc(fake)\n",
    "    # Calculate the fake loss component\n",
    "    fake_loss = criterion(disc_pred_fake, torch.ones_like(disc_pred_fake))\n",
    "    # Get discriminator's predictions for real images\n",
    "    disc_pred_real = disc(real)\n",
    "    # Calculate the real loss component\n",
    "    real_loss = criterion(disc_pred_real, torch.ones_like(disc_pred_real))\n",
    "    disc_loss = (real_loss + fake_loss) / 2\n",
    "    return disc_loss\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! The discriminator is rewarded it makes correct classifications: real images as real, and fake ones as fake!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Training loop\n",
    "\n",
    "Finally, all the hard work you put into defining the model architectures and loss functions comes to fruition: it's training time! Your job is to implement and execute the GAN training loop. Note: a break statement is placed after the first batch of data to avoid a long runtime.\n",
    "\n",
    "The two optimizers, disc_opt and gen_opt, have been initialized as Adam() optimizers. The functions to compute the losses that you defined earlier, gen_loss() and disc_loss(), are available to you. A dataloader is also prepared for you.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "    disc_loss()'s arguments are: gen, disc, real, cur_batch_size, z_dim.\n",
    "    gen_loss()'s arguments are: gen, disc, cur_batch_size, z_dim.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Calculate the discriminator loss using disc_loss() by passing it the generator, the discriminator, the sample of real images, current batch size, and the noise size of 16, in this order, and assign the result to disc_loss.\n",
    "\n",
    "    Calculate gradients using disc_loss.\n",
    "\n",
    "    Calculate the generator loss using gen_loss() by passing it the generator, the discriminator, current batch size, and the noise size of 16, in this order, and assign the result to gen_loss.\n",
    "\n",
    "    Calculate gradients using gen_loss.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "for epoch in range(1):\n",
    "    for real in dataloader:\n",
    "        cur_batch_size = len(real)\n",
    "        \n",
    "        disc_opt.zero_grad()\n",
    "        # Calculate discriminator loss\n",
    "        disc_loss = disc_loss(gen, disc, real, cur_batch_size, 16)\n",
    "        # Compute gradients\n",
    "        disc_loss.backward()\n",
    "        disc_opt.step()\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        # Calculate generator loss\n",
    "        gen_loss = gen_loss(gen, disc, cur_batch_size, 16)\n",
    "        # Compute generator gradients\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        print(f\"Generator loss: {gen_loss}\")\n",
    "        print(f\"Discriminator loss: {disc_loss}\")\n",
    "        break\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Perfect! You can now execute GAN training! In the next video, you will examine a trained model and the ways to evaluate it!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Generating images\n",
    "\n",
    "Now that you have designed and trained your GAN, it's time to evaluate the quality of the images it can generate. For a start, you will perform a visual inspection to see if the generation resemble the Pokemons at all. To do this, you will create random noise as input for the generator, pass it to the model and plot the outputs.\n",
    "\n",
    "The Deep Convolutional Generator with trained weights is available to you as gen. torch and matplotlib.pyplot as plt are already imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Create a random noise tensor of shape num_images_to_generate by 16, the input noise size you used to train the generator, and assign it to noise.\n",
    "\n",
    "    Generate images by passing the noise to the generator and assign them to fake.\n",
    "\n",
    "    Inside the for loop, slice fake to extract the i-th image and assign it to image_tensor.\n",
    "\n",
    "    Permute image_tensor's dimensions from (color, height, width) to (hight, width, color) and assign the output to image_tensor_permuted.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "num_images_to_generate = 5\n",
    "# Create random noise tensor\n",
    "noise = torch.randn(num_images_to_generate, 16)\n",
    "\n",
    "# Generate images\n",
    "with torch.no_grad():\n",
    "    fake = gen(noise)\n",
    "print(f\"Generated tensor shape: {fake.shape}\")\n",
    "    \n",
    "for i in range(num_images_to_generate):\n",
    "    # Slice fake to select i-th image\n",
    "    image_tensor = fake[i, :, :, :]\n",
    "    # Permute the image dimensions\n",
    "    image_tensor_permuted = image_tensor.permute(1,2,0)\n",
    "    plt.imshow(image_tensor_permuted)\n",
    "    plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice! Some of them are quite well-shaped Pokemons, while others might be missing an eye or a leg. Feel free to run the code again with different random noise to generate more images!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Fréchet Inception Distance\n",
    "\n",
    "The visual inspection of generated images is a great start. But given they look okay, a more precise, quantitative evaluation will be helpful to understand the generator's performance. You will evaluate your GAN using the Fréchet Inception Distance, or FID.\n",
    "\n",
    "Two tensors with fake and real images, 32 examples each, are available to you as fake and real, respectively. Use them to compute the FID!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    Import FrechetInceptionDistance from the appropriate torchmetrics module.\n",
    "\n",
    "    Instantiate the FID metric based on the 64th Inception feature layer and assign it to fid.\n",
    "\n",
    "    Update fid with real image tensor, multiplied by 255 and parsed to torch.uint8.\n",
    "\n",
    "    Compute the fid metric, assigning the output to fid_score.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import FrechetInceptionDistance\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "# Instantiate FID\n",
    "fid = FrechetInceptionDistance(feature=64)\n",
    "\n",
    "# Update FID with real images\n",
    "fid.update((fake * 255).to(torch.uint8), real=False)\n",
    "fid.update((real * 255).to(torch.uint8), real=True)\n",
    "\n",
    "# Compute the metric\n",
    "fid_score = fid.compute()\n",
    "print(fid_score)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic job! The FID below 10 indicates a really good quality and variety of generated images!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
