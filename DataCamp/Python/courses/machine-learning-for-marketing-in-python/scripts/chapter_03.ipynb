{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AcquisitionMonth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-01</th>\n",
       "      <td>716.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>332.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>316.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-01</th>\n",
       "      <td>388.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-01</th>\n",
       "      <td>255.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-01</th>\n",
       "      <td>249.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-01</th>\n",
       "      <td>207.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01</th>\n",
       "      <td>173.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01</th>\n",
       "      <td>139.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-01</th>\n",
       "      <td>279.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>318.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-01</th>\n",
       "      <td>291.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1      2      3      4      5      6      7      8  \\\n",
       "AcquisitionMonth                                                           \n",
       "2010-12-01        716.0  246.0  221.0  251.0  245.0  285.0  249.0  236.0   \n",
       "2011-01-01        332.0   69.0   82.0   81.0  110.0   90.0   82.0   86.0   \n",
       "2011-02-01        316.0   58.0   57.0   83.0   85.0   74.0   80.0   83.0   \n",
       "2011-03-01        388.0   63.0  100.0   76.0   83.0   67.0   98.0   85.0   \n",
       "2011-04-01        255.0   49.0   52.0   49.0   47.0   52.0   56.0   59.0   \n",
       "2011-05-01        249.0   40.0   43.0   36.0   52.0   58.0   61.0   22.0   \n",
       "2011-06-01        207.0   33.0   26.0   41.0   49.0   62.0   19.0    NaN   \n",
       "2011-07-01        173.0   28.0   31.0   38.0   44.0   17.0    NaN    NaN   \n",
       "2011-08-01        139.0   30.0   28.0   35.0   14.0    NaN    NaN    NaN   \n",
       "2011-09-01        279.0   56.0   78.0   34.0    NaN    NaN    NaN    NaN   \n",
       "2011-10-01        318.0   67.0   30.0    NaN    NaN    NaN    NaN    NaN   \n",
       "2011-11-01        291.0   32.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2011-12-01         38.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "                      9     10     11     12     13  \n",
       "AcquisitionMonth                                     \n",
       "2010-12-01        240.0  265.0  254.0  348.0  172.0  \n",
       "2011-01-01        104.0  102.0  124.0   45.0    NaN  \n",
       "2011-02-01         86.0   95.0   28.0    NaN    NaN  \n",
       "2011-03-01        107.0   38.0    NaN    NaN    NaN  \n",
       "2011-04-01         17.0    NaN    NaN    NaN    NaN  \n",
       "2011-05-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-06-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-07-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-08-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-09-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-10-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-11-01          NaN    NaN    NaN    NaN    NaN  \n",
       "2011-12-01          NaN    NaN    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cohort_counts = pd.read_csv('datasets/cohort_counts.csv', parse_dates=['AcquisitionMonth'], index_col=0)\n",
    "cohort_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    1         2         3         4         5         6  \\\n",
      "AcquisitionMonth                                                          \n",
      "2010-12-01        1.0  0.343575  0.308659  0.350559  0.342179  0.398045   \n",
      "2011-01-01        1.0  0.207831  0.246988  0.243976  0.331325  0.271084   \n",
      "2011-02-01        1.0  0.183544  0.180380  0.262658  0.268987  0.234177   \n",
      "2011-03-01        1.0  0.162371  0.257732  0.195876  0.213918  0.172680   \n",
      "2011-04-01        1.0  0.192157  0.203922  0.192157  0.184314  0.203922   \n",
      "2011-05-01        1.0  0.160643  0.172691  0.144578  0.208835  0.232932   \n",
      "2011-06-01        1.0  0.159420  0.125604  0.198068  0.236715  0.299517   \n",
      "2011-07-01        1.0  0.161850  0.179191  0.219653  0.254335  0.098266   \n",
      "2011-08-01        1.0  0.215827  0.201439  0.251799  0.100719       NaN   \n",
      "2011-09-01        1.0  0.200717  0.279570  0.121864       NaN       NaN   \n",
      "2011-10-01        1.0  0.210692  0.094340       NaN       NaN       NaN   \n",
      "2011-11-01        1.0  0.109966       NaN       NaN       NaN       NaN   \n",
      "2011-12-01        1.0       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "                         7         8         9        10        11        12  \\\n",
      "AcquisitionMonth                                                               \n",
      "2010-12-01        0.347765  0.329609  0.335196  0.370112  0.354749  0.486034   \n",
      "2011-01-01        0.246988  0.259036  0.313253  0.307229  0.373494  0.135542   \n",
      "2011-02-01        0.253165  0.262658  0.272152  0.300633  0.088608       NaN   \n",
      "2011-03-01        0.252577  0.219072  0.275773  0.097938       NaN       NaN   \n",
      "2011-04-01        0.219608  0.231373  0.066667       NaN       NaN       NaN   \n",
      "2011-05-01        0.244980  0.088353       NaN       NaN       NaN       NaN   \n",
      "2011-06-01        0.091787       NaN       NaN       NaN       NaN       NaN   \n",
      "2011-07-01             NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2011-08-01             NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2011-09-01             NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2011-10-01             NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2011-11-01             NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2011-12-01             NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "                        13  \n",
      "AcquisitionMonth            \n",
      "2010-12-01        0.240223  \n",
      "2011-01-01             NaN  \n",
      "2011-02-01             NaN  \n",
      "2011-03-01             NaN  \n",
      "2011-04-01             NaN  \n",
      "2011-05-01             NaN  \n",
      "2011-06-01             NaN  \n",
      "2011-07-01             NaN  \n",
      "2011-08-01             NaN  \n",
      "2011-09-01             NaN  \n",
      "2011-10-01             NaN  \n",
      "2011-11-01             NaN  \n",
      "2011-12-01             NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat! You are now ready to explore retention and churn rates.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Build retention and churn tables\n",
    "\n",
    "You have learned the main elements of the customer lifetime value calculation and certain variations of it. Now you will use use the monthly cohort activity dataset to calculate retention and churn values, which you will then explore and later use to project average customer lifetime value.\n",
    "\n",
    "The pandas library has been loaded as pd and the cohorts_counts dataset has been imported. Feel free to explore it in the console.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Extract cohort sizes from the first column of cohort_counts.\n",
    "\n",
    "    Calculate retention by dividing the cohort counts with the cohort sizes.\n",
    "\n",
    "    Calculate churn by subtracting 1 and the retention rates.\n",
    "\n",
    "    Print the retention table.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Extract cohort sizes from the first column of cohort_counts\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Calculate retention by dividing the counts with the cohort sizes\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "\n",
    "# Calculate churn\n",
    "churn = 1 - retention\n",
    "\n",
    "# Print the retention table\n",
    "print(retention)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! You are now ready to explore retention and churn rates.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retention rate: 0.24; Churn rate: 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood work! Exploring these rates is critical in customer lifetime value calculation as it gives you insight into the customer behavior.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Explore retention and churn\n",
    "\n",
    "Now that you have calculated the monthly retention and churn metrics for monthly customer cohorts, you can calculate the overall mean retention and churn rates. You will use the .mean() method twice in a row (this is called \"chaining\") to calculate the overall mean. You will have to exclude the first month values (first column) from this calculation as they are constant given this is the first month the customers have been active therefore their retention will be 100% and churn will be 0% for all cohorts.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The retention and churn monthly datasets that you built in the previous exercises are also imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Calculate the mean retention rate.\n",
    "\n",
    "    Calculate the mean churn rate.\n",
    "\n",
    "    Print rounded retention and churn rates.\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "# solution\n",
    "\n",
    "# Calculate the mean retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate the mean churn rate\n",
    "churn_rate = churn.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Print rounded retention and churn rates\n",
    "print('Retention rate: {:.2f}; Churn rate: {:.2f}'.format(retention_rate, churn_rate))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work! Exploring these rates is critical in customer lifetime value calculation as it gives you insight into the customer behavior.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TotalSum</th>\n",
       "      <th>InvoiceMonth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416792</th>\n",
       "      <td>572558</td>\n",
       "      <td>22745</td>\n",
       "      <td>POPPY'S PLAYHOUSE BEDROOM</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-10-25 08:26:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>14286.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2011-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        InvoiceNo StockCode                 Description  Quantity  \\\n",
       "index                                                               \n",
       "416792     572558     22745  POPPY'S PLAYHOUSE BEDROOM          6   \n",
       "\n",
       "                InvoiceDate  UnitPrice  CustomerID         Country  TotalSum  \\\n",
       "index                                                                          \n",
       "416792  2011-10-25 08:26:00        2.1     14286.0  United Kingdom      12.6   \n",
       "\n",
       "       InvoiceMonth  \n",
       "index                \n",
       "416792      2011-10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online = pd.read_csv('datasets/online.csv', index_col='index')\n",
    "\n",
    "online.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average basic CLV is 4774.6 USD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCongratulations! You have successfully calculated the basic customer lifetime value.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Calculate basic CLV\n",
    "\n",
    "You are now ready to calculate average customer lifetime with three different methods! In this exercise you will calculate the basic CLV which multiplies average monthly spent with the projected customer lifespan.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The online dataset has been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Group by CustomerID and calculate monthly spend per customer.\n",
    "\n",
    "    Calculate average monthly spend.\n",
    "\n",
    "    Define lifespan to 36 months.\n",
    "\n",
    "    Calculate basic CLV by multiplying monthly average spend with the lifespan.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum()\n",
    "\n",
    "# Calculate average monthly spend\n",
    "monthly_revenue = np.mean(monthly_revenue)\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate basic CLV\n",
    "clv_basic = monthly_revenue * lifespan_months\n",
    "\n",
    "# Print the basic CLV value\n",
    "print('Average basic CLV is {:.1f} USD'.format(clv_basic))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Congratulations! You have successfully calculated the basic customer lifetime value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average granular CLV is 1635.2 USD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood job! You can see how the granular approach gets you a different lifetime value estimate than the basic one.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Calculate granular CLV\n",
    "\n",
    "In this scenario you will use more granular data points at the invoice level. This approach uses more granular data and can give a better customer lifetime value estimate. Make sure you compare the results with the one from the basic CLV model.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The online dataset has been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Group by InvoiceNo and calculate the mean of the TotalSum column.\n",
    "\n",
    "    Group by CustomerID and InvoiceMonth and calculate the mean number of unique monthly invoices per customer.\n",
    "\n",
    "    Define lifespan to 36 months.\n",
    "\n",
    "    Calculate the granular CLV by multiplying the three previous metrics.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Calculate average revenue per invoice\n",
    "revenue_per_purchase = online.groupby(['InvoiceNo'])['TotalSum'].mean().mean()\n",
    "\n",
    "# Calculate average number of unique invoices per customer per month\n",
    "frequency_per_month = online.groupby(['CustomerID','InvoiceMonth'])['InvoiceNo'].nunique().mean()\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate granular CLV\n",
    "clv_granular = revenue_per_purchase * frequency_per_month * lifespan_months\n",
    "\n",
    "# Print granular CLV value\n",
    "print('Average granular CLV is {:.1f} USD'.format(clv_granular))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! You can see how the granular approach gets you a different lifetime value estimate than the basic one.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traditional CLV is 42.4 USD at 24.2 % retention_rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLooks great! As you can see, the traditional CLV formula yields a much lower estimate as it accounts for monthly retention which is quite low for this company.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Calculate traditional CLV\n",
    "\n",
    "Now you will calculate one of the most popular descriptive CLV models that accounts for the retention and churn rates. This gives a more robust estimate, but comes with certain assumptions that have to be validated. Make sure you review the video slides before you apply this method to your own use case.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The online and retention datasets have been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Group by CustomerID and InvoiceMonth and calculate monthly spend per customer.\n",
    "\n",
    "    Calculate average monthly retention rate.\n",
    "\n",
    "    Calculate average monthly churn rate.\n",
    "\n",
    "    Calculate traditional CLV by multiplying monthly average spend with retention to churn ratio.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "\n",
    "# Calculate average monthly retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate average monthly churn rate\n",
    "churn_rate = 1 - retention_rate\n",
    "\n",
    "# Calculate traditional CLV \n",
    "clv_traditional = monthly_revenue * (retention_rate / churn_rate)\n",
    "\n",
    "# Print traditional CLV and the retention rate values\n",
    "print('Average traditional CLV is {:.1f} USD at {:.1f} % retention_rate'.format(clv_traditional, retention_rate*100))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Looks great! As you can see, the traditional CLV formula yields a much lower estimate as it accounts for monthly retention which is quite low for this company.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TotalSum</th>\n",
       "      <th>InvoiceMonth</th>\n",
       "      <th>AcquisitionMonth</th>\n",
       "      <th>AcquisitionDate</th>\n",
       "      <th>CohortIndex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416792</th>\n",
       "      <td>572558</td>\n",
       "      <td>22745</td>\n",
       "      <td>POPPY'S PLAYHOUSE BEDROOM</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-10-25 08:26:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>14286.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>2011-04-11 08:16:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        InvoiceNo StockCode                 Description  Quantity  \\\n",
       "index                                                               \n",
       "416792     572558     22745  POPPY'S PLAYHOUSE BEDROOM          6   \n",
       "\n",
       "               InvoiceDate  UnitPrice  CustomerID         Country  TotalSum  \\\n",
       "index                                                                         \n",
       "416792 2011-10-25 08:26:00        2.1     14286.0  United Kingdom      12.6   \n",
       "\n",
       "       InvoiceMonth AcquisitionMonth     AcquisitionDate  CohortIndex  \n",
       "index                                                                  \n",
       "416792   2011-10-01       2011-04-01 2011-04-11 08:16:00            7  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_X = pd.read_csv('datasets/online_x.csv', index_col='index', parse_dates=['InvoiceDate','AcquisitionDate','AcquisitionMonth', 'InvoiceMonth'])\n",
    "online_X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104149/2052137483.py:31: FutureWarning: The provided callable <function sum at 0x716ed02f9120> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  features = online_X.groupby('CustomerID').agg({\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFantastic! You have successfully built the features for purchase prediction.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Build features\n",
    "\n",
    "You are now fully equipped to build recency, frequency, monetary value and other customer level features for your regression model. Feature engineering is the most important step in the machine learning process. In this exercise you will create five customer-level features that you will then use in predicting next month's customer transactions. These features capture highly predictive customer behavior patterns.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The online_X dataset has been imported for you. The datetime object NOW depicting the snapshot date you will use to calculate recency has been created for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Calculate recency by subtracting the current date from the latest InvoiceDate.\n",
    "\n",
    "    Calculate frequency by counting the unique number of invoices.\n",
    "\n",
    "    Calculate monetary value by summing all spend values.\n",
    "\n",
    "    Calculate average and total quantity.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Define the snapshot date\n",
    "NOW = dt.datetime(2011,11,1)\n",
    "\n",
    "# Calculate recency by subtracting current date from the latest InvoiceDate\n",
    "features = online_X.groupby('CustomerID').agg({\n",
    "  'InvoiceDate': lambda x: (NOW - x.max()).days,\n",
    "  # Calculate frequency by counting unique number of invoices\n",
    "  'InvoiceNo': pd.Series.nunique,\n",
    "  # Calculate monetary value by summing all spend values\n",
    "  'TotalSum': np.sum,\n",
    "  # Calculate average and total quantity\n",
    "  'Quantity': ['mean', 'sum']}).reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "features.columns = ['CustomerID', 'recency', 'frequency', 'monetary', 'quantity_avg', 'quantity_total']\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! You have successfully built the features for purchase prediction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPerfect! Now with the target variable defined and the features built previously, you are ready to split the data into training and testing.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Define target variable\n",
    "\n",
    "Here, you'll build a pandas pivot table with customers as rows, invoice months as columns, and number of invoice counts as values. You will use the last month's value as the target variable. The remaining variables can be used as the so-called lagged features in the model. You will not use them, but are highly encouraged to check if adding these variables will improve your model performance beyond what you'll see in the upcoming exercises.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The online dataset has been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build a pivot table using the pivot_table() function counting invoices.\n",
    "\n",
    "    Store November 2011 sales data column name as a list.\n",
    "\n",
    "    Store the target value as Y.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build a pivot table counting invoices for each customer monthly\n",
    "cust_month_tx = pd.pivot_table(data=online, values='InvoiceNo',\n",
    "                               index=['CustomerID'], columns=['InvoiceMonth'],\n",
    "                               aggfunc=pd.Series.nunique, fill_value=0)\n",
    "\n",
    "# Store November 2011 data column name as a list\n",
    "target = ['2011-11']\n",
    "\n",
    "# Store target value as `Y`\n",
    "Y = cust_month_tx[target]\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Perfect! Now with the target variable defined and the features built previously, you are ready to split the data into training and testing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGood job! The data is now fully prepared to be used for predicting next month transactions.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Split data to training and testing\n",
    "\n",
    "Final step before we move to building the regression model! Here, you will follow the steps of identifying the names of the target variable and the feature columns, extract the data, and split them into training and testing.\n",
    "\n",
    "The pandas and numpy libraries have been loaded as pd as np respectively. The input features are imported as the features dataset, and the target variable you built in the previous exercise has been imported for you as Y.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Store the customer identifier column name as a list.\n",
    "\n",
    "    Select the feature column names excluding the customer identifier.\n",
    "\n",
    "    Extract the features as X.\n",
    "\n",
    "    Split the data to training and testing by using the train_test_split() function.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Store customer identifier column name as a list\n",
    "custid = ['CustomerID']\n",
    "\n",
    "# Select feature column names excluding customer identifier\n",
    "cols = [col for col in features.columns if col not in custid]\n",
    "\n",
    "# Extract the features as `X`\n",
    "X = features[cols].iloc[:Y.shape[0],:]\n",
    "\n",
    "# Split data to training and testing\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y.iloc[:3372,:], test_size=0.25, random_state=99)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! The data is now fully prepared to be used for predicting next month transactions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGreat! You have built the model on the training data, and predicted values on testing data. Next, you will explore model fit.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Predict next month transactions\n",
    "\n",
    "You are finally in the stage of predicting next month's transaction with linear regression. Here you will use the input features you've previously built, train the model on them and the target variable, and predict the values on the unseen testing data. In the next exercise you will measure the model performance.\n",
    "\n",
    "The LinearRegression function from sklearn library has been loaded for you. The training and testing features are loaded as train_X and test_X respectively, and the training and testing target variables are loaded as train_Y and test_Y.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Initialize a linear regression instance.\n",
    "\n",
    "    Fit the model to the training dataset.\n",
    "\n",
    "    Predict the target variable for the training data.\n",
    "\n",
    "    Predict the target variable for the testing data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Initialize linear regression instance\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model to training dataset\n",
    "linreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the target variable for training data\n",
    "train_pred_Y = linreg.predict(train_X)\n",
    "\n",
    "# Predict the target variable for testing data\n",
    "test_pred_Y = linreg.predict(test_X)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! You have built the model on the training data, and predicted values on testing data. Next, you will explore model fit.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train: 0.8693884559042385; RMSE test: 1.6078464842767959\n",
      "MAE train: 0.6750713366548614, MAE test: 0.6878555812734993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "Measure model fit\n",
    "\n",
    "Now you will measure the regression performance on both training and testing data with two metrics - root mean squared error and mean absolute error. This is a critical step where you are measuring how \"close\" are the model predictions compared to actual values.\n",
    "\n",
    "The numpy library has been loaded as np. The mean_absolute_error and mean_squared_error functions have been loaded. The training and testing target variables are loaded as train_Y and test_Y, and the predicted training and testing values are imported as train_pred_Y and test_pred_Y respectively.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Calculate the root mean squared error on the training data by using the np.sqrt() function.\n",
    "\n",
    "    Calculate the mean absolute error on the training data.\n",
    "\n",
    "    Calculate the root mean squared error on the testing data.\n",
    "\n",
    "    Calculate the mean absolute error on the testing data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# Calculate root mean squared error on training data\n",
    "rmse_train = np.sqrt(mean_squared_error(train_Y, train_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on training data\n",
    "mae_train = mean_absolute_error(train_Y, train_pred_Y)\n",
    "\n",
    "# Calculate root mean squared error on testing data\n",
    "rmse_test = np.sqrt(mean_squared_error(test_Y, test_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on testing data\n",
    "mae_test = mean_absolute_error(test_Y, test_pred_Y)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('RMSE train: {}; RMSE test: {}\\nMAE train: {}, MAE test: {}'.format(rmse_train, rmse_test, mae_train, mae_test))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Looks great! You have successfully calculated the root mean squared error and mean absolute error of the model performance on both training and testing datasets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 11\n",
    "\n",
    "\"\"\"\n",
    "Explore model coefficients\n",
    "\n",
    "You will now explore the model performance from a different angle, and only on the training data. One thing you learned in the latest lesson is that not all model coefficients are statistically significant and we should look at the model summary table to explore their significance. Fortunately, the statsmodels library provides this functionality. Once you print the model summary table, explore which variables have the p-value lower than 0.05 (i.e. lower than 5%) to make sure the coefficient is significant.\n",
    "\n",
    "The training features are loaded as train_X, and the target variable as train_Y which was converted to a numpy array.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the statsmodels.api module.\n",
    "\n",
    "    Initialize a model instance on the training data using the OLS() function.\n",
    "\n",
    "    Fit the model.\n",
    "\n",
    "    Print model summary using the .summary() method.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
