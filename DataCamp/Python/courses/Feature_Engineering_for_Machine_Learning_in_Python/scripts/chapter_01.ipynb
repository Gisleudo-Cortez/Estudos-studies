{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:25:24.202812Z",
     "iopub.status.busy": "2023-06-12T11:25:24.202281Z",
     "iopub.status.idle": "2023-06-12T11:25:29.415847Z",
     "shell.execute_reply": "2023-06-12T11:25:29.415284Z",
     "shell.execute_reply.started": "2023-06-12T11:25:24.202766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "path_data = '/home/nero/Documents/Estudos/DataCamp/Python/Feature_Engineering_for_Machine_Learning_in_Python/datasets/'\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:25:30.630628Z",
     "iopub.status.busy": "2023-06-12T11:25:30.630009Z",
     "iopub.status.idle": "2023-06-12T11:25:30.636165Z",
     "shell.execute_reply": "2023-06-12T11:25:30.635134Z",
     "shell.execute_reply.started": "2023-06-12T11:25:30.630582Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "so_survey_csv = path_data + 'Combined_DS_v10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:25:31.493017Z",
     "iopub.status.busy": "2023-06-12T11:25:31.491303Z",
     "iopub.status.idle": "2023-06-12T11:25:31.650988Z",
     "shell.execute_reply": "2023-06-12T11:25:31.649354Z",
     "shell.execute_reply.started": "2023-06-12T11:25:31.492960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SurveyDate                                    FormalEducation   \n",
      "0  2/28/18 20:20           Bachelor's degree (BA. BS. B.Eng.. etc.)  \\\n",
      "1  6/28/18 13:26           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "2    6/6/18 3:37           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "3    5/9/18 1:06  Some college/university study without earning ...   \n",
      "4  4/12/18 22:41           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "\n",
      "   ConvertedSalary Hobby       Country  StackOverflowJobsRecommend   \n",
      "0              NaN   Yes  South Africa                         NaN  \\\n",
      "1          70841.0   Yes       Sweeden                         7.0   \n",
      "2              NaN    No       Sweeden                         8.0   \n",
      "3          21426.0   Yes       Sweeden                         NaN   \n",
      "4          41671.0   Yes            UK                         8.0   \n",
      "\n",
      "      VersionControl  Age  Years Experience Gender   RawSalary  \n",
      "0                Git   21                13   Male         NaN  \n",
      "1     Git;Subversion   38                 9   Male   70,841.00  \n",
      "2                Git   45                11    NaN         NaN  \n",
      "3  Zip file back-ups   46                12   Male   21,426.00  \n",
      "4                Git   39                 7   Male  Â£41,671.00  \n",
      "SurveyDate                     object\n",
      "FormalEducation                object\n",
      "ConvertedSalary               float64\n",
      "Hobby                          object\n",
      "Country                        object\n",
      "StackOverflowJobsRecommend    float64\n",
      "VersionControl                 object\n",
      "Age                             int64\n",
      "Years Experience                int64\n",
      "Gender                         object\n",
      "RawSalary                      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCorrect! ConvertedSalary contains floats which are numeric.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Getting to know your data\n",
    "\n",
    "Pandas is one the most popular packages used to work with tabular data in Python. It is generally imported using the alias pd and can be used to load a CSV (or other delimited files) using read_csv().\n",
    "\n",
    "You will be working with a modified subset of the Stackoverflow survey response data in the first three chapters of this course. This dataset records the details, and preferences of thousands of users of the StackOverflow website.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import the pandas library as pd.\n",
    "    so_survey_csv contains the URL to a CSV file. Import it using Pandas into so_survey_df.\n",
    "---\n",
    "Print the first five rows of so_survey_df.\n",
    "---\n",
    "Print the data type of each column in so_survey_df.\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import so_survey_csv into so_survey_df\n",
    "so_survey_df = pd.read_csv(so_survey_csv)\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "print(so_survey_df.head())\n",
    "\n",
    "# Print the data type of each column\n",
    "print(so_survey_df.dtypes)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct! ConvertedSalary contains floats which are numeric.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:26:57.521050Z",
     "iopub.status.busy": "2023-06-12T11:26:57.520287Z",
     "iopub.status.idle": "2023-06-12T11:26:57.537919Z",
     "shell.execute_reply": "2023-06-12T11:26:57.536808Z",
     "shell.execute_reply.started": "2023-06-12T11:26:57.520983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ConvertedSalary', 'StackOverflowJobsRecommend', 'Age',\n",
      "       'Years Experience'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWell done! In the next lesson, you will learn the most common ways of dealing with categorical data.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Selecting specific data types\n",
    "\n",
    "Often a dataset will contain columns with several different data types (like the one you are working with). The majority of machine learning models require you to have a consistent data type across features. Similarly, most feature engineering techniques are applicable to only one type of data at a time. For these reasons among others, you will often want to be able to access just the columns of certain types when working with a DataFrame.\n",
    "\n",
    "The DataFrame (so_survey_df) from the previous exercise is available in your workspace.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a subset of so_survey_df consisting of only the numeric (int and float) columns.\n",
    "    Print the column names contained in so_survey_df_num.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create subset of only the numeric columns\n",
    "so_numeric_df = so_survey_df.select_dtypes(include=['int','float'])\n",
    "\n",
    "# Print the column names contained in so_survey_df_num\n",
    "print(so_numeric_df.columns)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! In the next lesson, you will learn the most common ways of dealing with categorical data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:34:56.282131Z",
     "iopub.status.busy": "2023-06-12T11:34:56.281641Z",
     "iopub.status.idle": "2023-06-12T11:34:56.299586Z",
     "shell.execute_reply": "2023-06-12T11:34:56.298899Z",
     "shell.execute_reply.started": "2023-06-12T11:34:56.282086Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
      "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
      "       'Years Experience', 'Gender', 'RawSalary', 'OH_France', 'OH_India',\n",
      "       'OH_Ireland', 'OH_Russia', 'OH_South Africa', 'OH_Spain', 'OH_Sweeden',\n",
      "       'OH_UK', 'OH_USA', 'OH_Ukraine'],\n",
      "      dtype='object')\n",
      "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
      "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
      "       'Years Experience', 'Gender', 'RawSalary', 'DM_India', 'DM_Ireland',\n",
      "       'DM_Russia', 'DM_South Africa', 'DM_Spain', 'DM_Sweeden', 'DM_UK',\n",
      "       'DM_USA', 'DM_Ukraine'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat job! Did you notice that the column for France was missing when you created dummy variables? Now you can choose to use one-hot encoding or dummy variables where appropriate.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "One-hot encoding and dummy variables\n",
    "\n",
    "To use categorical variables in a machine learning model, you first need to represent them in a quantitative way. The two most common approaches are to one-hot encode the variables using or to use dummy variables. In this exercise, you will create both types of encoding, and compare the created column sets. We will continue using the same DataFrame from previous lesson loaded as so_survey_df and focusing on its Country column.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "One-hot encode the Country column, adding \"OH\" as a prefix for each column.\n",
    "\n",
    "Create dummy variables for the Country column, adding \"DM\" as a prefix for each column.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Convert the Country column to a one hot encoded Data Frame\n",
    "one_hot_encoded = pd.get_dummies(so_survey_df, columns=['Country'], prefix='OH')\n",
    "\n",
    "# Print the columns names\n",
    "print(one_hot_encoded.columns)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Create dummy variables for the Country column\n",
    "dummy = pd.get_dummies(so_survey_df, columns=['Country'], drop_first=True, prefix='DM')\n",
    "\n",
    "# Print the columns names\n",
    "print(dummy.columns)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! Did you notice that the column for France was missing when you created dummy variables? Now you can choose to use one-hot encoding or dummy variables where appropriate.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:41:28.155627Z",
     "iopub.status.busy": "2023-06-12T11:41:28.155433Z",
     "iopub.status.idle": "2023-06-12T11:41:28.167794Z",
     "shell.execute_reply": "2023-06-12T11:41:28.166931Z",
     "shell.execute_reply.started": "2023-06-12T11:41:28.155610Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "South Africa    166\n",
      "USA             164\n",
      "Spain           134\n",
      "Sweeden         119\n",
      "France          115\n",
      "Russia           97\n",
      "UK               95\n",
      "India            95\n",
      "Other            14\n",
      "Name: count, dtype: int64\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: Country, dtype: bool\n",
      "Country\n",
      "South Africa    166\n",
      "USA             164\n",
      "Spain           134\n",
      "Sweeden         119\n",
      "France          115\n",
      "Russia           97\n",
      "UK               95\n",
      "India            95\n",
      "Other            14\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_180215/572884252.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  countries.iloc[mask] = 'Other'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood work, now you can work with large datasets while grouping low frequency categories.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Dealing with uncommon categories\n",
    "\n",
    "Some features can have many different categories but a very uneven distribution of their occurrences. Take for example Data Science's favorite languages to code in, some common choices are Python, R, and Julia, but there can be individuals with bespoke choices, like FORTRAN, C etc. In these cases, you may not want to create a feature for each value, but only the more common occurrences.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Extract the Country column of so_survey_df as a series and assign it to countries.\n",
    "    Find the counts of each category in the newly created countries series.\n",
    "---\n",
    "\n",
    "    Create a mask for values occurring less than 10 times in country_counts.\n",
    "    Print the first 5 rows of the mask.\n",
    "---\n",
    "\n",
    "    Label values occurring less than the mask cutoff as 'Other'.\n",
    "    Print the new category counts in countries.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a series out of the Country column\n",
    "countries = so_survey_df.Country\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Print the count values for each category\n",
    "print(country_counts)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Create a series out of the Country column\n",
    "countries = so_survey_df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Create a mask for only categories that occur less than 10 times\n",
    "mask = countries.isin(country_counts[country_counts < 10].index)\n",
    "\n",
    "# Print the top 5 rows in the mask series\n",
    "print(mask.head())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Create a series out of the Country column\n",
    "countries = so_survey_df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Create a mask for only categories that occur less than 10 times\n",
    "mask = countries.isin(country_counts[country_counts < 10].index)\n",
    "\n",
    "# Label all other categories as Other\n",
    "countries.loc[mask] = 'Other'\n",
    "\n",
    "# Print the updated category counts\n",
    "print(countries.value_counts())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work, now you can work with large datasets while grouping low frequency categories.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:51:05.895886Z",
     "iopub.status.busy": "2023-06-12T11:51:05.894705Z",
     "iopub.status.idle": "2023-06-12T11:51:05.914148Z",
     "shell.execute_reply": "2023-06-12T11:51:05.913331Z",
     "shell.execute_reply.started": "2023-06-12T11:51:05.895787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Paid_Job  ConvertedSalary\n",
      "0         0              NaN\n",
      "1         1          70841.0\n",
      "2         0              NaN\n",
      "3         1          21426.0\n",
      "4         1          41671.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood work, binarizing columns can also be useful for your target variables.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Binarizing columns\n",
    "\n",
    "While numeric values can often be used without any feature engineering, there will be cases when some form of manipulation can be useful. For example on some occasions, you might not care about the magnitude of a value but only care about its direction, or if it exists at all. In these situations, you will want to binarize a column. In the so_survey_df data, you have a large number of survey respondents that are working voluntarily (without pay). You will create a new column titled Paid_Job indicating whether each person is paid (their salary is greater than zero).\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a new column called Paid_Job filled with zeros.\n",
    "    Replace all the Paid_Job values with a 1 where the corresponding ConvertedSalary is greater than 0.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create the Paid_Job column filled with zeros\n",
    "so_survey_df['Paid_Job'] = 0\n",
    "\n",
    "# Replace all the Paid_Job values where ConvertedSalary is > 0\n",
    "so_survey_df.loc[so_survey_df['ConvertedSalary'] > 0, 'Paid_Job'] = 1\n",
    "\n",
    "# Print the first five rows of the columns\n",
    "print(so_survey_df[['Paid_Job', 'ConvertedSalary']].head())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work, binarizing columns can also be useful for your target variables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:56:11.470670Z",
     "iopub.status.busy": "2023-06-12T11:56:11.469613Z",
     "iopub.status.idle": "2023-06-12T11:56:11.496854Z",
     "shell.execute_reply": "2023-06-12T11:56:11.496277Z",
     "shell.execute_reply.started": "2023-06-12T11:56:11.470575Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          equal_binned  ConvertedSalary\n",
      "0                  NaN              NaN\n",
      "1  (-2000.0, 400000.0]          70841.0\n",
      "2                  NaN              NaN\n",
      "3  (-2000.0, 400000.0]          21426.0\n",
      "4  (-2000.0, 400000.0]          41671.0\n",
      "  boundary_binned  ConvertedSalary\n",
      "0             NaN              NaN\n",
      "1          Medium          70841.0\n",
      "2             NaN              NaN\n",
      "3             Low          21426.0\n",
      "4             Low          41671.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCorrect, now you can bin columns with equal spacing and predefined boundaries.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Binning values\n",
    "\n",
    "For many continuous values you will care less about the exact value of a numeric column, but instead care about the bucket it falls into. This can be useful when plotting values, or simplifying your machine learning models. It is mostly used on continuous variables where accuracy is not the biggest concern e.g. age, height, wages.\n",
    "\n",
    "Bins are created using pd.cut(df['column_name'], bins) where bins can be an integer specifying the number of evenly spaced bins, or a list of bin boundaries.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Bin the value of the ConvertedSalary column in so_survey_df into 5 equal bins, in a new column called equal_binned.\n",
    "\n",
    "Bin the ConvertedSalary column using the boundaries in the list bins and label the bins using labels.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Bin the continuous variable ConvertedSalary into 5 bins\n",
    "so_survey_df['equal_binned'] = pd.cut(so_survey_df['ConvertedSalary'], bins = 5)\n",
    "\n",
    "# Print the first 5 rows of the equal_binned column\n",
    "print(so_survey_df[['equal_binned', 'ConvertedSalary']].head())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Specify the boundaries of the bins\n",
    "bins = [-np.inf, 10000, 50000, 100000, 150000, np.inf]\n",
    "\n",
    "# Bin labels\n",
    "labels = ['Very low', 'Low', 'Medium', 'High', 'Very high']\n",
    "\n",
    "# Bin the continuous variable ConvertedSalary using these boundaries\n",
    "so_survey_df['boundary_binned'] = pd.cut(so_survey_df['ConvertedSalary'], \n",
    "                                         bins = bins, labels = labels)\n",
    "\n",
    "# Print the first 5 rows of the boundary_binned column\n",
    "print(so_survey_df[['boundary_binned', 'ConvertedSalary']].head())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct, now you can bin columns with equal spacing and predefined boundaries.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
