{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "path_data = '/home/nero/Documents/Estudos/DataCamp/Python/courses/Designing_Machine_Learning_Workflows_in_Python/datasets/'\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    return {\n",
    "    'unique_ports': len(set(df['destination_port'])),\n",
    "    'average_packet': np.mean(df['packet_count']),\n",
    "    'average_duration': np.mean(df['duration'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_domain</th>\n",
       "      <th>source_computer</th>\n",
       "      <th>destination_computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151036</td>\n",
       "      <td>U748@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151648</td>\n",
       "      <td>U748@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151993</td>\n",
       "      <td>U6115@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153792</td>\n",
       "      <td>U636@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155219</td>\n",
       "      <td>U748@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C5693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time user_domain source_computer destination_computer\n",
       "0  151036   U748@DOM1          C17693                 C305\n",
       "1  151648   U748@DOM1          C17693                 C728\n",
       "2  151993  U6115@DOM1          C17693                C1173\n",
       "3  153792   U636@DOM1          C17693                 C294\n",
       "4  155219   U748@DOM1          C17693                C5693"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks = pd.read_csv(path_data + 'redteam.csv')\n",
    "attacks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>source_computer</th>\n",
       "      <th>source_port</th>\n",
       "      <th>destination_computer</th>\n",
       "      <th>destination_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>packet_count</th>\n",
       "      <th>byte_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24128</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N17023</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N2414</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N19148</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24156</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N8001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24161</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N18502</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24162</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N11309</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  duration source_computer source_port destination_computer  \\\n",
       "0  471692         0           C5808      N24128               C26871   \n",
       "1  471692         0           C5808       N2414               C26871   \n",
       "2  471692         0           C5808      N24156               C26871   \n",
       "3  471692         0           C5808      N24161               C26871   \n",
       "4  471692         0           C5808      N24162               C26871   \n",
       "\n",
       "  destination_port  protocol  packet_count  byte_count  \n",
       "0           N17023         6             1          60  \n",
       "1           N19148         6             1          60  \n",
       "2            N8001         6             1          60  \n",
       "3           N18502         6             1          60  \n",
       "4           N11309         6             1          60  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows = pd.read_csv(path_data + 'lanl_flows.csv')\n",
    "flows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nYou have successfully incorporated your analyst's feedback. Let's now try to add some more features.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Is the source or the destination bad?\n",
    "\n",
    "In the previous lesson, you used the destination computer as your entity of interest. However, your cybersecurity analyst just told you that it is the infected machines that generate the bad traffic, and will therefore appear as a source, not a destination, in the flows dataset.\n",
    "\n",
    "The data flows has been preloaded, as well as the list bad of infected IDs and the feature extractor featurizer() from the previous lesson. You also have numpy available as np, AdaBoostClassifier(), and cross_val_score().\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a data frame where each row is a feature vector for a source_computer. Group by source computer ID in the flows dataset and apply the feature extractor to each group.\n",
    "    Convert the iterator to a data frame by calling list() on it.\n",
    "    Create labels by checking whether each source_computer ID belongs in the list of bads you have been given.\n",
    "    Assess an AdaBoostClassifier() on this data using cross_val_score().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "bads = set(pd.concat([attacks['source_computer'], attacks['destination_computer']]))\n",
    "\n",
    "\n",
    "# Group by source computer, and apply the feature extractor\n",
    "out = flows.groupby('source_computer').apply(featurize)\n",
    "\n",
    "# Convert the iterator to a dataframe by calling list on it\n",
    "X = pd.DataFrame(list(out), index=out.index)\n",
    "\n",
    "# Check which sources in X.index are bad to create labels\n",
    "y = [x in bads for x in X.index]\n",
    "\n",
    "# Report the average accuracy of Adaboost over 3-fold CV\n",
    "print(np.mean(cross_val_score(AdaBoostClassifier(), X, y)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You have successfully incorporated your analyst's feedback. Let's now try to add some more features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou just achieved a further improvement by adding the number of unique protocols used by each source as a feature.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Feature engineering on grouped data\n",
    "\n",
    "You will now build on the previous exercise, by considering one additional feature: the number of unique protocols used by each source computer. Note that with grouped data, it is always possible to construct features in this manner: you can take the number of unique elements of all categorical columns, and the mean of all numeric columns as your starting point. As before, you have flows preloaded, cross_val_score() for measuring accuracy, AdaBoostClassifier(), pandas as pd and numpy as np.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Apply a lambda function on the group iterator provided, to compute the number of unique protocols used by each source computer. You can use set() to reduce the protocol column to a set of unique values.\n",
    "    Convert the result to a data frame with the right shape by providing an index and naming the column protocol.\n",
    "    Concatenate the new data frame with the old one, which is available as X.\n",
    "    Assess the accuracy of AdaBoostClassifier() on this new dataset using cross_val_score().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a feature counting unique protocols per source\n",
    "protocols = flows.groupby('source_computer').apply(\n",
    "    lambda df: len(set(df['protocol'])))\n",
    "\n",
    "# Convert this feature into a dataframe, naming the column\n",
    "protocols_DF = pd.DataFrame(\n",
    "    protocols, index=protocols.index, columns=['protocol'])\n",
    "\n",
    "# Now concatenate this feature with the previous dataset, X\n",
    "X_more = pd.concat([X, protocols_DF], axis=1)\n",
    "\n",
    "# Refit the classifier and report its accuracy\n",
    "print(np.mean(cross_val_score(\n",
    "  AdaBoostClassifier(),X_more, y)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You just achieved a further improvement by adding the number of unique protocols used by each source as a feature.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194630872483222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWell done! Isn't it surprising how well a simple heuristic can do on a real problem? Let's see if we can find more such simple rules.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Turning a heuristic into a classifier\n",
    "\n",
    "You are surprised by the fact that heuristics can be so helpful. So you decide to treat the heuristic that \"too many unique ports is suspicious\" as a classifier in its own right. You achieve that by thresholding the number of unique ports per source by the average number used in bad source computers -- these are computers for which the label is True. The dataset is preloaded and split into training and test, so you have objects X_train, X_test, y_train and y_test in memory. Your imports include accuracy_score(), and numpy as np. To clarify: you won't be fitting a classifier from scikit-learn in this exercise, but instead you will define your own classification rule explicitly!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Subselect all bad hosts from X_train to form a new dataset X_train_bad. Note that y_train is a Boolean array.\n",
    "    Calculate the average of the unique_ports column for bad hosts, and store it in avg_bad_ports.\n",
    "    Now consider a classifier that predicts as positive every example whose unique_ports exceed avg_bad_ports. Save the predictions of this classifier on the test data on a new variable, pred_port.\n",
    "    Calculate this classifier's accuracy on the test data using accuracy_score().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a new dataset X_train_bad by subselecting bad hosts\n",
    "X_train_bad = X_train[y_train]\n",
    "\n",
    "# Calculate the average of unique_ports in bad examples\n",
    "avg_bad_ports = np.mean(X_train_bad['unique_ports'])\n",
    "\n",
    "# Label as positive sources that use more ports than that\n",
    "pred_port = X_test['unique_ports'] > avg_bad_ports\n",
    "\n",
    "# Print the accuracy of the heuristic\n",
    "print(accuracy_score(y_test, pred_port))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! Isn't it surprising how well a simple heuristic can do on a real problem? Let's see if we can find more such simple rules.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328859060402684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe combined rule does pretty well! Often expert knowledge comes in the form of logical combinations of a large number of simple heuristics.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Combining heuristics\n",
    "\n",
    "A different cyber analyst tells you that during certain types of attack, the infected source computer sends small bits of traffic, to avoid detection. This makes you wonder whether it would be better to create a combined heuristic that simultaneously looks for large numbers of ports and small packet sizes. Does this improve performance over the simple port heuristic? As with the last exercise, you have X_train, X_test, y_train and y_test in memory. The sample code also helps you reproduce the outcome of the port heuristic, pred_port. You also have numpy as np and accuracy_score() preloaded.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    The column average_packet computes the average packet size over all flows observed from a single source. Take the mean of those values for bad sources only on the training set.\n",
    "    Now construct a new rule which flags as positive all sources whose average traffic is less than the value above.\n",
    "    Combine the rules so that both heuristics have to simultaneously apply, using an appropriate arithmetic operation.\n",
    "    Report the accuracy of the combined heuristic.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Compute the mean of average_packet for bad sources\n",
    "avg_bad_packet = np.mean(X_train[y_train]['average_packet'])\n",
    "\n",
    "# Label as positive if average_packet is lower than that\n",
    "pred_packet = X_test['average_packet'] < avg_bad_packet\n",
    "\n",
    "# Find indices where pred_port and pred_packet both True\n",
    "pred_port = X_test['unique_ports'] > avg_bad_ports\n",
    "pred_both = pred_packet & pred_port\n",
    "\n",
    "# Ports only produced an accuracy of 0.919. Is this better?\n",
    "print(accuracy_score(y_test, pred_both))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "The combined rule does pretty well! Often expert knowledge comes in the form of logical combinations of a large number of simple heuristics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_noisy = pd.read_csv(path_data+'y_train_noisy.csv').values.ravel()\n",
    "y_train_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14093959731543623\n",
      "0.1476510067114094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWonderful! You now have a way to handle noise in labels, by using weights that reflect your prior beliefs about their accuracy.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Dealing with label noise\n",
    "\n",
    "One of your cyber analysts informs you that many of the labels for the first 100 source computers in your training data might be wrong because of a database error. She hopes you can still use the data because most of the labels are still correct, but asks you to treat these 100 labels as \"noisy\". Thankfully you know how to do that, using weighted learning. The contaminated data is available in your workspace as X_train, X_test, y_train_noisy, y_test. You want to see if you can improve the performance of a GaussianNB() classifier using weighted learning. You can use the optional parameter sample_weight, which is supported by the .fit() methods of most popular classifiers. The function accuracy_score() is preloaded. You can consult the image below for guidance. \n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Fit an instance of GaussianNB() to the training data with the contaminated labels.\n",
    "    Report its accuracy on the test data using accuracy_score().\n",
    "    Create weights that assign twice as much weight to ground truth labels than to noisy labels. Remember that the weights concern the training data.\n",
    "    Refit the classifier using the above weights and report its accuracy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Fit a Gaussian Naive Bayes classifier to the training data\n",
    "clf = GaussianNB().fit(X_train, y_train_noisy)\n",
    "\n",
    "# Report its accuracy on the test data\n",
    "print(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Assign half the weight to the first 100 noisy examples\n",
    "weights = [0.5]*100 + [1.0]*(len(y_train_noisy)-100)\n",
    "\n",
    "# Refit using weights and report accuracy. Has it improved?\n",
    "clf_weights = GaussianNB().fit(X_train, y_train_noisy, sample_weight=weights)\n",
    "print(accuracy_score(y_test, clf_weights.predict(X_test)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Wonderful! You now have a way to handle noise in labels, by using weights that reflect your prior beliefs about their accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mCompute the F1 score for your classifier using the function f1_score().\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m---\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mAccuracy is the proportion of examples that were labelled correctly. Compute it without using accuracy_score().\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# solution\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mprint\u001b[39m(f1_score(y_test, preds))\n\u001b[1;32m     23\u001b[0m \u001b[39m#----------------------------------#\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(precision_score(y_test, preds))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Reminder of performance metrics\n",
    "\n",
    "Remember the credit dataset? With all the extra knowledge you now have about metrics, let's have another look at how good a random forest is on this dataset. You have already trained your classifier and obtained your confusion matrix on the test data. The test data and the results are available to you as tp, fp, fn and tn, for true positives, false positives, false negatives, and true negatives respectively. You also have the ground truth labels for the test data, y_test and the predicted labels, preds. The functions f1_score() and precision_score() have also been imported.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Compute the F1 score for your classifier using the function f1_score().\n",
    "---\n",
    "Compute the precision for this classifier using the function precision_score().\n",
    "---\n",
    "Accuracy is the proportion of examples that were labelled correctly. Compute it without using accuracy_score().\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "print(f1_score(y_test, preds))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "print(precision_score(y_test, preds))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "print((tp + tn)/len(y_test))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! You have mastered a number of performance metrics which will give you a lot of extra options when the time comes to build your own pipeline.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>6</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>buy_radio_tv</td>\n",
       "      <td>1169</td>\n",
       "      <td>'no known savings'</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>4</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>67</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'0&lt;=X&lt;200'</td>\n",
       "      <td>48</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>buy_radio_tv</td>\n",
       "      <td>5951</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>2</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>22</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'no checking'</td>\n",
       "      <td>12</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>education</td>\n",
       "      <td>2096</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>49</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>'unskilled resident'</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>42</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>buy_furniture_equipment</td>\n",
       "      <td>7882</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>'life insurance'</td>\n",
       "      <td>45</td>\n",
       "      <td>none</td>\n",
       "      <td>'for free'</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>24</td>\n",
       "      <td>'delayed previously'</td>\n",
       "      <td>buy_new_car</td>\n",
       "      <td>4870</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>3</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'no known property'</td>\n",
       "      <td>53</td>\n",
       "      <td>none</td>\n",
       "      <td>'for free'</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration                    credit_history  \\\n",
       "0            '<0'         6  'critical/other existing credit'   \n",
       "1      '0<=X<200'        48                   'existing paid'   \n",
       "2   'no checking'        12  'critical/other existing credit'   \n",
       "3            '<0'        42                   'existing paid'   \n",
       "4            '<0'        24              'delayed previously'   \n",
       "\n",
       "                   purpose  credit_amount      savings_status employment  \\\n",
       "0             buy_radio_tv           1169  'no known savings'      '>=7'   \n",
       "1             buy_radio_tv           5951              '<100'   '1<=X<4'   \n",
       "2                education           2096              '<100'   '4<=X<7'   \n",
       "3  buy_furniture_equipment           7882              '<100'   '4<=X<7'   \n",
       "4              buy_new_car           4870              '<100'   '1<=X<4'   \n",
       "\n",
       "   installment_commitment       personal_status other_parties  ...  \\\n",
       "0                       4         'male single'          none  ...   \n",
       "1                       2  'female div/dep/mar'          none  ...   \n",
       "2                       2         'male single'          none  ...   \n",
       "3                       2         'male single'     guarantor  ...   \n",
       "4                       3         'male single'          none  ...   \n",
       "\n",
       "    property_magnitude age  other_payment_plans     housing existing_credits  \\\n",
       "0        'real estate'  67                 none         own                2   \n",
       "1        'real estate'  22                 none         own                1   \n",
       "2        'real estate'  49                 none         own                1   \n",
       "3     'life insurance'  45                 none  'for free'                1   \n",
       "4  'no known property'  53                 none  'for free'                2   \n",
       "\n",
       "                    job num_dependents  own_telephone foreign_worker class  \n",
       "0               skilled              1            yes            yes  good  \n",
       "1               skilled              1           none            yes   bad  \n",
       "2  'unskilled resident'              2           none            yes  good  \n",
       "3               skilled              2           none            yes  good  \n",
       "4               skilled              2           none            yes   bad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(path_data + 'credit.csv')\n",
    "display(data.head())\n",
    "\n",
    "non_numeric_columns = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker']\n",
    "\n",
    "# solution\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder for each column. Encode the values\n",
    "for column in non_numeric_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "\n",
    "y = data['class']\n",
    "X = data.drop('class',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood work. This sort of analysis is the only way to assess what the actual impact of your classifier will be in the real world.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Real-world cost analysis\n",
    "\n",
    "You will still work on the credit dataset for this exercise. Recall that a \"positive\" in this dataset means \"bad credit\", i.e., a customer who defaulted on their loan, and a \"negative\" means a customer who continued to pay without problems. The bank manager informed you that the bank makes 10K profit on average from each \"good risk\" customer, but loses 150K from each \"bad risk\" customer. Your algorithm will be used to screen applicants, so those that are labeled as \"negative\" will be given a loan, and the \"positive\" ones will be turned down. What is the total cost of your classifier? The data is available as X_train, X_test, y_train and y_test. The functions confusion_matrix(), f1_score(), and precision_score() and RandomForestClassifier() are available.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Fit a random forest classifier to the training data.\n",
    "    Use it to label the test data.\n",
    "    Extract the false negatives and false positives from confusion_matrix(). You will have to flatten the matrix.\n",
    "    Falsely classifying a \"good\" customer as \"bad\" means that the bank would have lost the chance to make 10K profit. Falsely classifying a \"bad\" customer as \"good\" means that the bank would have lost 150K due to the customer defaulting on their loan.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Fit a random forest classifier to the training data\n",
    "clf = RandomForestClassifier(random_state=2).fit(X_train, y_train)\n",
    "\n",
    "# Label the test data\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "# Get false positives/negatives from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# Now compute the cost using the manager's advice\n",
    "cost = fp*10 + fn*150\n",
    "print(cost)\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good work. This sort of analysis is the only way to assess what the actual impact of your classifier will be in the real world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 45, 15, 163)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(path_data+'X_ex08.csv').drop(columns=['Unnamed: 0'])\n",
    "y = pd.read_csv(path_data+'y_ex08.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nWell done, you have confirmed that this classifier, too, uses 0.5 as a threshold. You will later see how to tune that threshold to fit your purposes.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Default thresholding\n",
    "\n",
    "You would like to confirm that the DecisionTreeClassifier() uses the same default classification threshold as mentioned in the previous lesson, namely 0.5. It seems strange to you that all classifiers should use the same threshold. Let's check! A fitted decision tree classifier clf has been preloaded for you, as have the training and test data with their usual names: X_train, X_test, y_train and y_test. You will have to extract probability scores from the classifier using the .predict_proba() method.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Produce scores for the test examples, using the preloaded classifier clf.\n",
    "    Now extract labels from the scores. Remember that you have a pair of scores for each example, not a single score, and the second element is the probability of the positive class.\n",
    "    Now label the test data using the standard .predict() method\n",
    "    Finally, compare with the predictions you got before. Are they identical?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Score the test data using the given classifier\n",
    "scores = clf.predict_proba(X_test)\n",
    "\n",
    "# Get labels from the scores using the default threshold\n",
    "preds = [s[1] > 0.5 for s in scores]\n",
    "\n",
    "# Use the predict method to label the test data again\n",
    "preds_default = clf.predict(X_test)\n",
    "\n",
    "# Compare the two sets of predictions\n",
    "display(all(preds == preds_default))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done, you have confirmed that this classifier, too, uses 0.5 as a threshold. You will later see how to tune that threshold to fit your purposes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou were right to be suspicious: in practice, accuracy is sometimes optimized with a threshold other than 0.5. Moreover, if you want to use a different metric, you should re-tune your threshold!\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Optimizing the threshold\n",
    "\n",
    "You heard that the default value of 0.5 maximizes accuracy in theory, but you want to test what happens in practice. So you try out a number of different threshold values, to see what accuracy you get, and hence determine the best-performing threshold value. You repeat this experiment for the F1 score. Is 0.5 the optimal threshold? Is the optimal threshold for accuracy and for the F1 score the same? Go ahead and find out! You have a scores matrix available, obtained by scoring the test data. The ground truth labels for the test data is also available as y_test. Finally, two numpy functions are preloaded, argmin() and argmax(), which retrieve the index of the minimum and maximum values in an array respectively, in addition to the metrics accuracy_score() and f1_score().\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a range of threshold values that include 0.0, 0.25, 0.5, 0.75 and 1.0.\n",
    "    Via double list comprehension, store the predictions for each threshold value in the range above. Recall that obtaining labels for a scores matrix using a threshold thr is possible using [s[1] > thr for s in scores].\n",
    "    Run through that list and compute the accuracy for each threshold. Repeat for the F1 score.\n",
    "    Using either argmin() or argmax(), find the optimal threshold for accuracy, and for F1.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.metrics import f1_score\n",
    "# Create a range of equally spaced threshold values\n",
    "t_range = [0.0,0.25,0.5,0.75,1.0]\n",
    "\n",
    "# Store the predicted labels for each value of the threshold\n",
    "preds = [[s[1] > thr for s in scores] for thr in t_range]\n",
    "\n",
    "# Compute the accuracy for each threshold\n",
    "accuracies = [accuracy_score(y_test, p) for p in preds]\n",
    "\n",
    "# Compute the F1 score for each threshold\n",
    "f1_scores = [f1_score(y_test, p) for p in preds]\n",
    "\n",
    "# Report the optimal threshold for accuracy, and for F1\n",
    "print(t_range[np.argmax(accuracies)], t_range[np.argmax(f1_scores)])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You were right to be suspicious: in practice, accuracy is sometimes optimized with a threshold other than 0.5. Moreover, if you want to use a different metric, you should re-tune your threshold!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_data+'arrh.csv')\n",
    "X = data.drop('class',axis=1)\n",
    "y = data['class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.0\n",
      "160.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat work! You have mastered the art of using weights in order to assign different importance to different parts of the data. Time to revisit your optimization skills using pipelines.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "Bringing it all together\n",
    "\n",
    "One of the engineers in your arrhythmia detection startup rushes into your office to let you know that there is a problem with the ECG sensor for overweight users. You decide to reduce the influence of examples with weight over 80 by 50%. You are also told that since your startup is targeting the fitness market and makes no medical claims, scaring an athlete unnecessarily is costlier than missing a possible case of arrhythmia. You decide to create a custom loss that makes each \"false alarm\" ten times costlier than missing a case of arrhythmia. Does down-weighting overweight subjects improve this custom loss? Your training data X_train, y_train and test data X_test, y_test are preloaded, as are confusion_matrix(), numpy as np, and DecisionTreeClassifier().\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Start by creating a custom loss which extracts the false positives and false negatives from the confusion matrix, and then makes each false alarm count ten times as much as a missed case of arrhythmia.\n",
    "---\n",
    "\n",
    "    Fit a DecisionTreeClassifier to the original data and estimate this loss.\n",
    "---\n",
    "\n",
    "    Create a list of weights so that each example where the weight is greater than 80 has half the weight of any other example. Does this improve your loss?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a scorer assigning more cost to false positives\n",
    "def my_scorer(y_test, y_est, cost_fp=10.0, cost_fn=1.0):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_est).ravel()\n",
    "    return cost_fp*fp + cost_fn*fn\n",
    "\n",
    "# Fit a DecisionTreeClassifier to the data and compute the loss\n",
    "clf = DecisionTreeClassifier(random_state=2).fit(X_train, y_train)\n",
    "print(my_scorer(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Refit with same seed, downweighting subjects weighing > 80\n",
    "weights = [0.5 if w > 80 else 1.0 for w in X_train.weight]\n",
    "clf_weighted = DecisionTreeClassifier(random_state=2).fit(\n",
    "  X_train,y_train, sample_weight=weights)\n",
    "print(my_scorer(y_test, clf_weighted.predict(X_test)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great work! You have mastered the art of using weights in order to assign different importance to different parts of the data. Time to revisit your optimization skills using pipelines.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
