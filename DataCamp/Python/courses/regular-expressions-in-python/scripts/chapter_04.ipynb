{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
    " 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
    " 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat job! Remember that placing a subpattern inside parenthesis will capture that content and stores it temporarily in memory. This can be later reused.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Try another name\n",
    "\n",
    "You are still working on your Twitter sentiment analysis. You analyze now some things that caught your attention. You noticed that there are email addresses inserted in some tweets. Now, you are curious to find out which is the most common name.\n",
    "\n",
    "You want to extract the first part of the email. E.g. if you have the email marysmith90@gmail.com, you are only interested in marysmith90.\n",
    "You need to match the entire expression. So you make sure to extract only names present in emails. Also, you are only interested in names containing upper (e.g. A,B, Z) or lowercase letters (e.g. a, d, z) and numbers.\n",
    "\n",
    "The list sentiment_analysis containing the text of three tweets as well as the re module were loaded in your session. You can use print() to view it in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the regex to match the email capturing only the name part. The name part appears before the @.\n",
    "    Find all matches of the regex in each element of sentiment_analysis analysis. Assign it to the variable email_matched.\n",
    "    Complete the .format() method to print the results captured in each element of sentiment_analysis analysis.\n",
    "\n",
    "\"\"\"\n",
    "import re\n",
    "# solution\n",
    "\n",
    "# Write a regex that matches email\n",
    "regex_email = r\"([A-Za-z0-9]+)@\\S+\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print(\"Lists of users found in this tweet: {}\".format(email_matched))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! Remember that placing a subpattern inside parenthesis will capture that content and stores it temporarily in memory. This can be later reused.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = 'Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat job! findall() returns a list of tuples. The nth element of each tuple is the element corresponding to group n. This provides us with an easy way to access and organize our data.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Flying home\n",
    "\n",
    "Your boss assigned you to a small project. They are performing an analysis of the travels people made to attend business meetings. You are given a dataset with only the email subjects for each of the people traveling.\n",
    "\n",
    "You learn that the text followed a pattern. Here is an example:\n",
    "\n",
    "Here you have your boarding pass LA4214 AER-CDB 06NOV.\n",
    "\n",
    "You need to extract the information about the flight:\n",
    "\n",
    "    The two letters indicate the airline (e.g LA),\n",
    "    The 4 numbers are the flight number (e.g. 4214).\n",
    "    The three letters correspond to the departure (e.g AER),\n",
    "    The destination (CDB),\n",
    "    The date (06NOV) of the flight.\n",
    "\n",
    "All letters are always uppercase.\n",
    "\n",
    "The variable flight containing one email subject was loaded in your session. You can use print() to view it in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Import the re module.\n",
    "---\n",
    "Complete the regular expression to match and capture all the flight information required. Only the first parenthesis were placed for you.\n",
    "---\n",
    "Find all the matches corresponding to each piece of information about the flight. Assign it to flight_matches.\n",
    "---\n",
    "Complete the format method with the elements contained in flight_matches. In the first line print the airline, and the flight number. In the second line, the departure and destination. In the third line, the date.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "    \n",
    "#Print the matches\n",
    "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print(\"Date: {}\".format(flight_matches[0][4]))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! findall() returns a list of tuples. The nth element of each tuple is the element corresponding to group n. This provides us with an easy way to access and organize our data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
    " 'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
    " \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
      "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
      "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat job! The pipe operator works by comparing everything that is to its left with everything to the right. Grouping optional patterns is the way to get the correct result.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Love it!\n",
    "\n",
    "You are still working on the Twitter sentiment analysis project. First, you want to identify positive tweets about movies and concerts.\n",
    "\n",
    "You plan to find all the sentences that contain the words love, like, or enjoy and capture that word. You will limit the tweets by focusing on those that contain the words movie or concert by keeping the word in another group. You will also save the movie or concert name.\n",
    "\n",
    "For example, if you have the sentence: I love the movie Avengers. You match and capture love. You need to match and capture movie. Afterwards, you match and capture anything until the dot.\n",
    "\n",
    "The list sentiment_analysis containing the text of three tweets and the re module are loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the regular expression to capture the words love or like or enjoy. Match and capture the words movie or concert. Match and capture anything appearing until the ..\n",
    "    Find all matches of the regex in each element of sentiment_analysis. Assign them to positive_matches.\n",
    "    Complete the .format() method to print out the results contained in positive_matches for each element in sentiment_analysis.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive =r\"(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Positive comments found {}\".format(positive_matches))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! The pipe operator works by comparing everything that is to its left with everything to the right. Grouping optional patterns is the way to get the correct result.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
    " \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
    " 'I dislike very much the concert After twelve Tour. The sound was horrible.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', 'The cabin and the ant')]\n",
      "Negative comments found [('disapprove', 'Honest with you')]\n",
      "Negative comments found [('dislike', 'After twelve Tour')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nNice job! Non-capturing groups are very often used together with alternation. Sometimes you have optional patterns and you need to group them. However you are not interested in keeping them. It's a nice feature of regex.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Ugh! Not for me!\n",
    "\n",
    "After finding positive tweets, you want to do it for negative tweets. Your plan now is to find sentences that contain the words hate, dislike or disapprove. You will again save the movie or concert name. You will get the tweet containing the words movie or concert but this time, you don't plan to save the word.\n",
    "\n",
    "For example, if you have the sentence: I dislike the movie Avengers a lot.. You match and capture dislike. You will match but not capture the word movie. Afterwards, you match and capture anything until the dot.\n",
    "\n",
    "The list sentiment_analysis containing the text of three tweets as well as the re module are loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the regular expression to capture the words hate or dislike or disapprove. Match but don't capture the words movie or concert. Match and capture anything appearing until the ..\n",
    "    Find all matches of the regex in each element of sentiment_analysis. Assign them to negative_matches.\n",
    "    Complete the .format() method to print out the results contained in negative_matches for each element in sentiment_analysis.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Write a regex that matches sentences with the optional words\n",
    "regex_negative = r\"(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Negative comments found {}\".format(negative_matches))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice job! Non-capturing groups are very often used together with alternation. Sometimes you have optional patterns and you need to group them. However you are not interested in keeping them. It's a nice feature of regex.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Provider’s status as an independent contractor. Signed on 03/25/2001.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAmazing job! Remember that each capturing group is assigned a number according to its position in the regex. Only if you use .search() and .match(), you can use .group() to retrieve the groups.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Parsing PDF files\n",
    "\n",
    "You now need to work on another small project you have been delaying. Your company gave you some PDF files of signed contracts. The goal of the project is to create a database with the information you parse from them. Three of these columns should correspond to the day, month, and year when the contract was signed.\n",
    "The dates appear as Signed on 05/24/2016 (05 indicating the month, 24 the day). You decide to use capturing groups to extract this information. Also, you would like to retrieve that information so you can store it separately in different variables.\n",
    "\n",
    "You decide to do a proof of concept.\n",
    "\n",
    "The variable contract containing the text of one contract and the re module are already loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Write a regex that captures the month, day, and year in which the contract was signed. Scan contract for matches.\n",
    "---\n",
    "\n",
    "    Assign each captured group to the corresponding keys in the dictionary.\n",
    "---\n",
    "\n",
    "    Complete the positional method to print out the captured groups. Use the values corresponding to each key in the dictionary.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "\t\"day\": dates.group(2),\n",
    "\t\"month\": dates.group(1),\n",
    "\t\"year\": dates.group(3)\n",
    "}\n",
    "# Complete the format method to print-out\n",
    "print(\"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Amazing job! Remember that each capturing group is assigned a number according to its position in the regex. Only if you use .search() and .match(), you can use .group() to retrieve the groups.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_tags = ['<body>Welcome to our course! It would be an awesome experience</body>',\n",
    " '<article>To be a data scientist, you need to have knowledge in statistics and mathematics</article>',\n",
    " '<nav>About me Links Contact me!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tag body is closed\n",
      "Your tag article is closed\n",
      "Close your nav tag!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat job! Backreferences are very helpful when you need to reuse part of the regex match inside the regex. Knowing when and how to use them will simplify many of your tasks!\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Close the tag, please!\n",
    "\n",
    "In the meantime, you are working on one of your other projects. The company is going to develop a new product. It will help developers automatically check the code they are writing. You need to write a short script for checking that every HTML tag that is open has its proper closure.\n",
    "\n",
    "You have an example of a string containing HTML tags:\n",
    "\n",
    "<title>The Data Science Company</title>\n",
    "\n",
    "You learn that an opening HTML tag is always at the beginning of the string. It appears inside <>. A closing tag also appears inside <>, but it is preceded by /.\n",
    "\n",
    "You also remember that capturing groups can be referenced using numbers, e.g \\4.\n",
    "\n",
    "The list html_tags, containing three strings with HTML tags, and there module are loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the regex in order to match closed HTML tags. Find if there is a match in each string of the list html_tags. Assign the result to match_tag.\n",
    "    If a match is found, print the first group captured and saved in match_tag.\n",
    "    If no match is found, complete the regex to match only the text inside the HTML tag. Assign it to notmatch_tag.\n",
    "    Print the first group captured by the regex and save it in notmatch_tag.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "for string in html_tags:\n",
    "    # Complete the regex and find if it matches a closed HTML tags\n",
    "    match_tag =  re.match(r\"<(\\w+)>.*?</\\1>\", string)\n",
    " \n",
    "    if match_tag:\n",
    "        # If it matches print the first group capture\n",
    "        print(\"Your tag {} is closed\".format(match_tag.group(1))) \n",
    "    else:\n",
    "        # If it doesn't match capture only the tag \n",
    "        notmatch_tag = re.match(r\"<(\\w+)>\", string)\n",
    "        # Print the first group capture\n",
    "        print(\"Close your {} tag!\".format(notmatch_tag.group(1)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job! Backreferences are very helpful when you need to reuse part of the regex match inside the regex. Knowing when and how to use them will simplify many of your tasks!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
    " 'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
    " 'Just woke up an already have read some e-mail']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Explanation\n",
    "\n",
    "The regex_elongated variable is assigned a regular expression pattern that matches elongated words. \n",
    "The pattern \\w*(\\w)\\1\\w* works by looking for a word character (\\w), followed by any number of word characters (\\w*), then a group consisting of a single word character ((\\w)), followed by the same character as in the most recent group (\\1), and finally any number of word characters (\\w*). \n",
    "The (\\w)\\1 part of the pattern is what allows it to match elongated words, because it looks for a character that is immediately repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elongated word found: Moscooooooow\n",
      "Elongated word found: neighborrrrrrrs\n",
      "No elongated word found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWell done! You should remember that the group zero stands for the entire expression matched. It's always helpful to keep that in mind. Sometimes you will need to use it.\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Reeepeated characters\n",
    "\n",
    "Back to your sentiment analysis! Your next task is to replace elongated words that appear in the tweets. We define an elongated word as a word that contains a repeating character twice or more times. e.g. \"Awesoooome\".\n",
    "\n",
    "Replacing those words is very important since a classifier will treat them as a different term from the source words lowering their frequency.\n",
    "\n",
    "To find them, you will use capturing groups and reference them back using numbers. E.g \\4.\n",
    "\n",
    "If you want to find a match for Awesoooome. You first need to capture Awes. Then, match o and reference the same character back, and then, me.\n",
    "\n",
    "The list sentiment_analysis, containing the text of three tweets, and the re module are loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Complete the regular expression to match an elongated word as described.\n",
    "    Search the elements in sentiment_analysis list to find out if they contain elongated words. Assign the result to match_elongated.\n",
    "    Assign the captured group number zero to the variable elongated_word.\n",
    "    Print the result contained in the variable elongated_word.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Complete the regex to match an elongated word\n",
    "regex_elongated = r\"\\w*(\\w)\\1\\w*\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find if there is a match in each tweet \n",
    "\tmatch_elongated = re.search(regex_elongated, tweet)\n",
    "    \n",
    "\tif match_elongated:\n",
    "\t\t# Assign the captured group zero \n",
    "\t\telongated_word = match_elongated.group(0)\n",
    "        \n",
    "\t\t# Complete the format method to print the word\n",
    "\t\tprint(\"Elongated word found: {word}\".format(word=elongated_word))\n",
    "\telse:\n",
    "\t\tprint(\"No elongated word found\")     \t\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! You should remember that the group zero stands for the entire expression matched. It's always helpful to keep that in mind. Sometimes you will need to use it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'You need excellent python skills to be a data scientist. Must be! Excellent python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'Excellent']\n",
      "['skills']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNice job! It is important to know that positive lookahead will return the text matched by the first part of the expression after asserting that it is followed by the lookahead expression while positive lookbehind will return all matches that follow a specific pattern. Interesting!\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Surrounding words\n",
    "\n",
    "Now, you want to perform some visualizations with your sentiment_analysis dataset. You are interested in the words surrounding python. You want to count how many times a specific word appears right before and after it.\n",
    "\n",
    "Positive lookahead (?=) makes sure that first part of the expression is followed by the lookahead expression. Positive lookbehind (?<=) returns all matches that are preceded by the specified pattern.\n",
    "\n",
    "The variable sentiment_analysis, containing the text of one tweet, and the re module are loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Get all the words that are followed by the word python in sentiment_analysis. Print out the word found.\n",
    "---\n",
    "Get all the words that are preceded by the word python or Python in sentiment_analysis. Print out the words found.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Positive lookahead\n",
    "look_ahead = re.findall(r\"\\w+(?=\\spython)\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_ahead)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Positive lookbehind\n",
    "look_behind = re.findall(r\"(?<=[Pp]ython\\s)\\w+\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_behind)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice job! It is important to know that positive lookahead will return the text matched by the first part of the expression after asserting that it is followed by the lookahead expression while positive lookbehind will return all matches that follow a specific pattern. Interesting!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellphones = ['4564-646464-01', '345-5785-544245', '6476-579052-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4564-646464-01']\n",
      "[]\n",
      "['6476-579052-01']\n",
      "[]\n",
      "['345-5785-544245']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNice job! Negative lookarounds work in a similar way to positive lookarounds. They are very helpful when we are looking to exclude certain patterns from our analysis.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Filtering phone numbers\n",
    "\n",
    "Now, you need to write a script for a cell-phone searcher. It should scan a list of phone numbers and return those that meet certain characteristics.\n",
    "\n",
    "The phone numbers in the list have the structure:\n",
    "\n",
    "    Optional area code: 3 numbers\n",
    "    Prefix: 4 numbers\n",
    "    Line number: 6 numbers\n",
    "    Optional extension: 2 numbers\n",
    "\n",
    "E.g. 654-8764-439434-01.\n",
    "\n",
    "You decide to use .findall() and the non-capturing group's negative lookahead (?!) and negative lookbehind (?<!).\n",
    "\n",
    "The list cellphones, containing three phone numbers, and the re module are loaded in your session. You can use print() to view the data in the IPython Shell.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Get all cell phones numbers that are not preceded by the optional area code.\n",
    "---\n",
    "Get all the cell phones numbers that are not followed by the optional extension.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not preceded by area code\n",
    "\tnumber = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
    "\tprint(number)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "for phone in cellphones:\n",
    "\t# Get all phone numbers not followed by optional extension\n",
    "\tnumber = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
    "\tprint(number)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice job! Negative lookarounds work in a similar way to positive lookarounds. They are very helpful when we are looking to exclude certain patterns from our analysis.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
