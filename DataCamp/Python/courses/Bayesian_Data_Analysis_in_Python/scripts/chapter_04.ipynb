{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_day</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>num_bikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.265833</td>\n",
       "      <td>0.687917</td>\n",
       "      <td>0.175996</td>\n",
       "      <td>2.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.622174</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>3.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>0.147379</td>\n",
       "      <td>4.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.256667</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.133721</td>\n",
       "      <td>2.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.562083</td>\n",
       "      <td>0.194037</td>\n",
       "      <td>3.830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_day      temp  humidity  wind_speed  num_bikes\n",
       "0         0  0.265833  0.687917    0.175996      2.947\n",
       "1         1  0.282609  0.622174    0.153800      3.784\n",
       "2         1  0.354167  0.496250    0.147379      4.375\n",
       "3         1  0.256667  0.722917    0.133721      2.802\n",
       "4         1  0.265000  0.562083    0.194037      3.830"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "bikes = pd.read_csv(path_data+'bikes_test.csv')\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/scalar/basic.py:2323: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  self.ctor = getattr(np, o_type.dtype)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m    Reorder the code lines to sample posterior draws, remembering to indent the lines that need it.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# solution\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpymc3\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpm\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m formula \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnum_bikes ~ temp + work_day\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nero/Documents/Estudos/DataCamp/Python/courses/Bayesian_Data_Analysis_in_Python/scripts/chapter_04.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mwith\u001b[39;00m pm\u001b[39m.\u001b[39mModel() \u001b[39mas\u001b[39;00m model_1:\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/pymc3/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplatform\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msemver\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtheano\u001b[39;00m\n\u001b[1;32m     25\u001b[0m _log \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m\"\u001b[39m\u001b[39mpymc3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mhandlers:\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/__init__.py:124\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msafe_asarray\u001b[39;00m \u001b[39mimport\u001b[39;00m _asarray\n\u001b[1;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprinting\u001b[39;00m \u001b[39mimport\u001b[39;00m pprint, pp\n\u001b[0;32m--> 124\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscan_module\u001b[39;00m \u001b[39mimport\u001b[39;00m (scan, \u001b[39mmap\u001b[39m, reduce, foldl, foldr, clone,\n\u001b[1;32m    125\u001b[0m                                 scan_checkpoints)\n\u001b[1;32m    127\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mupdates\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedUpdates\n\u001b[1;32m    129\u001b[0m \u001b[39m# scan_module import above initializes tensor and scalar making these imports\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m# redundant\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39m# import sparse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/scan_module/__init__.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m __copyright__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m(c) 2010, Universite de Montreal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m __contact__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRazvan Pascanu <r.pascanu@gmail>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscan_module\u001b[39;00m \u001b[39mimport\u001b[39;00m scan_opt\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscan_module\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscan\u001b[39;00m \u001b[39mimport\u001b[39;00m scan\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscan_module\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscan_checkpoints\u001b[39;00m \u001b[39mimport\u001b[39;00m scan_checkpoints\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/scan_module/scan_opt.py:60\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtheano\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor, scalar\n\u001b[1;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m opt, get_scalar_constant_value, Alloc, AllocEmpty\n\u001b[1;32m     62\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m \u001b[39mimport\u001b[39;00m gof\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/tensor/__init__.py:8\u001b[0m\n\u001b[1;32m      4\u001b[0m __docformat__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrestructuredtext en\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbasic\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msubtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtype_other\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/tensor/basic.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgof\u001b[39;00m \u001b[39mimport\u001b[39;00m Apply, Constant, Op, Variable, ParamsType\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgof\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtype\u001b[39;00m \u001b[39mimport\u001b[39;00m Generic\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscalar\u001b[39;00m \u001b[39mimport\u001b[39;00m int32 \u001b[39mas\u001b[39;00m int32_t\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m elemwise\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtheano\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvar\u001b[39;00m \u001b[39mimport\u001b[39;00m (AsTensorError, TensorVariable,\n\u001b[1;32m     23\u001b[0m                                TensorConstant, TensorConstantSignature,\n\u001b[1;32m     24\u001b[0m                                _tensor_py_operators)\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/scalar/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import, print_function, division\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbasic\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbasic_scipy\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/scalar/basic.py:2370\u001b[0m\n\u001b[1;32m   2367\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2368\u001b[0m             \u001b[39mreturn\u001b[39;00m s\n\u001b[0;32m-> 2370\u001b[0m convert_to_bool \u001b[39m=\u001b[39m Cast(\u001b[39mbool\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconvert_to_bool\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m   2371\u001b[0m convert_to_int8 \u001b[39m=\u001b[39m Cast(int8, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconvert_to_int8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2372\u001b[0m convert_to_int16 \u001b[39m=\u001b[39m Cast(int16, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconvert_to_int16\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/theano/scalar/basic.py:2323\u001b[0m, in \u001b[0;36mCast.__init__\u001b[0;34m(self, o_type, name)\u001b[0m\n\u001b[1;32m   2321\u001b[0m \u001b[39msuper\u001b[39m(Cast, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(specific_out(o_type), name\u001b[39m=\u001b[39mname)\n\u001b[1;32m   2322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mo_type \u001b[39m=\u001b[39m o_type\n\u001b[0;32m-> 2323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(np, o_type\u001b[39m.\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.11/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Sampling posterior draws\n",
    "\n",
    "Tired of working for the central government and for the marketing company, you take a new job as a data analyst for your city's local authorities. The city operates a bike-sharing system in the city and they ask you to predict the number of bikes rented per day to plan staff and repairs accordingly.\n",
    "\n",
    "You have been given some data on the number of rented vehicles per day, temperature, humidity, wind speed, and whether the day was a working day:\n",
    "\n",
    "     work_day      temp  humidity  wind_speed  num_bikes\n",
    "0           0  0.344167  0.805833    0.160446      0.985\n",
    "1           0  0.363478  0.696087    0.248539      0.801\n",
    "..        ...       ...       ...         ...        ...\n",
    "698         1  0.280870  0.555652    0.115522      5.323\n",
    "699         1  0.298333  0.649583    0.058471      5.668\n",
    "\n",
    "Try building a regression model to predict num_bikes using the bikes DataFrame and pymc3 (aliased as pm).\n",
    "\n",
    "NOTE: Calling pm.sample() for the first time in a fresh Python session takes some time, as Python code is being compiled to C under the hood. To save you time, we only ask you to get the code right instead of executing it.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Reorder the code lines to sample posterior draws, remembering to indent the lines that need it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "formula = 'num_bikes ~ temp + work_day'\n",
    "\n",
    "with pm.Model() as model_1:\n",
    "    pm.GLM.from_formula(formula, data=bikes)\n",
    "    trace_1 = pm.sample(draws=1000, tune=500)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! In just a couple of lines of code you can sample posterior draws in a Bayesian linear regression model! Let's take a look at what to do with the resulting trace!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Inspecting posterior draws\n",
    "\n",
    "You continue working on your task to predict the number of bikes rented per day in a bike-sharing system. The posterior draws from your regression model which you sampled before are available in your workspace as trace_1.\n",
    "\n",
    "You know that after obtaining the posteriors, it is best practice to take a look at them to see if they make sense and if the MCMC process has converged successfully. In this exercise, you will create two plots visualizing posterior draws and summarize them in a table. Let's inspect our posteriors!\n",
    "\n",
    "NOTE: Please allow up to half a minute for the plots to render, since they have many draws to process.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import pymc3 under its usual alias, pm.\n",
    "    Draw a trace plot of trace_1.\n",
    "    Draw a forest plot of trace_1.\n",
    "---\n",
    "Question\n",
    "\n",
    "Print the table with posterior draws' summary statistics by passing trace_1 to pm.summary(). Based on this table and the two plots you have just created, which of the following statements is false?\n",
    "\n",
    "    Given the 94% credible interval, we are not sure whether more bikes are rented in the working week than in the weekends.\n",
    "\n",
    "    Judging by the trace plot, sampling for all parameters has converged successfully.\n",
    "\n",
    "    The R-hat statistic signifies some convergence issues. (Answer)\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import pymc3\n",
    "import pymc3 as pm\n",
    "\n",
    "# Draw a trace plot of trace_1\n",
    "pm.traceplot(trace_1)\n",
    "plt.show()\n",
    "\n",
    "# Draw a forest plot of trace_1\n",
    "pm.forestplot(trace_1)\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct, this one's false! R-hat values above 1 signify convergence issues, and here R-hat is exactly 1 for all parameters, which denotes a successful convergence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Comparing models with WAIC\n",
    "\n",
    "Now that you have successfully built the first, basic model, you take another look at the data at your disposal. You notice a variable called wind_speed. This could be a great predictor of the numbers of bikes rented! Cycling against the wind is not that much fun, is it?\n",
    "\n",
    "You fit another model with this additional predictor:\n",
    "\n",
    "formula = \"num_bikes ~ temp + work_day + wind_speed\"\n",
    "\n",
    "with pm.Model() as model_2:\n",
    "    pm.GLM.from_formula(formula, data=bikes)\n",
    "    trace_2 = pm.sample(draws=1000, tune=500)\n",
    "\n",
    "Is your new model_2 better than model_1, the one without wind speed? Compare the two models using Widely Applicable Information Criterion, or WAIC, to find out!\n",
    "\n",
    "Both trace_1 and trace_2 are available in your workspace, and pycm3 has been imported as pm.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a dictionary traces_dict with two keys, trace_1 and trace_2, holding the corresponding trace objects.\n",
    "---\n",
    "\n",
    "    Call the appropriate pymc3 function to create a comparison table based on traces_dict, using waic for comparison, and assign the result to comparison.\n",
    "---\n",
    "\n",
    "    Draw a comparison plot between the two models (a textsize argument was added to the plotting function you need to call to improve the plot's readability).\n",
    "---\n",
    "Question\n",
    "\n",
    "You can print() the comparison between the two models you have created in the console. Based on the output, and on the comparison plot you have just drawn, which of the following statements is false?\n",
    "Possible answers:\n",
    "    The probability that it is model_2  of the two models that is true is around 2% (answer)\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Gather trace_1 and trace_2 into a dictionary\n",
    "traces_dict = {\"trace_1\": trace_1, \"trace_2\": trace_2}\n",
    "\n",
    "# Create a comparison table based on WAIC\n",
    "comparison = pm.compare(traces_dict, ic=\"waic\")\n",
    "\n",
    "# Draw a comparison plot\n",
    "pm.compareplot(comparison, textsize=20)\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Yes, it's the other way around! The weight of 0.021 for model_1 indicates it is the true model with around 2% probability.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Sample from predictive density\n",
    "\n",
    "Finally! Your job is to predict the number of bikes rented per day, and you are almost there. You have fitted the model and verified the quality of parameter draws. You have also chosen the better of the two competing models based on the WAIC. Now, it's time to use your best model to make predictions!\n",
    "\n",
    "A couple of new observations, not seen by the model, have been collected in a DataFrame named bikes_test. For each of them, we know the true number of bikes rented, which will allow us to evaluate model performance. In this exercise, you will get familiar with the test data and generate predictive draws for every test observation. The trace of your model which you have generated before is available as trace_2, and pymc3 has been imported as pm. Let's make predictions!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Print the head of bikes_test to the console and get familiar with the data.\n",
    "---\n",
    "\n",
    "    Define the model formula to predict num_bikes using temp, work_day and wind_speed as predictors.\n",
    "---\n",
    "\n",
    "    Generate predictive draws for the test data and assign the result to posterior_predictive.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Print bikes_test head\n",
    "print(bikes.head())\n",
    "\n",
    "# Define the formula\n",
    "formula = \"num_bikes ~ temp + work_day + wind_speed\"\n",
    "\n",
    "# Generate predictive draws\n",
    "with pm.Model() as model:\n",
    "    pm.GLM.from_formula(formula, data=bikes)\n",
    "    posterior_predictive = pm.fast_sample_posterior_predictive(trace_2)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done generating predictive draws! Let's proceed to the next exercise to find out how good your predictions are!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Estimating test error\n",
    "\n",
    "Now that you have your posterior_predictive (available to you in your workspace), you can evaluate model performance on new data. To do this, you will need to loop over the test observations, and for each of them, compute the prediction error as the difference between the predictive distribution for this observation and the actual, true value. This will give you the distribution of your model's error, which you can then visualize.\n",
    "\n",
    "You will need pymc3 and numpy, which have been imported for you as pm and np, respectively. The test data, bikes_test, is also available in your workspace. Let's get to it!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Initialize errors as an empty list.\n",
    "    For each row in bikes_test, calculate prediction error as the predictive draws for this row from posterior_predictive minus the single true value of num_bikes from the row.\n",
    "    Reshape errors by converting them to a numpy array and applying the .reshape() method to the outcome, and assign the final result to error_distribution.\n",
    "    Plot the test error distribution using pymc3's plot_posterior() function.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Initialize errors\n",
    "errors = []\n",
    "\n",
    "# Iterate over rows of bikes_test to compute error per row\n",
    "for index, test_example in bikes_test.iterrows():\n",
    "    error = posterior_predictive['y'][:, index] - test_example['num_bikes']\n",
    "    errors.append(error)\n",
    "\n",
    "# Reshape errors\n",
    "error_distribution = np.array(errors).reshape(-1)\n",
    "\n",
    "# Plot the error distribution\n",
    "pm.plot_posterior(error_distribution)\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Outstanding job! This was a tough one! In practice, you might want to compute the error estimate based on more than just 10 observations, but you can already see some patterns. For example, the error is more often positive than negative, which means that the model tends to overpredict the number of bikes rented!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Fitting the model\n",
    "\n",
    "You can use a linear regression model to estimate the avocado price elasticity. The regression formula should be:\n",
    "\n",
    "Here,\n",
    "\n",
    "will be the price elasticity, that is the impact of price on sales. You will assume that the elasticity is the same for regular and organic avocados. You also expect it to be negative: the higher the price, the lower the sales, that's the case for most goods. To incorporate this prior knowledge into the model, you decide to use a normal distribution with mean -80 as the prior for price. How would you build such a model?\n",
    "\n",
    "NOTE: Recall that calling pm.sample() for the first time in a fresh Python session takes some time, as Python code is being compiled to C under the hood. To save you time, we only ask you to get the code right instead of executing it.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Reorder the code lines to sample posterior draws, remembering to indent the lines that need it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "formula = 'volume ~ price + type_organic'\n",
    "\n",
    "with pm.Model as model:\n",
    "    priors = {'price' : pm.Normal.dist(mu=-80)}\n",
    "    pm.GLM.from_formula(formula, data=avocado, priors=priors)\n",
    "    trace = pm.sample(draws=1000, tune=500)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! That's how you would fit the model and generate posterior parameter draws! Let's inspect the model in the next exercise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Inspecting the model\n",
    "\n",
    "Well done getting the model-building right! The trace is available in your workspace and, following the best practices, you will now inspect the posterior draws to see if there are any convergence issues. Next, you will extract each model parameter from the trace and summarize it with its posterior mean. These posterior means will come in handy later, when you will be making predictions with the model. Let's take a look at the parameter draws!\n",
    "\n",
    "You will need to use pymc3 and numpy, which have been imported for you as pm and np, respectively.\n",
    "\n",
    "NOTE: Please allow up to half a minute for the plots to render, since they have many draws to process.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Draw and examine the trace plot of posterior draws.\n",
    "    Create a summary of posterior draws, assign in to summary, and print it.\n",
    "---\n",
    "\n",
    "    Calculate posterior mean of each parameter by extracting draws from trace and wrapping them with a function computing the mean.\n",
    "    Assign the posterior means to intercept_mean, organic_mean, price_mean, and sd_mean, accordingly.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Draw a trace plot of trace\n",
    "pm.traceplot(trace)\n",
    "plt.show()\n",
    "\n",
    "# Print a summary of trace\n",
    "summary = pm.summary(trace)\n",
    "print(summary)\n",
    "\n",
    "# Extract each model parameter\n",
    "intercept_mean = np.mean(trace.get_values(\"Intercept\")) \n",
    "organic_mean = np.mean(trace.get_values(\"type_organic\")) \n",
    "price_mean = np.mean(trace.get_values(\"price\")) \n",
    "sd_mean = np.mean(trace.get_values(\"sd\")) \n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! Have you noticed something unusual when it comes it MCMC convergence? Look at the left part of the trace plot for price: the density of one of the chains is slightly wobbly. Luckily, it's only one chain and its density is still quite close to the densities of other chains. So, all in all, we don't need to worry about it and we can safely use the model to optimize the price!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Optimizing the price\n",
    "\n",
    "Great job on fitting and inspecting the model! Now, down to business: your boss asks you to provide the avocado price that would yield the largest profit, and to state what profit can be expected. Also, they want the price to be divisible by $0.25 so that the customers can easily pay with quarters.\n",
    "\n",
    "In this exercise, you will use your model to predict the volume and the profit for a couple of sensible prices. Next, you will visualize the predictive distributions to pick the optimal price. Finally, you will compute the credible interval for your profit prediction. Now go and optimize!\n",
    "\n",
    "The posterior means you have computed before are available to you as intercept_mean, organic_mean, price_mean, and sd_mean, respectively. Also, pymc3, arviz, and numpy are imported as pm, az, and np.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    For each price in 0.5, 0.75, 1 and 1.25, calculate the predictive mean.\n",
    "    Sample from the predictive distribution to predict sales volume.\n",
    "    Use the predicted volume to predict the profit.\n",
    "---\n",
    "\n",
    "    Draw a forest plot of predicted profit.\n",
    "---\n",
    "\n",
    "    Based on the plot you have just created, pick the optimal price and calculate the Highest Posterior Density credible interval of 99% for this price.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# For each price, predict volume and use it to predict profit\n",
    "predicted_profit_per_price = {}\n",
    "for price in [0.5, 0.75, 1, 1.25]:\n",
    "    pred_mean = (intercept_mean + price_mean * price + organic_mean)\n",
    "    volume_pred = np.random.normal(pred_mean, sd_mean, size=1000)\n",
    "    profit_pred = price * volume_pred\n",
    "    predicted_profit_per_price.update({price: profit_pred})\n",
    "    \n",
    "# Draw a forest plot of predicted profit for all prices\n",
    "pm.forestplot(predicted_profit_per_price)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print HPD of predicted profit for the optimal price\n",
    "opt_hpd = az.hdi(predicted_profit_per_price[0.75], credible_interval=0.99)\n",
    "print(opt_hpd)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Terrfic work! With a higher or lower price, your company would lose profit, but thanks to your modeling skills, they were able to set the best possible price. More than that, knowing the uncertainty in the profit prediction, they can prepare for the worst-case scenario (in which the profit is negative)! \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
