{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoted_tweet = {'created_at': 'Wed Apr 25 17:20:04 +0000 2018',\n",
    " 'id': 989192330832891904,\n",
    " 'id_str': '989192330832891904',\n",
    " 'text': 'maybe if I quote tweet this lil guy https://t.co/BzbLDz9j6g',\n",
    " 'display_text_range': [0, 35],\n",
    " 'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    " 'truncated': False,\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'user': {'id': 661613,\n",
    "  'id_str': '661613',\n",
    "  'name': 'Alex Hanna, Data Witch',\n",
    "  'screen_name': 'alexhanna',\n",
    "  'location': 'Toronto, ON',\n",
    "  'url': 'http://alex-hanna.com',\n",
    "  'description': 'Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She/her.',\n",
    "  'translator_type': 'regular',\n",
    "  'protected': False,\n",
    "  'verified': False,\n",
    "  'followers_count': 4275,\n",
    "  'friends_count': 2806,\n",
    "  'listed_count': 246,\n",
    "  'favourites_count': 23526,\n",
    "  'statuses_count': 71926,\n",
    "  'created_at': 'Thu Jan 18 20:37:52 +0000 2007',\n",
    "  'utc_offset': -14400,\n",
    "  'time_zone': 'Eastern Time (US & Canada)',\n",
    "  'geo_enabled': True,\n",
    "  'lang': 'en',\n",
    "  'contributors_enabled': False,\n",
    "  'is_translator': False,\n",
    "  'profile_background_color': '000000',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_link_color': '0671B8',\n",
    "  'profile_sidebar_border_color': '666666',\n",
    "  'profile_sidebar_fill_color': 'CCCCCC',\n",
    "  'profile_text_color': '333333',\n",
    "  'profile_use_background_image': False,\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/661613/1524231456',\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'following': None,\n",
    "  'follow_request_sent': None,\n",
    "  'notifications': None},\n",
    " 'geo': None,\n",
    " 'coordinates': None,\n",
    " 'place': None,\n",
    " 'contributors': None,\n",
    " 'quoted_status_id': 989191655759663105,\n",
    " 'quoted_status_id_str': '989191655759663105',\n",
    " 'quoted_status': {'created_at': 'Wed Apr 25 17:17:23 +0000 2018',\n",
    "  'id': 989191655759663105,\n",
    "  'id_str': '989191655759663105',\n",
    "  'text': 'O 280 characters, 280 characters! Wherefore art thou 280 characters?\\nDeny thy JSON and refuse thy key.\\nOr, if thou… https://t.co/MlFg4qFnEC',\n",
    "  'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    "  'truncated': True,\n",
    "  'in_reply_to_status_id': None,\n",
    "  'in_reply_to_status_id_str': None,\n",
    "  'in_reply_to_user_id': None,\n",
    "  'in_reply_to_user_id_str': None,\n",
    "  'in_reply_to_screen_name': None,\n",
    "  'user': {'id': 661613,\n",
    "   'id_str': '661613',\n",
    "   'name': 'Alex Hanna, Data Witch',\n",
    "   'screen_name': 'alexhanna',\n",
    "   'location': 'Toronto, ON',\n",
    "   'url': 'http://alex-hanna.com',\n",
    "   'description': 'Assistant professor @UofT. Protest, media, computation. Trans. Roller derby athlete @TOROLLERDERBY (Kate Silver #538). She/her.',\n",
    "   'translator_type': 'regular',\n",
    "   'protected': False,\n",
    "   'verified': False,\n",
    "   'followers_count': 4275,\n",
    "   'friends_count': 2806,\n",
    "   'listed_count': 246,\n",
    "   'favourites_count': 23526,\n",
    "   'statuses_count': 71925,\n",
    "   'created_at': 'Thu Jan 18 20:37:52 +0000 2007',\n",
    "   'utc_offset': -14400,\n",
    "   'time_zone': 'Eastern Time (US & Canada)',\n",
    "   'geo_enabled': True,\n",
    "   'lang': 'en',\n",
    "   'contributors_enabled': False,\n",
    "   'is_translator': False,\n",
    "   'profile_background_color': '000000',\n",
    "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif',\n",
    "   'profile_background_tile': False,\n",
    "   'profile_link_color': '0671B8',\n",
    "   'profile_sidebar_border_color': '666666',\n",
    "   'profile_sidebar_fill_color': 'CCCCCC',\n",
    "   'profile_text_color': '333333',\n",
    "   'profile_use_background_image': False,\n",
    "   'profile_image_url': 'http://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/980799823900180483/J9CDOX_X_normal.jpg',\n",
    "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/661613/1524231456',\n",
    "   'default_profile': False,\n",
    "   'default_profile_image': False,\n",
    "   'following': None,\n",
    "   'follow_request_sent': None,\n",
    "   'notifications': None},\n",
    "  'geo': None,\n",
    "  'coordinates': None,\n",
    "  'place': None,\n",
    "  'contributors': None,\n",
    "  'is_quote_status': False,\n",
    "  'extended_tweet': {'full_text': 'O 280 characters, 280 characters! Wherefore art thou 280 characters?\\nDeny thy JSON and refuse thy key.\\nOr, if thou wilt not, be but sworn my love,\\nAnd I’ll no longer be a 140 character tweet.',\n",
    "   'display_text_range': [0, 191],\n",
    "   'entities': {'hashtags': [],\n",
    "    'urls': [],\n",
    "    'user_mentions': [],\n",
    "    'symbols': []}},\n",
    "  'quote_count': 0,\n",
    "  'reply_count': 1,\n",
    "  'retweet_count': 0,\n",
    "  'favorite_count': 1,\n",
    "  'entities': {'hashtags': [],\n",
    "   'urls': [{'url': 'https://t.co/MlFg4qFnEC',\n",
    "     'expanded_url': 'https://twitter.com/i/web/status/989191655759663105',\n",
    "     'display_url': 'twitter.com/i/web/status/9…',\n",
    "     'indices': [116, 139]}],\n",
    "   'user_mentions': [],\n",
    "   'symbols': []},\n",
    "  'favorited': False,\n",
    "  'retweeted': False,\n",
    "  'filter_level': 'low',\n",
    "  'lang': 'en'},\n",
    " 'is_quote_status': True,\n",
    " 'quote_count': 0,\n",
    " 'reply_count': 0,\n",
    " 'retweet_count': 0,\n",
    " 'favorite_count': 0,\n",
    " 'entities': {'hashtags': [],\n",
    "  'urls': [{'url': 'https://t.co/BzbLDz9j6g',\n",
    "    'expanded_url': 'https://twitter.com/alexhanna/status/989191655759663105',\n",
    "    'display_url': 'twitter.com/alexhanna/stat…',\n",
    "    'indices': [36, 59]}],\n",
    "  'user_mentions': [],\n",
    "  'symbols': []},\n",
    " 'favorited': False,\n",
    " 'retweeted': False,\n",
    " 'possibly_sensitive': False,\n",
    " 'filter_level': 'low',\n",
    " 'lang': 'en',\n",
    " 'timestamp_ms': '1524676804632'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maybe if I quote tweet this lil guy https://t.co/BzbLDz9j6g\n",
      "O 280 characters, 280 characters! Wherefore art thou 280 characters?\n",
      "Deny thy JSON and refuse thy key.\n",
      "Or, if thou… https://t.co/MlFg4qFnEC\n",
      "O 280 characters, 280 characters! Wherefore art thou 280 characters?\n",
      "Deny thy JSON and refuse thy key.\n",
      "Or, if thou wilt not, be but sworn my love,\n",
      "And I’ll no longer be a 140 character tweet.\n",
      "Toronto, ON\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Tweet Items and Tweet Flattening\n",
    "\n",
    "There are multiple fields in the Twitter JSON which contains textual data. In a typical tweet, there's the tweet text, the user description, and the user location. In a tweet longer than 140 characters, there's the extended tweet child JSON. And in a quoted tweet, there's the original tweet text and the commentary with the quoted tweet.\n",
    "\n",
    "For this exercise, you'll extract textual elements from a single quoted tweet in which the original tweet has more than 140 characters. Then, to analyze tweets at scale, we will want to flatten the tweet JSON into a single level. This will allow us to store the tweets in a DataFrame format.\n",
    "\n",
    "quoted_tweet has been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Print the tweet text.\n",
    "    Print the quoted tweet text, that is, the text in quoted_status.\n",
    "    Print the quoted tweet's extended (140+ character) full_text in extended_tweet.\n",
    "    Print the quoted tweet user's location.\n",
    "---\n",
    "\n",
    "    Store the user screen_name in user-screen_name.\n",
    "    Store the quoted tweet's text in quoted_status-text.\n",
    "    Store the quoted tweet's extended text in quoted_status-extended_tweet-full_text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Print the tweet text\n",
    "print(quoted_tweet['text'])\n",
    "\n",
    "# Print the quoted tweet text\n",
    "print(quoted_tweet['quoted_status']['text'])\n",
    "\n",
    "# Print the quoted tweet's extended (140+) text\n",
    "print(quoted_tweet['quoted_status']['extended_tweet']['full_text'])\n",
    "\n",
    "# Print the quoted user location\n",
    "print(quoted_tweet['quoted_status']['user']['location'])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Store the user screen_name in 'user-screen_name'\n",
    "quoted_tweet['user-screen_name'] = quoted_tweet['user']['screen_name']\n",
    "\n",
    "# Store the quoted_status text in 'quoted_status-text'\n",
    "quoted_tweet['quoted_status-text'] = quoted_tweet['quoted_status']['text']\n",
    "\n",
    "# Store the quoted tweet's extended (140+) text in \n",
    "# 'quoted_status-extended_tweet-full_text'\n",
    "quoted_tweet['quoted_status-extended_tweet-full_text'] = quoted_tweet['quoted_status']['extended_tweet']['full_text']\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGreat! Now we can flatten the JSON.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "A tweet flattening function\n",
    "\n",
    "We are typically interested in hundreds or thousands of tweets. For this purpose, it makes sense to define a function to flatten JSON file full of tweets. Let's call this function flatten_tweets(). We will use this function multiple times in this course and change it slightly as we deal with different types of data.\n",
    "\n",
    "json has been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Store the user screen name in user-screen_name.\n",
    "\n",
    "    Store the extended tweet text in extended_tweet-full_text.\n",
    "\n",
    "    Store the retweet user screen name in retweeted_status-user-screen_name.\n",
    "\n",
    "    Store the retweet text in retweeted_status-text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def flatten_tweets(tweets_json):\n",
    "    \"\"\" Flattens out tweet dictionaries so relevant JSON\n",
    "        is in a top-level dictionary.\"\"\"\n",
    "    tweets_list = []\n",
    "    \n",
    "    # Iterate through each tweet\n",
    "    for tweet in tweets_json:\n",
    "        tweet_obj = json.loads(tweet)\n",
    "    \n",
    "        # Store the user screen name in 'user-screen_name'\n",
    "        tweet_obj['user-screen_name'] = tweet_obj['user']['screen_name']\n",
    "    \n",
    "        # Check if this is a 140+ character tweet\n",
    "        if 'extended_tweet' in tweet_obj:\n",
    "            # Store the extended tweet text in 'extended_tweet-full_text'\n",
    "            tweet_obj['extended_tweet-full_text'] = tweet_obj['extended_tweet']['full_text']\n",
    "    \n",
    "        if 'retweeted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in 'retweeted_status-user-screen_name'\n",
    "            tweet_obj['retweeted_status-user-screen_name'] = tweet_obj['retweeted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['retweeted_status-text'] = tweet_obj['retweeted_status']['text']\n",
    "            \n",
    "        tweets_list.append(tweet_obj)\n",
    "    return tweets_list\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! Now we can flatten the JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"created_at\":\"Fri Mar 30 13:04:22 +0000 2018\",\"\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/data_science_json.txt','r') as file:\n",
    "    data_science_json = file.read()\n",
    "    file.close()\n",
    "\n",
    "print(data_science_json[:50])\n",
    "data_science_json = list(data_science_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Loading tweets into a DataFrame\n",
    "\n",
    "Now it's time to import data into a pandas DataFrame so we can analyze tweets at scale.\n",
    "\n",
    "We will work with a dataset of tweets which contain the hashtag '#rstats' or '#python'. This dataset is stored as a list of tweet JSON objects in data_science_json.\n",
    "\n",
    "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the pandas basics Cheat Sheet and keep it handy!\n",
    "(https://datacamp-community-prod.s3.amazonaws.com/fbc502d0-46b2-4e1b-b6b0-5402ff273251)\n",
    "Be aware that this is real data from Twitter and as such there is always a risk for the presence of profanity or other offensive content (in this exercise, and any following exercises that also use real Twitter data).\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Import pandas (remember, by convention we'll alias it as pd).\n",
    "\n",
    "    Flatten the data_science_json tweets with flatten_tweets() and store them in tweets.\n",
    "\n",
    "    Create a DataFrame from tweets using pd.DataFrame().\n",
    "\n",
    "    Print out the text from the first 5 tweets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import pandas\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the tweets and store in `tweets`\n",
    "tweets = flatten_tweets(data_science_json)\n",
    "\n",
    "# Create a DataFrame from `tweets`\n",
    "ds_tweets = pd.DataFrame(tweets)\n",
    "\n",
    "# Print out the first 5 tweets from this dataset\n",
    "print(ds_tweets['text'].values[0:5])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted_status-text</th>\n",
       "      <th>retweeted_status-extended_tweet-full_text</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>extended_tweet-full_text</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Mar 30 13:04:22 +0000 2018</td>\n",
       "      <td>979705897457942528</td>\n",
       "      <td>979705897457942528</td>\n",
       "      <td>RT @Dennboss: Hahahah Efteling maakt Maxi-Cosi...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Hahahah Efteling maakt Maxi-Cosi's voor in de ...</td>\n",
       "      <td>Hahahah Efteling maakt Maxi-Cosi's voor in de ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Mar 16 11:59:09 +0000 2018</td>\n",
       "      <td>974616055006941184</td>\n",
       "      <td>974616055006941184</td>\n",
       "      <td>RT @PythonWeekly: Python Weekly - Issue 338 ht...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Python Weekly - Issue 338 https://t.co/7gJSoLJ...</td>\n",
       "      <td>Python Weekly - Issue 338 https://t.co/7gJSoLJ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Mar 27 08:34:33 +0000 2018</td>\n",
       "      <td>978550832273805312</td>\n",
       "      <td>978550832273805312</td>\n",
       "      <td>RT @dataandme: ICYMI, still 💜ing this: \"Where ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ICYMI, still 💜ing this: \"Where do things live ...</td>\n",
       "      <td>ICYMI, still 💜ing this: \"Where do things live ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Mar 16 21:26:58 +0000 2018</td>\n",
       "      <td>974758950737448960</td>\n",
       "      <td>974758950737448960</td>\n",
       "      <td>RT @dataandme: 🕴@jaredlander knows how to put ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>🕴@jaredlander knows how to put on a show…\\n\"Ne...</td>\n",
       "      <td>🕴@jaredlander knows how to put on a show…\\n\"Ne...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu Mar 15 23:35:05 +0000 2018</td>\n",
       "      <td>974428804494995456</td>\n",
       "      <td>974428804494995456</td>\n",
       "      <td>RT @llanga: I heard it's Py Day today so I mad...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I heard it's Py Day today so I made a thing! M...</td>\n",
       "      <td>I heard it's Py Day today so I made a thing! M...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                  id              id_str  \\\n",
       "0  Fri Mar 30 13:04:22 +0000 2018  979705897457942528  979705897457942528   \n",
       "1  Fri Mar 16 11:59:09 +0000 2018  974616055006941184  974616055006941184   \n",
       "2  Tue Mar 27 08:34:33 +0000 2018  978550832273805312  978550832273805312   \n",
       "3  Fri Mar 16 21:26:58 +0000 2018  974758950737448960  974758950737448960   \n",
       "4  Thu Mar 15 23:35:05 +0000 2018  974428804494995456  974428804494995456   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @Dennboss: Hahahah Efteling maakt Maxi-Cosi...   \n",
       "1  RT @PythonWeekly: Python Weekly - Issue 338 ht...   \n",
       "2  RT @dataandme: ICYMI, still 💜ing this: \"Where ...   \n",
       "3  RT @dataandme: 🕴@jaredlander knows how to put ...   \n",
       "4  RT @llanga: I heard it's Py Day today so I mad...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                    NaN                        NaN                  NaN   \n",
       "1                    NaN                        NaN                  NaN   \n",
       "2                    NaN                        NaN                  NaN   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ...  \\\n",
       "0                      NaN  ...   \n",
       "1                      NaN  ...   \n",
       "2                      NaN  ...   \n",
       "3                      NaN  ...   \n",
       "4                      NaN  ...   \n",
       "\n",
       "                               retweeted_status-text  \\\n",
       "0  Hahahah Efteling maakt Maxi-Cosi's voor in de ...   \n",
       "1  Python Weekly - Issue 338 https://t.co/7gJSoLJ...   \n",
       "2  ICYMI, still 💜ing this: \"Where do things live ...   \n",
       "3  🕴@jaredlander knows how to put on a show…\\n\"Ne...   \n",
       "4  I heard it's Py Day today so I made a thing! M...   \n",
       "\n",
       "           retweeted_status-extended_tweet-full_text  possibly_sensitive  \\\n",
       "0  Hahahah Efteling maakt Maxi-Cosi's voor in de ...                 NaN   \n",
       "1  Python Weekly - Issue 338 https://t.co/7gJSoLJ...               False   \n",
       "2  ICYMI, still 💜ing this: \"Where do things live ...               False   \n",
       "3  🕴@jaredlander knows how to put on a show…\\n\"Ne...               False   \n",
       "4  I heard it's Py Day today so I made a thing! M...               False   \n",
       "\n",
       "   extended_entities extended_tweet  extended_tweet-full_text  \\\n",
       "0                NaN            NaN                       NaN   \n",
       "1                NaN            NaN                       NaN   \n",
       "2                NaN            NaN                       NaN   \n",
       "3                NaN            NaN                       NaN   \n",
       "4                NaN            NaN                       NaN   \n",
       "\n",
       "  display_text_range  quoted_status_id  quoted_status_id_str  quoted_status  \n",
       "0                NaN               NaN                   NaN            NaN  \n",
       "1                NaN               NaN                   NaN            NaN  \n",
       "2                NaN               NaN                   NaN            NaN  \n",
       "3                NaN               NaN                   NaN            NaN  \n",
       "4                NaN               NaN                   NaN            NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tweets = pd.read_csv('datasets/ds_tweets.csv').drop(columns=['index'], axis=1)\n",
    "ds_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of #python tweets: 0.44533333333333336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Finding keywords\n",
    "\n",
    "Counting known keywords is one of the first ways you can analyze text data in a Twitter dataset. In this dataset, you're going to count the number of times specific hashtags occur in a collection of tweets about data science. To this end, you're going to use the string methods in the pandas Series object to do this.\n",
    "\n",
    "pandas and numpy have been imported as pd and np, respectively. A more fully-featured flatten_tweets and data_science_json have also been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Flatten the tweets with flatten_tweets() and store them in flat_tweets.\n",
    "\n",
    "    Convert tweets to DataFrame using the pandas DataFrame constructor.\n",
    "\n",
    "    Find mentions of #python in 'text', ignoring case.\n",
    "\n",
    "    Print proportion of tweets mentioning #python by summing python with np.sum() and dividing it by the total number of tweets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Flatten the tweets and store them\n",
    "#flat_tweets = flatten_tweets(data_science_json)\n",
    "\n",
    "# Convert to DataFrame\n",
    "#ds_tweets = pd.DataFrame(flat_tweets)\n",
    "\n",
    "# Find mentions of #python in 'text'\n",
    "python = ds_tweets['text'].str.contains(\"#python\", case=False)\n",
    "\n",
    "# Print proportion of tweets mentioning #python\n",
    "print(\"Proportion of #python tweets:\", np.sum(python) / ds_tweets.shape[0])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Looking for text in all the wrong places\n",
    "\n",
    "Recall that relevant text may not only be in the main text field of the tweet. It may also be in the extended_tweet, the retweeted_status, or the quoted_status. We need to check all of these fields to make sure we've accounted for all the of the relevant text. We'll do this often so we're going to create a function which does this.\n",
    "\n",
    "The first two lines check if the main text field or the extended_tweet contain the text. You will need to check the rest.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Finish the check_word_in_tweet function by doing the following:\n",
    "\n",
    "\n",
    "    Check if the field quoted_status-text contains the word.\n",
    "\n",
    "    Check if the field quoted_status-extended_tweet-full_text contains the word.\n",
    "\n",
    "    Check if the field retweeted_status-text contains the word.\n",
    "\n",
    "    Check if the field retweeted_status-extended_tweet-full_text contains the word.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def check_word_in_tweet(word, data):\n",
    "    \"\"\"Checks if a word is in a Twitter dataset's text. \n",
    "    Checks text and extended tweet (140+ character tweets) for tweets,\n",
    "    retweets and quoted tweets.\n",
    "    Returns a logical pandas Series.\n",
    "    \"\"\"\n",
    "    contains_column = data['text'].str.contains(word, case = False)\n",
    "    contains_column |= data['extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['retweeted_status-text'].str.contains(word, case = False)\n",
    "    contains_column |= data['retweeted_status-extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    return contains_column\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'text', 'source', 'truncated',\n",
       "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
       "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
       "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
       "       'contributors', 'retweeted_status', 'is_quote_status', 'quote_count',\n",
       "       'reply_count', 'retweet_count', 'favorite_count', 'entities',\n",
       "       'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms',\n",
       "       'user-screen_name', 'retweeted_status-user-screen_name',\n",
       "       'retweeted_status-text', 'retweeted_status-extended_tweet-full_text',\n",
       "       'possibly_sensitive', 'extended_entities', 'extended_tweet',\n",
       "       'extended_tweet-full_text', 'display_text_range', 'quoted_status_id',\n",
       "       'quoted_status_id_str', 'quoted_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tweets.head(1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'quoted_status-text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'quoted_status-text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Use the function check_word_in_tweet() to find all instances of #python in the text fields of ds_tweets.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# solution\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Find mentions of #python in all text fields\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m python \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_word_in_tweet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#python\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_tweets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Find mentions of #rstats in all text fields\u001b[39;00m\n\u001b[1;32m     31\u001b[0m rstats \u001b[38;5;241m=\u001b[39m check_word_in_tweet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#rstats\u001b[39m\u001b[38;5;124m'\u001b[39m, ds_tweets)\n",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m, in \u001b[0;36mcheck_word_in_tweet\u001b[0;34m(word, data)\u001b[0m\n\u001b[1;32m     35\u001b[0m contains_column \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(word, case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m contains_column \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended_tweet-full_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(word, case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 37\u001b[0m contains_column \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquoted_status-text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(word, case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m contains_column \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquoted_status-extended_tweet-full_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(word, case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m contains_column \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretweeted_status-text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(word, case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/Estudos/estudos/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'quoted_status-text'"
     ]
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Comparing #python to #rstats\n",
    "\n",
    "Now that we have a function to check whether or not the word is in the tweet in multiple places, we can deploy this across multiple words and compare them. Let's return to our example with the data science hashtag dataset. We want to see how many times that #rstats occurs compared to #python.\n",
    "\n",
    "The data science hashtag dataset ds_tweets has been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Use the function check_word_in_tweet() to find all instances of #python in the text fields of ds_tweets.\n",
    "\n",
    "    Do the same with #rstats.\n",
    "\n",
    "    Print proportion of tweets mentioning #python by summing python with np.sum() and dividing it by ds_tweets.shape[0].\n",
    "\n",
    "    Do the same for rstats.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Find mentions of #python in all text fields\n",
    "python = check_word_in_tweet('#python', ds_tweets)\n",
    "\n",
    "# Find mentions of #rstats in all text fields\n",
    "rstats = check_word_in_tweet('#rstats', ds_tweets)\n",
    "\n",
    "# Print proportion of tweets mentioning #python\n",
    "print(\"Proportion of #python tweets:\", np.sum(python) / ds_tweets.shape[0])\n",
    "\n",
    "# Print proportion of tweets mentioning #rstats\n",
    "print(\"Proportion of #rstats tweets:\", np.sum(rstats) / ds_tweets.shape[0])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Creating time series data frame\n",
    "\n",
    "Time series data is used when we want to analyze or explore variation over time. This is useful when exploring Twitter text data if we want to track the prevalence of a word or set of words.\n",
    "\n",
    "The first step in doing this is converting the DataFrame into a format which can be handled using pandas time series methods. That can be done by converting the index to a datetime type.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Creating time series data frame\n",
    "\n",
    "Time series data is used when we want to analyze or explore variation over time. This is useful when exploring Twitter text data if we want to track the prevalence of a word or set of words.\n",
    "\n",
    "The first step in doing this is converting the DataFrame into a format which can be handled using pandas time series methods. That can be done by converting the index to a datetime type.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Print created_at to see the original format of datetime in Twitter data\n",
    "print(ds_tweets['created_at'].head())\n",
    "\n",
    "# Convert the created_at column to np.datetime object\n",
    "ds_tweets['created_at'] = pd.to_datetime(ds_tweets['created_at'])\n",
    "\n",
    "# Print created_at to see new format\n",
    "print(ds_tweets['created_at'].head())\n",
    "\n",
    "# Set the index of ds_tweets to created_at\n",
    "ds_tweets = ds_tweets.set_index('created_at')\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Generating mean frequency\n",
    "\n",
    "We need to produce a metric which can be graphed over time. Our function check_word_in_tweet() returns a boolean Series. Remember that the boolean value True == 1, so we can produce a column for each keyword we're interested in and use it to understand its over time prevalence.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a column called python and store the results of check_word_in_tweet() for the string '#python' in it.\n",
    "    Do the same, but with a column called rstats and the string '#rstats'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a python column\n",
    "ds_tweets['python'] = check_word_in_tweet('#python', ds_tweets)\n",
    "\n",
    "# Create an rstats column\n",
    "ds_tweets['rstats'] = check_word_in_tweet('#rstats', ds_tweets)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Plotting mean frequency\n",
    "\n",
    "Lastly, we'll create a per-day average of the mentions of both hashtags and plot them across time. We'll first create proportions from the two boolean Series by the day, then we'll plot them.\n",
    "\n",
    "matplotlib.pyplot has been imported as plt and ds_tweets has been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Generate the mean number of tweets with the python column with .resample() and .mean() methods. .resample() takes one argument, '1 d', to produce daily averages.\n",
    "    Do the same with the rstats column.\n",
    "    Plot a line for #python usage with mean_python. Use mean_python.index.day as the x-axis.\n",
    "    Do the same with mean_rstats.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "import matplotlib.pyplot as plt\n",
    "# Average of python column by day\n",
    "mean_python = ds_tweets['python'].resample('1 d').mean()\n",
    "\n",
    "# Average of rstats column by day\n",
    "mean_rstats = ds_tweets['rstats'].resample('1 d').mean()\n",
    "\n",
    "# Plot mean python by day(green)/mean rstats by day(blue)\n",
    "plt.plot(mean_python.index.day, mean_python, color = 'green')\n",
    "plt.plot(mean_rstats.index.day, mean_rstats, color = 'blue')\n",
    "\n",
    "# Add labels and show\n",
    "plt.xlabel('Day'); plt.ylabel('Frequency')\n",
    "plt.title('Language mentions over time')\n",
    "plt.legend(('#python', '#rstats'))\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "Loading VADER\n",
    "\n",
    "Sentiment analysis provides us a small glimpse of the meaning of texts with a rather directly interpretable method. While it has its limitations, it's a good place to begin working with textual data. There's a number of out-of-the-box tools in Python we can use for sentiment analysis.\n",
    "\n",
    "ds_tweets with the datetime index has been loaded for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Load SentimentIntensityAnalyzer from nltk.sentiment.vader.\n",
    "    Instantiate a new SentimentIntensityAnalyzer object.\n",
    "    Generate sentiment scores with the .apply() method and the analyzer's polarity_scores() function.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate new SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = ds_tweets['text'].apply(sid.polarity_scores)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 11\n",
    "\n",
    "\"\"\"\n",
    "Calculating sentiment scores\n",
    "\n",
    "A rough measure of sentiment towards a particular hashtag is to measure average sentiment for tweets mentioning a particular hashtag. It's also possible that other things are happening in that tweet, so it's important to inspect both text as well as metrics generated by automated text methods.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Print out the first example of a positive tweet. Select the DataFrame with sentiment > 0.6 and use .values to get the full text of the tweet.\n",
    "\n",
    "    Do the same for negative tweets with the index sentiment < -0.6.\n",
    "\n",
    "    Generate average sentiment score per day for #python with the index check_word_in_tweet. Use .resample() with argument '1 d'. Then take the mean.\n",
    "\n",
    "    Do the same with #rstats.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Print out the text of a positive tweet\n",
    "print(ds_tweets[sentiment > 0.6]['text'].values[0])\n",
    "\n",
    "# Print out the text of a negative tweet\n",
    "print(ds_tweets[sentiment <  -0.6]['text'].values[0])\n",
    "\n",
    "# Generate average sentiment scores for #python\n",
    "sentiment_py = sentiment[check_word_in_tweet(\"#python\", ds_tweets)].resample('1 d').mean()\n",
    "\n",
    "# Generate average sentiment scores for #rstats\n",
    "sentiment_r = sentiment[check_word_in_tweet(\"#rstats\", ds_tweets)].resample('1 d').mean()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 12\n",
    "\n",
    "\"\"\"\n",
    "Plotting sentiment scores\n",
    "\n",
    "Lastly, let's plot the sentiment of each hashtag over time. This is largely similar to plotting the prevalence of tweets.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Plot a line for #python usage with sentiment_py. Use sentiment_py.index.day as the x-axis.\n",
    "    Do the same with sentiment_r.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot average #python sentiment per day\n",
    "plt.plot(sentiment_py.index.day, sentiment_py, color = 'green')\n",
    "\n",
    "# Plot average #rstats sentiment per day\n",
    "plt.plot(sentiment_r.index.day, sentiment_r, color = 'blue')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Sentiment of data science languages')\n",
    "plt.legend(('#python', '#rstats'))\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
