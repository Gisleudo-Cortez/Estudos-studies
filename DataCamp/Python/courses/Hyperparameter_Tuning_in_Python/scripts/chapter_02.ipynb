{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "path_data = '/home/nero/Documents/Estudos/DataCamp/Python/Hyperparameter_Tuning_in_Python/datasets/'\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>EDUCATION_1</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>EDUCATION_5</th>\n",
       "      <th>EDUCATION_6</th>\n",
       "      <th>MARRIAGE_0</th>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990</td>\n",
       "      <td>48233</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617</td>\n",
       "      <td>5670</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  \\\n",
       "0      20000   24      2      2     -1     -1     -2     -2       3913   \n",
       "1     120000   26     -1      2      0      0      0      2       2682   \n",
       "2      90000   34      0      0      0      0      0      0      29239   \n",
       "3      50000   37      0      0      0      0      0      0      46990   \n",
       "4      50000   57     -1      0     -1      0      0      0       8617   \n",
       "\n",
       "   BILL_AMT2  ...  EDUCATION_1  EDUCATION_2  EDUCATION_3  EDUCATION_4  \\\n",
       "0       3102  ...            0            1            0            0   \n",
       "1       1725  ...            0            1            0            0   \n",
       "2      14027  ...            0            1            0            0   \n",
       "3      48233  ...            0            1            0            0   \n",
       "4       5670  ...            0            1            0            0   \n",
       "\n",
       "   EDUCATION_5  EDUCATION_6  MARRIAGE_0  MARRIAGE_1  MARRIAGE_2  MARRIAGE_3  \n",
       "0            0            0           0           1           0           0  \n",
       "1            0            0           0           0           1           0  \n",
       "2            0            0           0           0           1           0  \n",
       "3            0            0           0           1           0           0  \n",
       "4            0            0           0           1           0           0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path_data + 'credit_card_with_cats.csv').drop('Unnamed: 0', axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21000, 33), (9000, 33), (21000,), (9000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['default payment next month'])\n",
    "y = data['default payment next month']\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "X_train.shape , X_test.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNice! You now have a function you can call to test different combinations of two hyperparameters for the GBM algorithm. In the next exercise we will use it to test some values and analyze the results.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Build Grid Search functions\n",
    "\n",
    "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.\n",
    "\n",
    "In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise.\n",
    "\n",
    "You will have available the X_train, X_test, y_train and y_test datasets available.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build a function that takes two parameters called learning_rate and max_depth for the learning rate and maximum depth.\n",
    "    Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.\n",
    "    Have the function return the results of that model and the chosen hyperparameters (learning_rate and max_depth).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create the function\n",
    "def gbm_grid_search(learning_rate, max_depth):\n",
    "\n",
    "\t# Create the model\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=max_depth)\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Return the hyperparameters and score\n",
    "    return([learning_rate, max_depth, accuracy_score(y_test, predictions)])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice! You now have a function you can call to test different combinations of two hyperparameters for the GBM algorithm. In the next exercise we will use it to test some values and analyze the results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01, 2, 0.8191111111111111], [0.01, 4, 0.819], [0.01, 6, 0.8155555555555556], [0.1, 2, 0.8211111111111111], [0.1, 4, 0.8191111111111111], [0.1, 6, 0.8185555555555556], [0.5, 2, 0.8165555555555556], [0.5, 4, 0.8002222222222222], [0.5, 6, 0.7832222222222223]]\n",
      "[[0.01, 2, 0.4, 0.8183333333333334], [0.01, 2, 0.6, 0.8193333333333334], [0.01, 4, 0.4, 0.8175555555555556], [0.01, 4, 0.6, 0.8186666666666667], [0.01, 6, 0.4, 0.8158888888888889], [0.01, 6, 0.6, 0.8147777777777778], [0.1, 2, 0.4, 0.8213333333333334], [0.1, 2, 0.6, 0.8207777777777778], [0.1, 4, 0.4, 0.8195555555555556], [0.1, 4, 0.6, 0.8207777777777778], [0.1, 6, 0.4, 0.8131111111111111], [0.1, 6, 0.6, 0.8168888888888889], [0.5, 2, 0.4, 0.8131111111111111], [0.5, 2, 0.6, 0.8142222222222222], [0.5, 4, 0.4, 0.7955555555555556], [0.5, 4, 0.6, 0.7968888888888889], [0.5, 6, 0.4, 0.7875555555555556], [0.5, 6, 0.6, 0.7826666666666666]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCongratulations. You have effectively built your own grid search! You went from 2 to 3 hyperparameters and can see how you could extend that to even more values and hyperparameters. That was a lot of effort though. Be warned - we are now entering a world that can get very computationally expensive very fast!\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Iteratively tune multiple hyperparameters\n",
    "\n",
    "In this exercise, you will build on the function you previously created to take in 2 hyperparameters, build a model and return the results. You will now use that to loop through some values and then extend this function and loop with another hyperparameter.\n",
    "\n",
    "The function gbm_grid_search(learn_rate, max_depth) is available in this exercise.\n",
    "\n",
    "If you need to remind yourself of the function you can run the function print_func() that has been created for you\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Write a for-loop to test the values (0.01, 0.1, 0.5) for the learning_rate and (2, 4, 6) for the max_depth using the function you created gbm_grid_search and print the results.\n",
    "---\n",
    "Extend the gbm_grid_search function to include the hyperparameter subsample. Name this new function gbm_grid_search_extended.\n",
    "---\n",
    "Extend your loop to call gbm_grid_search (available in your console), then test the values [0.4 , 0.6] for the subsample hyperparameter and print the results. max_depth_list & learn_rate_list are available in your environment.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create the relevant lists\n",
    "results_list = []\n",
    "learn_rate_list = [0.01, 0.1, 0.5]\n",
    "max_depth_list = [2, 4, 6]\n",
    "\n",
    "# Create the for loop\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        results_list.append(gbm_grid_search(learn_rate,max_depth))\n",
    "\n",
    "# Print the results\n",
    "print(results_list)   \n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "results_list = []\n",
    "learn_rate_list = [0.01, 0.1, 0.5]\n",
    "max_depth_list = [2,4,6]\n",
    "\n",
    "# Extend the function input\n",
    "def gbm_grid_search_extended(learn_rate, max_depth, subsample):\n",
    "\n",
    "\t# Extend the model creation section\n",
    "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, subsample=subsample)\n",
    "    \n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Extend the return part\n",
    "    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])       \n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Create the new list to test\n",
    "subsample_list = [0.4 , 0.6]\n",
    "\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "    \n",
    "    \t# Extend the for loop\n",
    "        for subsample in subsample_list:\n",
    "        \t\n",
    "            # Extend the results to include the new hyperparameter\n",
    "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
    "            \n",
    "# Print results\n",
    "print(results_list)            \n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Congratulations. You have effectively built your own grid search! You went from 2 to 3 hyperparameters and can see how you could extend that to even more values and hyperparameters. That was a lot of effort though. Be warned - we are now entering a world that can get very computationally expensive very fast!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion='entropy'),\n",
      "             n_jobs=4,\n",
      "             param_grid={'max_depth': [2, 4, 8, 15],\n",
      "                         'max_features': ['auto', 'sqrt']},\n",
      "             return_train_score=True, scoring='roc_auc')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nExcellent work! You now understand all the inputs to a GridSearchCV object and can tune many different hyperparameters and many different values for each on a chosen algorithm!\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "GridSearchCV with Scikit Learn\n",
    "\n",
    "The GridSearchCV module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a GridSearchCV object with certain parameters.\n",
    "\n",
    "The desired options are:\n",
    "\n",
    "    A Random Forest Estimator, with the split criterion as 'entropy'\n",
    "    5-fold cross validation\n",
    "    The hyperparameters max_depth (2, 4, 8, 15) and max_features ('auto' vs 'sqrt')\n",
    "    Use roc_auc to score the models\n",
    "    Use 4 cores for processing in parallel\n",
    "    Ensure you refit the best model and return training scores\n",
    "\n",
    "You will have available X_train, X_test, y_train & y_test datasets.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a Random Forest estimator as specified in the context above.\n",
    "    Create a parameter grid as specified in the context above.\n",
    "    Create a GridSearchCV object as outlined in the context above, using the two elements created in the previous two instructions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Create a Random Forest Classifier with specified criterion\n",
    "rf_class = RandomForestClassifier(criterion='entropy')\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['sqrt']} \n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_rf_class = GridSearchCV(\n",
    "    estimator=rf_class,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    refit=True, return_train_score=True)\n",
    "print(grid_rf_class)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Excellent work! You now understand all the inputs to a GridSearchCV object and can tune many different hyperparameters and many different values for each on a chosen algorithm!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 8, 15],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 8, 15],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(criterion='entropy'),\n",
       "             n_jobs=4,\n",
       "             param_grid={'max_depth': [2, 4, 8, 15],\n",
       "                         'max_features': ['auto', 'sqrt']},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       2.156262      0.108977         0.094793        0.012879   \n",
      "1       2.233040      0.173453         0.096065        0.014492   \n",
      "2       3.633133      0.178726         0.102498        0.002046   \n",
      "3       3.900888      0.126586         0.108609        0.004633   \n",
      "4       7.089564      0.173724         0.148029        0.022124   \n",
      "5       7.104259      0.167709         0.142552        0.004997   \n",
      "6      12.068568      0.330516         0.233459        0.021829   \n",
      "7      11.405906      0.545763         0.201667        0.019520   \n",
      "\n",
      "  param_max_depth param_max_features  \\\n",
      "0               2               auto   \n",
      "1               2               sqrt   \n",
      "2               4               auto   \n",
      "3               4               sqrt   \n",
      "4               8               auto   \n",
      "5               8               sqrt   \n",
      "6              15               auto   \n",
      "7              15               sqrt   \n",
      "\n",
      "                                      params  split0_test_score  \\\n",
      "0   {'max_depth': 2, 'max_features': 'auto'}           0.779926   \n",
      "1   {'max_depth': 2, 'max_features': 'sqrt'}           0.778981   \n",
      "2   {'max_depth': 4, 'max_features': 'auto'}           0.785266   \n",
      "3   {'max_depth': 4, 'max_features': 'sqrt'}           0.783906   \n",
      "4   {'max_depth': 8, 'max_features': 'auto'}           0.794634   \n",
      "5   {'max_depth': 8, 'max_features': 'sqrt'}           0.794524   \n",
      "6  {'max_depth': 15, 'max_features': 'auto'}           0.794594   \n",
      "7  {'max_depth': 15, 'max_features': 'sqrt'}           0.789565   \n",
      "\n",
      "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
      "0           0.771632           0.783012  ...         0.769401        0.011445   \n",
      "1           0.774113           0.781723  ...         0.769429        0.011151   \n",
      "2           0.777497           0.787189  ...         0.774529        0.011255   \n",
      "3           0.780890           0.787557  ...         0.774889        0.011498   \n",
      "4           0.784522           0.792924  ...         0.781932        0.011290   \n",
      "5           0.784369           0.790337  ...         0.780997        0.011193   \n",
      "6           0.787242           0.788711  ...         0.780872        0.011667   \n",
      "7           0.785460           0.789147  ...         0.781082        0.008698   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                8            0.768846            0.771709   \n",
      "1                7            0.767963            0.773525   \n",
      "2                6            0.778074            0.779990   \n",
      "3                5            0.778826            0.781895   \n",
      "4                1            0.827983            0.829690   \n",
      "5                3            0.830597            0.830893   \n",
      "6                4            0.972406            0.974261   \n",
      "7                2            0.974433            0.973214   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0            0.772450            0.775090            0.773274   \n",
      "1            0.770083            0.775762            0.773306   \n",
      "2            0.778919            0.785469            0.783953   \n",
      "3            0.778585            0.784522            0.784136   \n",
      "4            0.829655            0.835511            0.832710   \n",
      "5            0.831396            0.835256            0.832172   \n",
      "6            0.973968            0.975708            0.972320   \n",
      "7            0.975611            0.977773            0.973999   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "0          0.772274         0.002051  \n",
      "1          0.772128         0.002760  \n",
      "2          0.781281         0.002906  \n",
      "3          0.781593         0.002524  \n",
      "4          0.831110         0.002677  \n",
      "5          0.832063         0.001683  \n",
      "6          0.973733         0.001264  \n",
      "7          0.975006         0.001586  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "                                      params\n",
      "0   {'max_depth': 2, 'max_features': 'auto'}\n",
      "1   {'max_depth': 2, 'max_features': 'sqrt'}\n",
      "2   {'max_depth': 4, 'max_features': 'auto'}\n",
      "3   {'max_depth': 4, 'max_features': 'sqrt'}\n",
      "4   {'max_depth': 8, 'max_features': 'auto'}\n",
      "5   {'max_depth': 8, 'max_features': 'sqrt'}\n",
      "6  {'max_depth': 15, 'max_features': 'auto'}\n",
      "7  {'max_depth': 15, 'max_features': 'sqrt'}\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "4       7.089564      0.173724         0.148029        0.022124   \n",
      "\n",
      "  param_max_depth param_max_features  \\\n",
      "4               8               auto   \n",
      "\n",
      "                                     params  split0_test_score  \\\n",
      "4  {'max_depth': 8, 'max_features': 'auto'}           0.794634   \n",
      "\n",
      "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
      "4           0.784522           0.792924  ...         0.781932         0.01129   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "4                1            0.827983             0.82969   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "4            0.829655            0.835511             0.83271   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "4           0.83111         0.002677  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nGreat work! You have built invaluable skills in looking 'under the hood' at what your grid search is doing by extracting and analysing the cv_results_ property.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Exploring the grid search results\n",
    "\n",
    "You will now explore the cv_results_ property of the GridSearchCV object defined in the video. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook.\n",
    "\n",
    "A reminder of the different column types in this property:\n",
    "\n",
    "    time_ columns\n",
    "    param_ columns (one for each hyperparameter) and the singular params column (with all hyperparameter settings)\n",
    "    a train_score column for each cv fold including the mean_train_score and std_train_score columns\n",
    "    a test_score column for each cv fold including the mean_test_score and std_test_score columns\n",
    "    a rank_test_score column with a number from 1 to n (number of iterations) ranking the rows based on their mean_test_score\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Read the cv_results_ property of the grid_rf_class GridSearchCV object into a data frame & print the whole thing out to inspect.\n",
    "    Extract & print the singular column containing a dictionary of all hyperparameters used in each iteration of the grid search.\n",
    "    Extract & print the row that had the best mean test score by indexing using the rank_test_score column.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Read the cv_results property into a dataframe & print it out\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "print(cv_results_df)\n",
    "\n",
    "# Extract and print the column with a dictionary of hyperparameters used\n",
    "column = cv_results_df.loc[:, ['params']]\n",
    "print(column)\n",
    "\n",
    "# Extract and print the row that had the best mean test score\n",
    "best_row = cv_results_df[cv_results_df['rank_test_score'] == 1 ]\n",
    "print(best_row)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great work! You have built invaluable skills in looking 'under the hood' at what your grid search is doing by extracting and analysing the cv_results_ property.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 'auto'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_class.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7819318029127879\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "4       7.089564      0.173724         0.148029        0.022124   \n",
      "\n",
      "  param_max_depth param_max_features  \\\n",
      "4               8               auto   \n",
      "\n",
      "                                     params  split0_test_score  \\\n",
      "4  {'max_depth': 8, 'max_features': 'auto'}           0.794634   \n",
      "\n",
      "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
      "4           0.784522           0.792924  ...         0.781932         0.01129   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "4                1            0.827983             0.82969   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "4            0.829655            0.835511             0.83271   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "4           0.83111         0.002677  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(best_row)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Get the n_estimators parameter from the best-performing square and print\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m best_n_estimators \u001b[39m=\u001b[39m grid_rf_class\u001b[39m.\u001b[39;49mbest_params_[\u001b[39m\"\u001b[39;49m\u001b[39mn_estimators\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(best_n_estimators)\n\u001b[1;32m     44\u001b[0m \u001b[39m#----------------------------------#\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[39m# Conclusion\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_estimators'"
     ]
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Analyzing the best results\n",
    "\n",
    "At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's gridSearchCv objects have a number of parameters that provide key information on just the best square (or row in cv_results_).\n",
    "\n",
    "Three properties you will explore are:\n",
    "\n",
    "    best_score_ – The score (here ROC_AUC) from the best-performing square.\n",
    "    best_index_ – The index of the row in cv_results_ containing information on the best-performing square.\n",
    "    best_params_ – A dictionary of the parameters that gave the best score, for example 'max_depth': 10\n",
    "\n",
    "The grid search object grid_rf_class is available.\n",
    "\n",
    "A dataframe (cv_results_df) has been created from the cv_results_ for you on line 6. This will help you index into the results.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Extract and print out the ROC_AUC score from the best performing square in grid_rf_class.\n",
    "    Create a variable from the best-performing row by indexing into cv_results_df.\n",
    "    Create a variable, best_n_estimators by extracting the n_estimators parameter from the best-performing square in grid_rf_class and print it out.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Print out the ROC_AUC score from the best-performing square\n",
    "best_score = grid_rf_class.best_score_\n",
    "print(best_score)\n",
    "\n",
    "# Create a variable from the row related to the best-performing square\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
    "print(best_row)\n",
    "\n",
    "# Get the n_estimators parameter from the best-performing square and print\n",
    "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
    "print(best_n_estimators)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice stuff! Being able to quickly find and prioritize the huge volume of information given back from machine learning modeling output is a great skill. Here you had great practice doing that with cv_results_ by quickly isolating the key information on the best performing square. This will be very important when your grids grow from 12 squares to many more!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "[0 0 0 0 0]\n",
      "Confusion Matrix \n",
      " [[6699  341]\n",
      " [1291  669]]\n",
      "ROC-AUC Score \n",
      " 0.7746385812847868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNice stuff! The .best_estimator_ property is a really powerful property to understand for streamlining your machine learning model building process. You now can run a grid search and seamlessly use the best model from that search to make predictions. Piece of cake!\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Using the best results\n",
    "\n",
    "While it is interesting to analyze the results of our grid search, our final goal is practical in nature; we want to make predictions on our test set using our estimator object.\n",
    "\n",
    "We can access this object through the best_estimator_ property of our grid search object.\n",
    "\n",
    "Let's take a look inside the best_estimator_ property, make predictions, and generate evaluation scores. We will firstly use the default predict (giving class predictions), but then we will need to use predict_proba rather than predict to generate the roc-auc score as roc-auc needs probability scores for its calculation. We use a slice [:,1] to get probabilities of the positive class.\n",
    "\n",
    "You have available the X_test and y_test datasets to use and the grid_rf_class object from previous exercises.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Check the type of the best_estimator_ property.\n",
    "    Use the best_estimator_ property to make predictions on our test set.\n",
    "    Generate a confusion matrix and ROC_AUC score from our predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# See what type of object the best_estimator_ property is\n",
    "print(type(grid_rf_class.best_estimator_))\n",
    "\n",
    "# Create an array of predictions directly using the best_estimator_ property\n",
    "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
    "\n",
    "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
    "print(predictions[0:5])\n",
    "\n",
    "# Now create a confusion matrix \n",
    "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the ROC-AUC score\n",
    "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
    "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice stuff! The .best_estimator_ property is a really powerful property to understand for streamlining your machine learning model building process. You now can run a grid search and seamlessly use the best model from that search to make predictions. Piece of cake!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
