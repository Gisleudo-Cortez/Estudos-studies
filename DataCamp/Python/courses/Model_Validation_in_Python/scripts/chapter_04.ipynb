{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:42:07.383832Z",
     "iopub.status.busy": "2023-06-14T12:42:07.383456Z",
     "iopub.status.idle": "2023-06-14T12:42:07.783634Z",
     "shell.execute_reply": "2023-06-14T12:42:07.783054Z",
     "shell.execute_reply.started": "2023-06-14T12:42:07.383793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "path_data = '/home/nero/Documents/Estudos/DataCamp/Python/Model_Validation_in_Python/datasets/'\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:44:25.381074Z",
     "iopub.status.busy": "2023-06-14T12:44:25.380564Z",
     "iopub.status.idle": "2023-06-14T12:44:25.889966Z",
     "shell.execute_reply": "2023-06-14T12:44:25.889360Z",
     "shell.execute_reply.started": "2023-06-14T12:44:25.381034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:44:27.103525Z",
     "iopub.status.busy": "2023-06-14T12:44:27.101023Z",
     "iopub.status.idle": "2023-06-14T12:44:27.140812Z",
     "shell.execute_reply": "2023-06-14T12:44:27.138038Z",
     "shell.execute_reply.started": "2023-06-14T12:44:27.103422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood job! Hyperparameter tuning requires selecting parameters to tune, as well the possible values these parameters can be set to.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Creating Hyperparameters\n",
    "\n",
    "For a school assignment, your professor has asked your class to create a random forest model to predict the average test score for the final exam.\n",
    "\n",
    "After developing an initial random forest model, you are unsatisfied with the overall accuracy. You realize that there are too many hyperparameters to choose from, and each one has a lot of possible values. You have decided to make a list of possible ranges for the hyperparameters you might use in your next model.\n",
    "\n",
    "Your professor has provided de-identified data for the last ten quizzes to act as the training data. There are 30 students in your class.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Print.get_params() in the console to review the possible parameters of the model that you can tune.\n",
    "---\n",
    "\n",
    "    Create a maximum depth list, [4, 8, 12] and a minimum samples list [2, 5, 10] that specify possible values for each hyperparameter.\n",
    "---\n",
    "Create one final list to use for the maximum features.\n",
    "\n",
    "    Use values 4 through the maximum number of features possible (10), by 2.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Review the parameters of rfr\n",
    "print(rfr.get_params())\n",
    "\n",
    "# Maximum Depth\n",
    "max_depth = [4, 8, 12]\n",
    "\n",
    "# Minimum samples for a split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Max features \n",
    "max_features = [4,6,8,10]\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! Hyperparameter tuning requires selecting parameters to tune, as well the possible values these parameters can be set to.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:51:29.610035Z",
     "iopub.status.busy": "2023-06-14T12:51:29.609217Z",
     "iopub.status.idle": "2023-06-14T12:51:29.617587Z",
     "shell.execute_reply": "2023-06-14T12:51:29.615657Z",
     "shell.execute_reply.started": "2023-06-14T12:51:29.609980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:51:46.373837Z",
     "iopub.status.busy": "2023-06-14T12:51:46.372936Z",
     "iopub.status.idle": "2023-06-14T12:51:46.396647Z",
     "shell.execute_reply": "2023-06-14T12:51:46.394848Z",
     "shell.execute_reply.started": "2023-06-14T12:51:46.373668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 12, 'max_features': 10, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood job! Notice that min_samples_split was randomly set to 2. Since you specified a random state, min_samples_split will always be set to 2 if you only run this model one time.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Running a model using ranges\n",
    "\n",
    "You have just finished creating a list of hyperparameters and ranges to use when tuning a predictive model for an assignment. You have used max_depth, min_samples_split, and max_features as your range variable names.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Randomly select a max_depth, min_samples_split, and max_features using your range variables.\n",
    "    Print out all of the parameters for rfr to see which values were randomly selected.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fill in rfr using your variables\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=random.choice(max_depth),\n",
    "    min_samples_split=random.choice(min_samples_split),\n",
    "    max_features=random.choice(max_features))\n",
    "\n",
    "# Print out the parameters\n",
    "print(rfr.get_params())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! Notice that min_samples_split was randomly set to 2. Since you specified a random state, min_samples_split will always be set to 2 if you only run this model one time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:57:48.212438Z",
     "iopub.status.busy": "2023-06-14T12:57:48.211092Z",
     "iopub.status.idle": "2023-06-14T12:57:48.228019Z",
     "shell.execute_reply": "2023-06-14T12:57:48.226766Z",
     "shell.execute_reply.started": "2023-06-14T12:57:48.212336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWell done! To use RandomizedSearchCV(), you need a distribution dictionary, an estimator, and a scorer—once you've got these, you can run a random search to find the best parameters for your model.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Preparing for RandomizedSearch\n",
    "\n",
    "Last semester your professor challenged your class to build a predictive model to predict final exam test scores. You tried running a few different models by randomly selecting hyperparameters. However, running each model required you to code it individually.\n",
    "\n",
    "After learning about RandomizedSearchCV(), you're revisiting your professors challenge to build the best model. In this exercise, you will prepare the three necessary inputs for completing a random search.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Finalize the parameter dictionary by adding a list for the max_depth parameter with options 2, 4, 6, and 8.\n",
    "    Create a random forest regression model with ten trees and a random_state of 1111.\n",
    "    Create a mean squared error scorer to use.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Finish the dictionary by adding the max_depth parameter\n",
    "param_dist = {\"max_depth\": [2,4,6,8],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 8, 16]}\n",
    "\n",
    "# Create a random forest regression model\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n",
    "\n",
    "# Create a scorer to use (use the mean squared error)\n",
    "scorer = _=make_scorer(mean_squared_error)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! To use RandomizedSearchCV(), you need a distribution dictionary, an estimator, and a scorer—once you've got these, you can run a random search to find the best parameters for your model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:59:44.650009Z",
     "iopub.status.busy": "2023-06-14T12:59:44.648971Z",
     "iopub.status.idle": "2023-06-14T12:59:44.661744Z",
     "shell.execute_reply": "2023-06-14T12:59:44.659894Z",
     "shell.execute_reply.started": "2023-06-14T12:59:44.649954Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNice! Although it takes a lot of steps, hyperparameter tuning with random search is well worth it and can improve the accuracy of your models. Plus, you are already using cross-validation to validate your best model.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Implementing RandomizedSearchCV\n",
    "\n",
    "You are hoping that using a random search algorithm will help you improve predictions for a class assignment. You professor has challenged your class to predict the overall final exam average score.\n",
    "\n",
    "In preparation for completing a random search, you have created:\n",
    "\n",
    "    param_dist: the hyperparameter distributions\n",
    "    rfr: a random forest regression model\n",
    "    scorer: a scoring method to use\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Load the method for conducting a random search in sklearn.\n",
    "    Complete a random search by filling in the parameters: estimator, param_distributions, and scoring.\n",
    "    Use 5-fold cross validation for this random search.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Import the method for random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Build a random search using param_dist, rfr, and scorer\n",
    "random_search =\\\n",
    "    RandomizedSearchCV(\n",
    "        estimator=rfr,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring=scorer)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice! Although it takes a lot of steps, hyperparameter tuning with random search is well worth it and can improve the accuracy of your models. Plus, you are already using cross-validation to validate your best model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:08:26.527846Z",
     "iopub.status.busy": "2023-06-14T13:08:26.527430Z",
     "iopub.status.idle": "2023-06-14T13:08:26.536523Z",
     "shell.execute_reply": "2023-06-14T13:08:26.534269Z",
     "shell.execute_reply.started": "2023-06-14T13:08:26.527794Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:08:27.071385Z",
     "iopub.status.busy": "2023-06-14T13:08:27.069630Z",
     "iopub.status.idle": "2023-06-14T13:08:27.081690Z",
     "shell.execute_reply": "2023-06-14T13:08:27.078899Z",
     "shell.execute_reply.started": "2023-06-14T13:08:27.071318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=1111)\n",
    "param_dist = {'n_estimators': [10, 25, 50],\n",
    " 'max_depth': range(2, 12, 2),\n",
    " 'min_samples_split': range(2, 12, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:09:30.744692Z",
     "iopub.status.busy": "2023-06-14T13:09:30.744231Z",
     "iopub.status.idle": "2023-06-14T13:09:30.773010Z",
     "shell.execute_reply": "2023-06-14T13:09:30.771205Z",
     "shell.execute_reply.started": "2023-06-14T13:09:30.744661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tic_df = pd.read_csv(path_data + 'tic-tac-toe.csv')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "lenc = LabelEncoder()\n",
    "\n",
    "X = enc.fit_transform(tic_df.iloc[:,:9]).toarray()\n",
    "y = lenc.fit_transform(tic_df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:09:32.991523Z",
     "iopub.status.busy": "2023-06-14T13:09:32.990527Z",
     "iopub.status.idle": "2023-06-14T13:09:37.617700Z",
     "shell.execute_reply": "2023-06-14T13:09:37.615816Z",
     "shell.execute_reply.started": "2023-06-14T13:09:32.991476Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for each run was: [0.87614978 0.75561877 0.67740077 0.89141614 0.87024051 0.85772772\n",
      " 0.68244199 0.82867397 0.88717239 0.91980724].\n",
      "The best accuracy for a single model was: 0.9198072369317106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWow - Your model's precision was 93%! The best model accurately predicts a winning game 93% of the time. If you look at the mean test scores, you can tell some of the other parameter sets did really poorly. Also, since you used cross-validation, you can be confident in your predictions. Well done!\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Selecting the best precision model\n",
    "\n",
    "Your boss has offered to pay for you to see three sports games this year. Of the 41 home games your favorite team plays, you want to ensure you go to three home games that they will definitely win. You build a model to decide which games your team will win.\n",
    "\n",
    "To do this, you will build a random search algorithm and focus on model precision (to ensure your team wins). You also want to keep track of your best model and best parameters, so that you can use them again next year (if the model does well, of course). You have already decided on using the random forest classification model rfc and generated a parameter distribution param_dist.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a precision scorer, precision using make_scorer(<scoring_function>).\n",
    "    Complete the random search method by using rfc and param_dist.\n",
    "    Use rs.cv_results_ to print the mean test scores.\n",
    "    Print the best overall score.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from sklearn.metrics import precision_score, make_scorer\n",
    "\n",
    "# Create a precision scorer\n",
    "precision = make_scorer(precision_score)\n",
    "# Finalize the random search\n",
    "rs = RandomizedSearchCV(\n",
    "  estimator=rfc, param_distributions=param_dist,\n",
    "  scoring = precision,\n",
    "  cv=5, n_iter=10, random_state=1111)\n",
    "rs.fit(X, y)\n",
    "\n",
    "# print the mean test scores:\n",
    "print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
    "# print the best model score:\n",
    "print('The best accuracy for a single model was: {}'.format(rs.best_score_))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Wow - Your model's precision was 93%! The best model accurately predicts a winning game 93% of the time. If you look at the mean test scores, you can tell some of the other parameter sets did really poorly. Also, since you used cross-validation, you can be confident in your predictions. Well done!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
