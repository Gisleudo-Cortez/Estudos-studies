{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "path_data = '/home/nero/Documents/Estudos/DataCamp/Python/Image_Processing_with_Keras_in_Python/datasets/'\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCongratulations!! You built a network with multiple convolution layers.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Creating a deep learning network\n",
    "\n",
    "A deep convolutional neural network is a network that has more than one layer. Each layer in a deep network receives its input from the preceding layer, with the very first layer receiving its input from the images used as training or test data.\n",
    "\n",
    "Here, you will create a network that has two convolutional layers.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    The first convolutional layer is the input layer of the network. This should have 15 units with kernels of 2 by 2 pixels. It should have a 'relu' activation function. It can use the variables img_rows and img_cols to define its input_shape.\n",
    "    The second convolutional layer receives its inputs from the first layer. It should have 5 units with kernels of 2 by 2 pixels. It should also have a 'relu' activation function.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer (15 units)\n",
    "model.add(Conv2D(15, input_shape = (img_rows, img_cols, 1), kernel_size =2, activation = 'relu'))\n",
    "\n",
    "\n",
    "# Add another convolutional layer (5 units)\n",
    "model.add(Conv2D(5, kernel_size = 2, activation = 'relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Congratulations!! You built a network with multiple convolution layers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/nero/Documents/Estudos/DataCamp/Python/courses/Image_Processing_with_Keras_in_Python/datasets/clothing_mnist/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 28, 28, 1), (50,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.drop(columns='label').iloc[:50, :].values.reshape(50,28,28,1)\n",
    "\n",
    "train_labels = data['label'][:50]\n",
    "\n",
    "\n",
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 28, 28, 1), (10, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data.drop(columns=['label']).iloc[50:60, :].values.reshape(10,28,28,1)\n",
    "test_labels = to_categorical(data['label'][50:60])\n",
    "\n",
    "test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - 3s 358ms/step - loss: 64.2108 - accuracy: 0.1000 - val_loss: 35.5033 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 21.9195 - accuracy: 0.3000 - val_loss: 26.3906 - val_accuracy: 0.2000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 7.2049 - accuracy: 0.6000 - val_loss: 26.9262 - val_accuracy: 0.3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.5399 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy calculated on the test data is not subject to overfitting.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Train a deep CNN to classify clothing images\n",
    "\n",
    "Training a deep learning model is very similar to training a single layer network. Once the model is constructed (as you have done in the previous exercise), the model needs to be compiled with the right set of parameters. Then, the model is fit by providing it with training data, as well as training labels. After training is done, the model can be evaluated on test data.\n",
    "\n",
    "The model you built in the previous exercise is available in your workspace.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Compile the model to use the categorical cross-entropy loss function and the Adam optimizer.\n",
    "    Train the network with train_data for 3 epochs with batches of 10 images each.\n",
    "    Use randomly selected 20% of the training data as validation data during training.\n",
    "    Evaluate the model with test_data, use a batch size of 10.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Accuracy calculated on the test data is not subject to overfitting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 27, 27, 10)        50        \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 10)        410       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6760)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 20283     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,743\n",
      "Trainable params: 20,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis model has 20,743 parameters!\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "How many parameters in a deep CNN?\n",
    "\n",
    "In this exercise, you will use Keras to calculate the total number of parameters along with the number of parameters in each layer of the network.\n",
    "\n",
    "We have already provided code that builds a deep CNN for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Summarize the network, providing a count of the number of parameters.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu', \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Summarize the model \n",
    "model.summary()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "This model has 20,743 parameters!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = pd.read_csv('/home/nero/Documents/Estudos/DataCamp/Python/courses/Image_Processing_with_Keras_in_Python/datasets/im_ch03.csv').drop(columns = ['Unnamed: 0']).values\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe resulting image is smaller, but retains the salient features in every location\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Write your own pooling operation\n",
    "\n",
    "As we have seen before, CNNs can have a lot of parameters. Pooling layers are often added between the convolutional layers of a neural network to summarize their outputs in a condensed manner, and reduce the number of parameters in the next layer in the network. This can help us if we want to train the network more rapidly, or if we don't have enough data to learn a very large number of parameters.\n",
    "\n",
    "A pooling layer can be described as a particular kind of convolution. For every window in the input it finds the maximal pixel value and passes only this pixel through. In this exercise, you will write your own max pooling operation, based on the code that you previously used to write a two-dimensional convolution operation.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Index into the input array (im) and select the right window.\n",
    "    Find the maximum in this window.\n",
    "    Allocate this into the right entry in the output array (result).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Result placeholder\n",
    "result = np.zeros((im.shape[0]//2, im.shape[1]//2))\n",
    "\n",
    "# Pooling operation\n",
    "for ii in range(result.shape[0]):\n",
    "    for jj in range(result.shape[1]):\n",
    "        result[ii, jj] = np.max(im[ii*2:ii*2+2, jj*2:jj*2+2])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "The resulting image is smaller, but retains the salient features in every location\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 27, 27, 15)        75        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 15)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 5)         305       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 720)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                7210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,590\n",
      "Trainable params: 7,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis model is even deeper, but has fewer parameters.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Keras pooling layers\n",
    "\n",
    "Keras implements a pooling operation as a layer that can be added to CNNs between other layers. In this exercise, you will construct a convolutional neural network similar to the one you have constructed before:\n",
    "\n",
    "Convolution => Convolution => Flatten => Dense\n",
    "\n",
    "However, you will also add a pooling layer. The architecture will add a single max-pooling layer between the convolutional layer and the dense layer with a pooling of 2x2:\n",
    "\n",
    "Convolution => Max pooling => Convolution => Flatten => Dense\n",
    "\n",
    "A Sequential model along with Dense, Conv2D, Flatten, and MaxPool2D objects are available in your workspace.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Add an input convolutional layer (15 units, kernel size of 2, relu activation).\n",
    "    Add a maximum pooling operation (pooling over windows of size 2x2).\n",
    "    Add another convolution layer (5 units, kernel size of 2, relu activation).\n",
    "    Flatten the output of the second convolution and add a Dense layer for output (3 categories, softmax activation).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size= 2, activation = 'relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "This model is even deeper, but has fewer parameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - 3s 181ms/step - loss: 14.4677 - accuracy: 0.1250 - val_loss: 8.3953 - val_accuracy: 0.2000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 9.2980 - accuracy: 0.2250 - val_loss: 7.2033 - val_accuracy: 0.2000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 6.2405 - accuracy: 0.2500 - val_loss: 6.9035 - val_accuracy: 0.3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9203 - accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis model is also very accurate!\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Train a deep CNN with pooling to classify images\n",
    "\n",
    "Training a CNN with pooling layers is very similar to training of the deep networks that y have seen before. Once the network is constructed (as you did in the previous exercise), the model needs to be appropriately compiled, and then training data needs to be provided, together with the other arguments that control the fitting procedure.\n",
    "\n",
    "The following model from the previous exercise is available in your workspace:\n",
    "\n",
    "Convolution => Max pooling => Convolution => Flatten => Dense\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Compile this model to use the categorical cross-entropy loss function and the Adam optimizer.\n",
    "    Train the model for 3 epochs with batches of size 10.\n",
    "    Use 20% of the data as validation data.\n",
    "    Evaluate the model on test_data with test_labels (also batches of size 10).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(train_data, train_labels, epochs = 3, batch_size = 10, validation_split = 0.20)\n",
    "\n",
    "# Evaluate on test data \n",
    "model.evaluate(test_data, test_labels, batch_size = 10)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "This model is also very accurate!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/nero/Documents/Estudos/DataCamp/Python/courses/Image_Processing_with_Keras_in_Python/datasets/full_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
