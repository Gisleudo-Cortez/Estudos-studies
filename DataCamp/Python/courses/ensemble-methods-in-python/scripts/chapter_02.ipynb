{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(path_data+'Pokemon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140481/3066382982.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = data.iloc[:, -1].replace({False:0, True:1})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "X = data.iloc[:, 4:-2]\n",
    "y = data.iloc[:, -1].replace({False:0, True:1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[144   6]\n",
      " [  2   8]]\n",
      "F1-Score: 0.667\n",
      "Confusion matrix:\n",
      " [[143   7]\n",
      " [  3   7]]\n",
      "F1-Score: 0.583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWell done! Notice how the restricted decision tree performs worse, and is only slightly better than random guessing.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Restricted and unrestricted decision trees\n",
    "\n",
    "For this exercise, we will revisit the Pokémon dataset from the last chapter. Recall that the goal is to predict whether or not a given Pokémon is legendary.\n",
    "\n",
    "Here, you will build two separate decision tree classifiers. In the first, you will specify the parameters min_samples_leaf and min_samples_split, but not a maximum depth, so that the tree can fully develop without any restrictions.\n",
    "\n",
    "In the second, you will specify some constraints by limiting the depth of the decision tree. By then comparing the two models, you'll better understand the notion of a \"weak\" learner.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Build an unrestricted decision tree using the parameters min_samples_leaf=3, min_samples_split=9, and random_state=500.\n",
    "---\n",
    "Build a restricted tree by replacing min_samples_leaf and min_samples_split with max_depth=4 and max_features=2.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build unrestricted decision tree\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Build restricted decision tree\n",
    "clf = DecisionTreeClassifier(max_depth=4, max_features=2, random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! Notice how the restricted decision tree performs worse, and is only slightly better than random guessing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "\"Weak\" decision tree\n",
    "\n",
    "In the previous exercise you built two decision trees. Which one is fine-tuned and which one is \"weak\"?\n",
    "\n",
    "Decision tree \"A\":\n",
    "\n",
    "    min_samples_leaf = 3 and min_samples_split = 9\n",
    "    F1-Score: ~58%\n",
    "\n",
    "Decision tree \"B\":\n",
    "\n",
    "    max_depth = 4 and max_features = 2\n",
    "    F1-Score: ~53%\n",
    "\n",
    "Both classifiers are available for you as clf_A and clf_B.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    Model A is \"weak\" while model B is fine-tuned.\n",
    "    \n",
    "    Model A is fine-tuned while model B is \"weak\". {Answer}\n",
    "    \n",
    "    Both models are fine-tuned with optimal parameters.\n",
    "    \n",
    "    Both models are \"weak\", as they are restricted.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct choice! Model A is a fine-tuned decision tree, with a decent performance on its own. Model B is 'weak', restricted in height and with performance just above 50%.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNicely done! You took a sample with replacement from the training set and built a decision tree with it. This represents one iteration of a bagging ensemble.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Training with bootstrapping\n",
    "\n",
    "Let's now build a \"weak\" decision tree classifier and train it on a sample of the training set drawn with replacement. This will help you understand what happens on every iteration of a bagging ensemble.\n",
    "\n",
    "To take a sample, you'll use pandas' .sample() method, which has a replace parameter. For example, the following line of code samples with replacement from the whole DataFrame df:\n",
    "\n",
    "df.sample(frac=1.0, replace=True, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Take a sample drawn with replacement (replace=True) from the whole (frac=1.0) training set, X_train.\n",
    "    Build a decision tree classifier using the parameter max_depth = 4.\n",
    "    Fit the model to the sampled training data.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Take a sample with replacement\n",
    "X_train_sample = X_train.sample(frac=1.0, replace=True, random_state=42)\n",
    "y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "# Build a \"weak\" Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=500)\n",
    "\n",
    "# Fit the model to the training sample\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nicely done! You took a sample with replacement from the training set and built a decision tree with it. This represents one iteration of a bagging ensemble.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def build_decision_tree(X_train, y_train, random_state=None):\n",
    "\t# Take a sample with replacement\n",
    "\tX_train_sample = X_train.sample(frac=1.0, replace=True, random_state=random_state)\n",
    "\ty_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "\t# Build a \"weak\" Decision Tree classifier\n",
    "\tclf = DecisionTreeClassifier(max_depth=4, random_state=500)\n",
    "\n",
    "\t# Fit the model on the training sample\n",
    "\tclf.fit(X_train_sample, y_train_sample)\n",
    "\t\n",
    "\treturn clf\n",
    "\n",
    "def predict_voting(classifiers, X):\n",
    "\t# Make the individual predictions\n",
    "\tpred_list = [clf.predict(X) for clf in classifiers]\n",
    "\t# Combine the predictions using \"Voting\"\n",
    "\tpred_vote = []\n",
    "\tfor i in range(X.shape[0]):\n",
    "\t\tindividual_preds = np.array([pred[i] for pred in pred_list])\n",
    "\t\tcombined_pred = stats.mode(individual_preds)[0]\n",
    "\t\tpred_vote.insert(i, combined_pred)\n",
    "\t\n",
    "\treturn pred_vote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nExcellent! You just built a custom bagging ensemble. This got a better performance than that of the single 'weak' model, and you only used 21 of them! Now that you have an intuition for how bagging ensembles work underneath the hood, let's learn how to build them using the scikit-learn framework.\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "A first attempt at bagging\n",
    "\n",
    "You've seen what happens in a single iteration of a bagging ensemble. Now let's build a custom bagging model!\n",
    "\n",
    "Two functions have been prepared for you:\n",
    "\n",
    "def build_decision_tree(X_train, y_train, random_state=None):\n",
    "    # Takes a sample with replacement,\n",
    "    # builds a \"weak\" decision tree,\n",
    "    # and fits it to the train set\n",
    "\n",
    "def predict_voting(classifiers, X_test):\n",
    "    # Makes the individual predictions \n",
    "    # and then combines them using \"Voting\"\n",
    "\n",
    "Technically, the build_decision_tree() function is what you did in the previous exercise. Here, you will build multiple such trees and then combine them. Let's see if this ensemble of \"weak\" models improves performance!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build the individual models by calling build_decision_tree(), passing the training set and the index i as the random state.\n",
    "    Predict the labels of the test set using predict_voting(), with the list of classifiers clf_list and the input test features.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build the list of individual models\n",
    "clf_list = []\n",
    "for i in range(21):\n",
    "\tweak_dt = build_decision_tree(X_train, y_train, random_state=i)\n",
    "\tclf_list.append(weak_dt)\n",
    "\n",
    "# Predict on the test set\n",
    "pred = predict_voting(clf_list, X_test)\n",
    "\n",
    "# Print the F1 score\n",
    "print('F1 score: {:.3f}'.format(f1_score(y_test, pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Excellent! You just built a custom bagging ensemble. This got a better performance than that of the single 'weak' model, and you only used 21 of them! Now that you have an intuition for how bagging ensembles work underneath the hood, let's learn how to build them using the scikit-learn framework.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou just built a bagging classifier using the scikit-learn framework. Well done! It got a better performance than our custom ensemble (0.67 vs 0.63) and also using only 21 estimators!\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Bagging: the scikit-learn way\n",
    "\n",
    "Let's now apply scikit-learn's BaggingClassifier to the Pokémon dataset.\n",
    "\n",
    "You obtained an F1 score of around 0.63 with your custom bagging ensemble.\n",
    "\n",
    "Will BaggingClassifier() beat it? Time to find out!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Instantiate the base model, clf_dt: a \"restricted\" decision tree with a max depth of 4.\n",
    "    Build a bagging classifier using 21 estimators, with the decision tree as base estimator.\n",
    "    Predict the labels of the test set.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Instantiate the base model\n",
    "clf_dt = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Build and train the Bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  clf_dt,\n",
    "  n_estimators=21,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "pred = clf_bag.predict(X_test)\n",
    "\n",
    "# Show the F1-score\n",
    "print('F1-Score: {:.3f}'.format(f1_score(y_test, pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You just built a bagging classifier using the scikit-learn framework. Well done! It got a better performance than our custom ensemble (0.67 vs 0.63) and also using only 21 estimators!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB-Score: 0.942\n",
      "Accuracy: 0.969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBoth scores are close and above 90%! Now you know how to use the out-of-bag score for bagging ensemble models. Great work! Let's now learn a few more bagging tips and tricks.\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Checking the out-of-bag score\n",
    "\n",
    "Let's now check the out-of-bag score for the model from the previous exercise.\n",
    "\n",
    "So far you've used the F1 score to measure performance. However, in this exercise you should use the accuracy score so that you can easily compare it to the out-of-bag score.\n",
    "\n",
    "The decision tree classifier from the previous exercise, clf_dt, is available in your workspace.\n",
    "\n",
    "The pokemon dataset is already loaded for you and split into train and test sets. In addition, the decision tree classifier was fit and is available for you as clf_dt to use it as base estimator.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build the bagging classifier using the decision tree as base estimator and 21 estimators. This time, use the out-of-bag score by specifying an argument for the oob_score parameter.\n",
    "    Print the classifier's out-of-bag score.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Build and train the bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  clf_dt,\n",
    "  n_estimators=21,\n",
    "  oob_score=True,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Print the out-of-bag score\n",
    "print('OOB-Score: {:.3f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Evaluate the performance on the test set to compare\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Both scores are close and above 90%! Now you know how to use the out-of-bag score for bagging ensemble models. Great work! Let's now learn a few more bagging tips and tricks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                  Time        0        1          2          3       4      5  \\\n",
       " 0  2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   \n",
       " 1  2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0   \n",
       " 2  2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   \n",
       " 3  2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0   \n",
       " 4  2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0   \n",
       " \n",
       "           6       7       8  ...       581     582     583     584      585  \\\n",
       " 0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       " 1  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       " 2   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       " 3  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       " 4  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       " \n",
       "       586     587     588       589  Pass/Fail  \n",
       " 0     NaN     NaN     NaN       NaN         -1  \n",
       " 1  0.0096  0.0201  0.0060  208.2045         -1  \n",
       " 2  0.0584  0.0484  0.0148   82.8602          1  \n",
       " 3  0.0202  0.0149  0.0044   73.8432         -1  \n",
       " 4  0.0202  0.0149  0.0044   73.8432         -1  \n",
       " \n",
       " [5 rows x 592 columns],\n",
       " (1567, 592))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_secom = pd.read_csv(path_data+'uci-secom.csv')\n",
    "uci_secom.head(), uci_secom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass/Fail\n",
      "-1    1463\n",
      " 1     104\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nCorrect! It seems like this target is imbalanced, as more than 90% of the tests are negative. An individual model may be prone to overfitting, so it's a good idea to leverage an ensemble method here.\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Exploring the UCI SECOM data\n",
    "\n",
    "To round out this chapter and solidify your understanding of bagging, it's time to work with a new dataset! This data is from a semi-conductor manufacturing process, obtained from the UCI Machine Learning Repository.\n",
    "\n",
    "Each row represents a production entity. The features are measurements from sensors or points in the process. The labels represent whether the entity passes (1) or fails (-1) the test.\n",
    "\n",
    "The dataset is loaded and available to you as uci_secom. The target is the 'Pass/Fail' column. Use the .value_counts() and .describe() methods to check this variable. What do you notice?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    There are fewer negative than positive tests.\n",
    "    \n",
    "    The target has many missing values.\n",
    "    \n",
    "    There is evidence of high class imbalance in the target. {Answer}\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "print(uci_secom['Pass/Fail'].value_counts(dropna=False))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct! It seems like this target is imbalanced, as more than 90% of the tests are negative. An individual model may be prone to overfitting, so it's a good idea to leverage an ensemble method here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_secom.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = uci_secom.iloc[:, :-1]\n",
    "y = uci_secom.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.70\n",
      "OOB-Score: 0.58\n",
      "[[416 170]\n",
      " [ 21  20]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:789: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:795: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNot bad for an initial model, with an accuracy ~71% and unbiased predictions for the test set. In addition, the out-of-bag score is a good indicator of the actual performance - close to 60%.\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "A more complex bagging model\n",
    "\n",
    "Having explored the semi-conductor data, let's now build a bagging classifier to predict the 'Pass/Fail' label given the input features.\n",
    "\n",
    "The preprocessed dataset is available in your workspace as uci_secom, and training and test sets have been created for you.\n",
    "\n",
    "As the target has a high class imbalance, use a \"balanced\" logistic regression as the base estimator here.\n",
    "\n",
    "We will also reduce the computation time for LogisticRegression with the parameter solver='liblinear', which is a faster optimizer than the default.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Instantiate a logistic regression to use as the base classifier with the parameters: class_weight='balanced', solver='liblinear', and random_state=42.\n",
    "    \n",
    "    Build a bagging classifier using the logistic regression as the base estimator, including the out-of-bag score, and using the maximum number of features as 10.\n",
    "    \n",
    "    Print the out-of-bag score to compare to the accuracy.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Build a balanced logistic regression\n",
    "clf_lr = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "\n",
    "# Build and fit a bagging classifier\n",
    "clf_bag = BaggingClassifier(clf_lr, max_features=10, oob_score=True, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy on the test set and show the out-of-bag score\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, pred)))\n",
    "print('OOB-Score: {:.2f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Not bad for an initial model, with an accuracy ~71% and unbiased predictions for the test set. In addition, the out-of-bag score is a good indicator of the actual performance - close to 60%.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.71      0.81       586\n",
      "           1       0.09      0.41      0.15        41\n",
      "\n",
      "    accuracy                           0.69       627\n",
      "   macro avg       0.52      0.56      0.48       627\n",
      "weighted avg       0.89      0.69      0.77       627\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGreat work! With the correct hyperparameters the model could get to a better performance.\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Tuning bagging hyperparameters\n",
    "\n",
    "While you can easily build a bagging classifier using the default parameters, it is highly recommended that you tune these in order to achieve optimal performance. Ideally, these should be optimized using K-fold cross-validation.\n",
    "\n",
    "In this exercise, let's see if we can improve model performance by modifying the parameters of the bagging classifier.\n",
    "\n",
    "Here we are also passing the parameter solver='liblinear' to LogisticRegression to reduce the computation time.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build a bagging classifier with 20 base estimators, 10 maximum features, and 0.65 (65%) maximum samples (max_samples). Sample without replacement.\n",
    "    \n",
    "    Use clf_bag to predict the labels of the test set, X_test.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.metrics import classification_report\n",
    "# Build a balanced logistic regression\n",
    "clf_base = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "\n",
    "# Build and fit a bagging classifier with custom parameters\n",
    "clf_bag = BaggingClassifier(clf_base, n_estimators=20, max_features=10, max_samples=0.65, bootstrap=False, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions and evaluate the accuracy on the test set\n",
    "y_pred = clf_bag.predict(X_test)\n",
    "print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great work! With the correct hyperparameters the model could get to a better performance.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
