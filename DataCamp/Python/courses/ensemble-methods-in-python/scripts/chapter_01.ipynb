{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>19M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>January 7, 2018</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              App        Category  Rating  \\\n",
       "0  Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
       "\n",
       "  Reviews Size Installs  Type Price Content Rating        Genres  \\\n",
       "0     159  19M  10,000+  Free     0       Everyone  Art & Design   \n",
       "\n",
       "      Last Updated Current Ver   Android Ver  \n",
       "0  January 7, 2018       1.0.0  4.0.3 and up  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(path_data+'googleplaystore.csv')\n",
    "ratings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 App        Category  Rating  \\\n",
      "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
      "1                                Coloring book moana  ART_AND_DESIGN     3.9   \n",
      "2  U Launcher Lite â€“ FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
      "3                              Sketch - Draw & Paint  ART_AND_DESIGN     4.5   \n",
      "4              Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN     4.3   \n",
      "\n",
      "  Reviews  Size     Installs  Type Price Content Rating  \\\n",
      "0     159   19M      10,000+  Free     0       Everyone   \n",
      "1     967   14M     500,000+  Free     0       Everyone   \n",
      "2   87510  8.7M   5,000,000+  Free     0       Everyone   \n",
      "3  215644   25M  50,000,000+  Free     0           Teen   \n",
      "4     967  2.8M     100,000+  Free     0       Everyone   \n",
      "\n",
      "                      Genres      Last Updated         Current Ver  \\\n",
      "0               Art & Design   January 7, 2018               1.0.0   \n",
      "1  Art & Design;Pretend Play  January 15, 2018               2.0.0   \n",
      "2               Art & Design    August 1, 2018               1.2.4   \n",
      "3               Art & Design      June 8, 2018  Varies with device   \n",
      "4    Art & Design;Creativity     June 20, 2018                 1.1   \n",
      "\n",
      "    Android Ver  \n",
      "0  4.0.3 and up  \n",
      "1  4.0.3 and up  \n",
      "2  4.0.3 and up  \n",
      "3    4.2 and up  \n",
      "4    4.4 and up               Rating\n",
      "count  9367.000000\n",
      "mean      4.193338\n",
      "std       0.537431\n",
      "min       1.000000\n",
      "25%       4.000000\n",
      "50%       4.300000\n",
      "75%       4.500000\n",
      "max      19.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIndeed! It looks like there are some faulty ratings (higher than 5) as the maximum is 19.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Exploring Google apps data\n",
    "\n",
    "The first dataset you'll work with contains information about the ratings of around 10,800 apps on the Google Play store. It has been preloaded into a DataFrame called ratings. There are 13 features that describe a given app, such as 'Category' and 'Price'. The goal is to use this information to predict the rating of an app, which can range from 1 to 5.\n",
    "\n",
    "Before doing that, it's a good idea to familiarize yourself with the dataset using pandas methods such as .head() and .describe(). Explore the data in the IPython Shell and select the incorrect statement from the options below.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    The average rating is around 3.62.\n",
    "    \n",
    "    The median rating is greater than the mean.\n",
    "    \n",
    "    All the ratings lie in the range from 0 to 5. {Answer}\n",
    "    \n",
    "    Most of the ratings are 3 or higher.\n",
    "    \n",
    "    'Rating' is the only numerical feature.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "print(ratings.head(), ratings.describe())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Indeed! It looks like there are some faulty ratings (higher than 5) as the maximum is 19.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9367, 6), (9367,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ratings[['Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating']].dropna().iloc[:9367, :]\n",
    "\n",
    "y = ratings['Rating'].dropna()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240251/2023531535.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X.replace(\"\", 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def remove_non_numeric(column):\n",
    "    \"\"\"Removes non-numeric characters from a DataFrame column.\n",
    "\n",
    "    Args:\n",
    "        column (pd.Series): A pandas Series containing strings.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A pandas Series with non-numeric characters removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return column.str.replace(r\"[^\\d\\.]\", \"\", regex=True).dropna()\n",
    "\n",
    "X = X.apply(remove_non_numeric, axis=1)\n",
    "X.replace(\"\", 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nGood job! As the MAE is around 0.61, the error of the model is, on average, less than one rating point away from the actual value! Having refreshed our understanding of how to build scikit-learn models, let's now jump into our first ensemble method: Voting!\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Predicting the rating of an app\n",
    "\n",
    "Having explored the Google apps dataset in the previous exercise, let's now build a model that predicts the rating of an app given a subset of its features.\n",
    "\n",
    "To do this, you'll use scikit-learn's DecisionTreeRegressor. As decision trees are the building blocks of many ensemble models, refreshing your memory of how they work will serve you well throughout this course.\n",
    "\n",
    "We'll use the MAE (mean absolute error) as the evaluation metric. This metric is highly interpretable, as it represents the average absolute difference between actual and predicted ratings.\n",
    "\n",
    "All required modules have been pre-imported for you. The features and target are available in the variables X and y, respectively.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Use train_test_split() to split X and y into train and test sets. Use 20%, or 0.2, as the test size.\n",
    "    \n",
    "    Instantiate a DecisionTreeRegressor(), reg_dt, with the following hyperparameters: min_samples_leaf = 3 and min_samples_split = 9.\n",
    "    \n",
    "    Fit the regressor to the training set using .fit().\n",
    "    \n",
    "    Predict the labels of the test set using .predict().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Split into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the regressor\n",
    "reg_dt = DecisionTreeRegressor(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "\n",
    "# Fit to the training set\n",
    "reg_dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "y_pred = reg_dt.predict(X_test)\n",
    "print('MAE: {:.3f}'.format(mean_absolute_error(y_test, y_pred)))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! As the MAE is around 0.61, the error of the model is, on average, less than one rating point away from the actual value! Having refreshed our understanding of how to build scikit-learn models, let's now jump into our first ensemble method: Voting!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Choosing the best model\n",
    "\n",
    "In this exercise, you'll compare different classifiers and choose the one that performs the best.\n",
    "\n",
    "The dataset here - already loaded and split into train and test sets - consists of PokÃ©mon - their stats, types, and whether or not they're legendary. The objective of our classifiers is to predict this 'Legendary' variable.\n",
    "\n",
    "Three individual classifiers have been fitted to the training set:\n",
    "\n",
    "    clf_lr is a logistic regression.\n",
    "    clf_dt is a decision tree.\n",
    "    clf_knn is a 5-nearest neighbors classifier.\n",
    "\n",
    "As the classes here are imbalanced - only 65 of the 800 PokÃ©mon in the dataset are legendary - we'll use F1-Score to evaluate the performance. Scikit-learn's f1_score() has been imported for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Predict the labels of X_test using each of the classifiers - clf_lr, clf_dt, and clf_knn.\n",
    "---\n",
    "\n",
    "    Calculate the F1-score for each of the classifiers. The f1_score() function takes in two arguments: the actual labels, y_test, and the classifier's predicted labels.\n",
    "---\n",
    "Question\n",
    "\n",
    "Which model performs the best on the test set?\n",
    "Possible answers:\n",
    "    \n",
    "    Logistic regression (clf_lr). {Answer}\n",
    "    \n",
    "    Decision tree (clf_dt).\n",
    "    \n",
    "    5-nearest neighbors (clf_knn).\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Make the invidual predictions\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "pred_dt = clf_dt.predict(X_test)\n",
    "pred_knn = clf_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of each model\n",
    "score_lr = f1_score(y_test, pred_lr)\n",
    "score_dt = f1_score(y_test, pred_dt)\n",
    "score_knn = f1_score(y_test, pred_knn)\n",
    "\n",
    "# Print the scores\n",
    "print(score_lr)\n",
    "print(score_dt)\n",
    "print(score_knn)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great choice! The logistic regression got the best F1-Score: ~59%. Therefore, it's the best individual choice!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Assembling your first ensemble\n",
    "\n",
    "It's time to build your first ensemble model! The PokÃ©mon dataset from the previous exercise has been loaded and split into train and test sets.\n",
    "\n",
    "Your job is to leverage the voting ensemble technique using the sklearn API. It's up to you to instantiate the individual models and pass them as parameters to build your first voting classifier.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Instantiate a KNeighborsClassifier called clf_knn with 5 neighbors (specified using n_neighbors).\n",
    "    \n",
    "    Instantiate a \"balanced\" LogisticRegression called clf_lr (specified using class_weight).\n",
    "    \n",
    "    Instantiate a DecisionTreeClassifier called clf_dt with min_samples_leaf = 3 and min_samples_split = 9.\n",
    "    \n",
    "    Build a VotingClassifier using the parameter estimators to specify the following list of (str, estimator) tuples: 'knn', clf_knn, 'lr', clf_lr, and 'dt', clf_dt.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Instantiate the individual models\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_lr = LogisticRegression(class_weight='balanced')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "\n",
    "# Create and fit the voting classifier\n",
    "clf_vote = VotingClassifier(\n",
    "    estimators=[('knn', clf_knn), ('lr', clf_lr), ('dt', clf_dt)]\n",
    ")\n",
    "clf_vote.fit(X_train, y_train)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Congratulations - you just built your first ensemble model! It's now time to evaluate it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Evaluating your ensemble\n",
    "\n",
    "In the previous exercise, you built your first voting classifier. Let's now evaluate it and compare it to that of the individual models.\n",
    "\n",
    "The individual models (clf_knn, clf_dt, and clf_lr) and the voting classifier (clf_vote) have already been loaded and trained.\n",
    "\n",
    "Remember to use f1_score() to evaluate the performance. In addition, you'll create a classification report on the test set (X_test, y_test) using the classification_report() function.\n",
    "\n",
    "Will your voting classifier beat the 58% F1-score of the decision tree?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Use the voting classifier, clf_vote, to predict the labels of the test set, X_test.\n",
    "    \n",
    "    Calculate the F1-Score of the voting classifier.\n",
    "    \n",
    "    Calculate the classification report of the voting classifier by passing in y_test and pred_vote to classification_report().\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Calculate the predictions using the voting classifier\n",
    "pred_vote = clf_vote.predict(X_test)\n",
    "\n",
    "# Calculate the F1-Score of the voting classifier\n",
    "score_vote = f1_score(y_test, pred_vote)\n",
    "print('F1-Score: {:.3f}'.format(score_vote))\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(y_test, pred_vote)\n",
    "print(report)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Legendary! The performance is not higher, but is at least as good as the best individual model - the decision tree. This may be because the other two models had a performance around 10% lower than the decision tree.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>actual</th>\n",
       "      <th>pred</th>\n",
       "      <th>alive</th>\n",
       "      <th>plod</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>male</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>...</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>boolDeadRelations</th>\n",
       "      <th>isPopular</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.946</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.613</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>1</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.507</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.924</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.383</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>0</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No  actual  pred  alive   plod                  name  \\\n",
       "0     1       0     0  0.054  0.946  Viserys II Targaryen   \n",
       "1     2       1     0  0.387  0.613           Walder Frey   \n",
       "2     3       1     0  0.493  0.507          Addison Hill   \n",
       "3     4       0     0  0.076  0.924           Aemma Arryn   \n",
       "4     5       1     1  0.617  0.383        Sylva Santagar   \n",
       "\n",
       "                  title  male   culture  dateOfBirth  ...  isAliveHeir  \\\n",
       "0                   NaN     1       NaN          NaN  ...          0.0   \n",
       "1  Lord of the Crossing     1  Rivermen        208.0  ...          NaN   \n",
       "2                   Ser     1       NaN          NaN  ...          NaN   \n",
       "3                 Queen     0       NaN         82.0  ...          NaN   \n",
       "4            Greenstone     0   Dornish        276.0  ...          NaN   \n",
       "\n",
       "  isAliveSpouse isMarried isNoble   age numDeadRelations  boolDeadRelations  \\\n",
       "0           NaN         0       0   NaN               11                  1   \n",
       "1           1.0         1       1  97.0                1                  1   \n",
       "2           NaN         0       1   NaN                0                  0   \n",
       "3           0.0         1       1  23.0                0                  0   \n",
       "4           1.0         1       1  29.0                0                  0   \n",
       "\n",
       "   isPopular  popularity  isAlive  \n",
       "0          1    0.605351        0  \n",
       "1          1    0.896321        1  \n",
       "2          0    0.267559        1  \n",
       "3          0    0.183946        0  \n",
       "4          0    0.043478        1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got = pd.read_csv(path_data+'character-predictions.csv')\n",
    "got.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>actual</th>\n",
       "      <th>pred</th>\n",
       "      <th>alive</th>\n",
       "      <th>plod</th>\n",
       "      <th>male</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>DateoFdeath</th>\n",
       "      <th>book1</th>\n",
       "      <th>book2</th>\n",
       "      <th>...</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>boolDeadRelations</th>\n",
       "      <th>isPopular</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>973.500000</td>\n",
       "      <td>0.745632</td>\n",
       "      <td>0.687050</td>\n",
       "      <td>0.634470</td>\n",
       "      <td>0.365530</td>\n",
       "      <td>0.619219</td>\n",
       "      <td>1577.364896</td>\n",
       "      <td>2950.193694</td>\n",
       "      <td>0.198356</td>\n",
       "      <td>0.374615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>0.141829</td>\n",
       "      <td>0.460946</td>\n",
       "      <td>-1293.563510</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.074512</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>0.089584</td>\n",
       "      <td>0.745632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>561.906131</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.463813</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>0.485704</td>\n",
       "      <td>19565.414460</td>\n",
       "      <td>28192.245529</td>\n",
       "      <td>0.398864</td>\n",
       "      <td>0.484148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486985</td>\n",
       "      <td>0.415684</td>\n",
       "      <td>0.348965</td>\n",
       "      <td>0.498601</td>\n",
       "      <td>19564.340993</td>\n",
       "      <td>1.383910</td>\n",
       "      <td>0.262669</td>\n",
       "      <td>0.235864</td>\n",
       "      <td>0.160568</td>\n",
       "      <td>0.435617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-298001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>487.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391250</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>973.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735500</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1459.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.608750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1946.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>298299.000000</td>\n",
       "      <td>298299.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              S.No       actual         pred        alive         plod  \\\n",
       "count  1946.000000  1946.000000  1946.000000  1946.000000  1946.000000   \n",
       "mean    973.500000     0.745632     0.687050     0.634470     0.365530   \n",
       "std     561.906131     0.435617     0.463813     0.312637     0.312637   \n",
       "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     487.250000     0.000000     0.000000     0.391250     0.101000   \n",
       "50%     973.500000     1.000000     1.000000     0.735500     0.264500   \n",
       "75%    1459.750000     1.000000     1.000000     0.899000     0.608750   \n",
       "max    1946.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              male    dateOfBirth    DateoFdeath        book1        book2  \\\n",
       "count  1946.000000     433.000000     444.000000  1946.000000  1946.000000   \n",
       "mean      0.619219    1577.364896    2950.193694     0.198356     0.374615   \n",
       "std       0.485704   19565.414460   28192.245529     0.398864     0.484148   \n",
       "min       0.000000     -28.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     240.000000     282.000000     0.000000     0.000000   \n",
       "50%       1.000000     268.000000     299.000000     0.000000     0.000000   \n",
       "75%       1.000000     285.000000     299.000000     0.000000     1.000000   \n",
       "max       1.000000  298299.000000  298299.000000     1.000000     1.000000   \n",
       "\n",
       "       ...  isAliveHeir  isAliveSpouse    isMarried      isNoble  \\\n",
       "count  ...    23.000000     276.000000  1946.000000  1946.000000   \n",
       "mean   ...     0.652174       0.778986     0.141829     0.460946   \n",
       "std    ...     0.486985       0.415684     0.348965     0.498601   \n",
       "min    ...     0.000000       0.000000     0.000000     0.000000   \n",
       "25%    ...     0.000000       1.000000     0.000000     0.000000   \n",
       "50%    ...     1.000000       1.000000     0.000000     0.000000   \n",
       "75%    ...     1.000000       1.000000     0.000000     1.000000   \n",
       "max    ...     1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "                 age  numDeadRelations  boolDeadRelations    isPopular  \\\n",
       "count     433.000000       1946.000000        1946.000000  1946.000000   \n",
       "mean    -1293.563510          0.305755           0.074512     0.059096   \n",
       "std     19564.340993          1.383910           0.262669     0.235864   \n",
       "min   -298001.000000          0.000000           0.000000     0.000000   \n",
       "25%        18.000000          0.000000           0.000000     0.000000   \n",
       "50%        27.000000          0.000000           0.000000     0.000000   \n",
       "75%        50.000000          0.000000           0.000000     0.000000   \n",
       "max       100.000000         15.000000           1.000000     1.000000   \n",
       "\n",
       "        popularity      isAlive  \n",
       "count  1946.000000  1946.000000  \n",
       "mean      0.089584     0.745632  \n",
       "std       0.160568     0.435617  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.013378     0.000000  \n",
       "50%       0.033445     1.000000  \n",
       "75%       0.086957     1.000000  \n",
       "max       1.000000     1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nYou're right! It looks like there are no missing values in this column. Other features in the dataset do have some missing values, however.\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Journey to Westeros\n",
    "\n",
    "If you're a Game of Thrones fan, you might already know all about the fictional world of Westeros and the characters that inhabit it. Regardless, it's important to explore a new dataset before doing any modeling. That's what you'll do now!\n",
    "\n",
    "The dataset is loaded into the environment and available to you as got, the commonly used acronym for Game of Thrones.\n",
    "\n",
    "The target variable here is 'actual'. It represents whether a character is alive (1) or not (0). First explore the target using the .describe() method. What can you conclude about it?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    The maximum value is 1946.\n",
    "    \n",
    "    There are no missing values. {Answer}\n",
    "    \n",
    "    Around 75% of the characters die.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "display(got.describe())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "You're right! It looks like there are no missing values in this column. Other features in the dataset do have some missing values, however.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Predicting GoT deaths\n",
    "\n",
    "While the target variable does not have any missing values, other features do. As the focus of the course is not on data cleaning and preprocessing, we have already done the following preprocessing for you:\n",
    "\n",
    "    Replaced NA values with 0.\n",
    "    Replace negative values of age with 0.\n",
    "    Replace NA values of age with the mean.\n",
    "\n",
    "Let's now build an ensemble model using the averaging technique. The following individual models have been built:\n",
    "\n",
    "    Logistic Regression (clf_lr).\n",
    "    Decision Tree (clf_dt).\n",
    "    Support Vector Machine (clf_svm).\n",
    "\n",
    "As the target is binary, all these models might have good individual performance. Your objective is to combine them using averaging. Recall from the video that this is the same as a soft voting approach, so you should still use the VotingClassifier().\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Set up the list of (string, estimator) tuples. Use 'lr' for clf_lr, 'dt' for clf_dt, and 'svm' for clf_svm.\n",
    "    \n",
    "    Build an averaging classifier called clf_avg. Be sure to specify an argument for the voting parameter.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build the individual models\n",
    "clf_lr = LogisticRegression(class_weight='balanced')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_svm = SVC(probability=True, class_weight='balanced', random_state=500)\n",
    "\n",
    "# List of (string, estimator) tuples\n",
    "estimators = [('lr',clf_lr),('dt',clf_dt),('svm',clf_svm)]\n",
    "\n",
    "# Build and fit an averaging classifier\n",
    "clf_avg = VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "clf_avg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "acc_avg = accuracy_score(y_test,  clf_avg.predict(X_test))\n",
    "print('Accuracy: {:.2f}'.format(acc_avg))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job predicting the GoT deaths! With these three individual models, we could achieve a combined accuracy of ~80%!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Soft vs. hard voting\n",
    "\n",
    "You've now practiced building two types of ensemble methods: Voting and Averaging (soft voting). Which one is better? It's best to try both of them and then compare their performance. Let's try this now using the Game of Thrones dataset.\n",
    "\n",
    "Three individual classifiers have been instantiated for you:\n",
    "\n",
    "    A DecisionTreeClassifier (clf_dt).\n",
    "    A LogisticRegression (clf_lr).\n",
    "    A KNeighborsClassifier (clf_knn).\n",
    "\n",
    "Your task is to try both voting and averaging to determine which is better.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Prepare the list of (string, estimator) tuples. Use 'dt' as the label for clf_dt, 'lr' for clf_lr, and 'knn' for clf_knn.\n",
    "    \n",
    "    Build a voting classifier called clf_vote.\n",
    "    \n",
    "    Build an averaging classifier called clf_avg.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# List of (string, estimator) tuples\n",
    "estimators = estimators = [('lr',clf_lr),('dt',clf_dt),('knn',clf_knn)]\n",
    "\n",
    "# Build and fit a voting classifier\n",
    "clf_vote = VotingClassifier(estimators)\n",
    "clf_vote.fit(X_train, y_train)\n",
    "\n",
    "# Build and fit an averaging classifier\n",
    "clf_avg = VotingClassifier(estimators, voting='soft')\n",
    "clf_avg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of both models\n",
    "acc_vote = accuracy_score(y_test, clf_vote.predict(X_test))\n",
    "acc_avg = accuracy_score(y_test,  clf_avg.predict(X_test))\n",
    "print('Voting: {:.2f}, Averaging: {:.2f}'.format(acc_vote, acc_avg))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done, and congratulations on completing Chapter 1! It looks like 'Voting' was better to predict GoT deaths. When feasible, try both approaches and choose the better performing one. It's now time to learn about Bagging!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
