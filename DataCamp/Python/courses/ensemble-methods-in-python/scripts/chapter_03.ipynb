{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "movies = pd.read_csv(path_data+'tmdb_5000_movies.csv')\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             budget             id   popularity       revenue      runtime  \\\n",
      "count  4.803000e+03    4803.000000  4803.000000  4.803000e+03  4801.000000   \n",
      "mean   2.904504e+07   57165.484281    21.492301  8.226064e+07   106.875859   \n",
      "std    4.072239e+07   88694.614033    31.816650  1.628571e+08    22.611935   \n",
      "min    0.000000e+00       5.000000     0.000000  0.000000e+00     0.000000   \n",
      "25%    7.900000e+05    9014.500000     4.668070  0.000000e+00    94.000000   \n",
      "50%    1.500000e+07   14629.000000    12.921594  1.917000e+07   103.000000   \n",
      "75%    4.000000e+07   58610.500000    28.313505  9.291719e+07   118.000000   \n",
      "max    3.800000e+08  459488.000000   875.581305  2.787965e+09   338.000000   \n",
      "\n",
      "       vote_average    vote_count  log-revenue  \n",
      "count   4803.000000   4803.000000  4803.000000  \n",
      "mean       6.092172    690.217989         -inf  \n",
      "std        1.194612   1234.585891          NaN  \n",
      "min        0.000000      0.000000         -inf  \n",
      "25%        5.600000     54.000000          NaN  \n",
      "50%        6.200000    235.000000    16.768857  \n",
      "75%        6.800000    737.000000    18.347219  \n",
      "max       10.000000  13752.000000    21.748578  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/home/nero/Documents/Estudos/estudos/lib/python3.11/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThat's it! It appears that even after the log-transformation, there are many zero values, around 30% to be more precise.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Introducing the movie database\n",
    "\n",
    "Throughout this chapter, you'll be working with the TMDb (The Movie Database). This contains metadata on around 5000 movies.\n",
    "\n",
    "The dataset is loaded and available to you as movies.\n",
    "\n",
    "Your main objective is to predict movie revenue - more specifically, log-revenue, which is the normalized version of the revenue feature.\n",
    "\n",
    "Use the .describe() method to explore this feature. You can also inspect the histogram to the right. What can you conclude?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "    \n",
    "    The average log-revenue is around 16.77.\n",
    "    \n",
    "    There are many zero values.\n",
    "    \n",
    "    There many extreme values.\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "movies['log-revenue'] = np.log(movies.revenue)\n",
    "print(movies.describe())\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "That's it! It appears that even after the log-transformation, there are many zero values, around 30% to be more precise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   budget        4803 non-null   int64  \n",
      " 1   popularity    4803 non-null   float64\n",
      " 2   runtime       4801 non-null   float64\n",
      " 3   vote_average  4803 non-null   float64\n",
      " 4   vote_count    4803 non-null   int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 187.7 KB\n",
      "None\n",
      "             budget   popularity      runtime  vote_average    vote_count\n",
      "count  4.803000e+03  4803.000000  4801.000000   4803.000000   4803.000000\n",
      "mean   2.904504e+07    21.492301   106.875859      6.092172    690.217989\n",
      "std    4.072239e+07    31.816650    22.611935      1.194612   1234.585891\n",
      "min    0.000000e+00     0.000000     0.000000      0.000000      0.000000\n",
      "25%    7.900000e+05     4.668070    94.000000      5.600000     54.000000\n",
      "50%    1.500000e+07    12.921594   103.000000      6.200000    235.000000\n",
      "75%    4.000000e+07    28.313505   118.000000      6.800000    737.000000\n",
      "max    3.800000e+08   875.581305   338.000000     10.000000  13752.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nCorrect! The only feature with missing values is 'runtime'. But there are only two missing values, so it's not a critical issue. However, all features are on different scales, and therefore need to be normalized.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Exploring movie features\n",
    "\n",
    "In the rest of this chapter, you will use boosting algorithms to build models that predict the log-revenue of movies based on the following features: 'budget', 'popularity', 'runtime', 'vote_average', and 'vote_count'. There are many more features, but these will be of primary interest. Having explored the target in the previous exercise, it's now time to explore these features!\n",
    "\n",
    "The features of interest have been loaded into the features variable. Use the .describe() method to explore it. What do you notice?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers\n",
    "    \n",
    "    The only feature with missing values is 'runtime'. {Answer}\n",
    "    \n",
    "    All the features are on the same scale.\n",
    "    \n",
    "    Some of the features contain negative values.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "print(movies[['budget', 'popularity', 'runtime', 'vote_average','vote_count']].info())\n",
    "print(movies[['budget', 'popularity', 'runtime', 'vote_average','vote_count']].describe())\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct! The only feature with missing values is 'runtime'. But there are only two missing values, so it's not a critical issue. However, all features are on different scales, and therefore need to be normalized.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movies[['budget', 'popularity', 'runtime', 'vote_average','vote_count']].fillna(0)\n",
    "y = movies['log-revenue'].fillna(0).replace(-np.inf, y.max())\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWell done! This simple linear regression model provides a RMSE of around 7.34. Let's try and boost the model now!\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Predicting movie revenue\n",
    "\n",
    "Let's begin the challenge of predicting movie revenue by building a simple linear regression to estimate the log-revenue of movies based on the 'budget' feature. The metric you will use here is the RMSE (root mean squared error). To calculate this using scikit-learn, you can use the mean_squared_error() function from the sklearn.metrics module and then take its square root using numpy.\n",
    "\n",
    "The movies dataset has been loaded for you and split into train and test sets. Additionally, the missing values have been replaced with zeros. We also standardized the input feature by using StandardScaler(). Check out DataCamp's courses on cleaning data and feature engineering if you want to learn more about preprocessing for machine learning.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Instantiate the default LinearRegression model.\n",
    "    \n",
    "    Calculate the predictions on the test set.\n",
    "    \n",
    "    Calculate the RMSE. The mean_squared_error() function requires two arguments: y_test, followed by the predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build and fit linear regression model\n",
    "reg_lm = LinearRegression()\n",
    "reg_lm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_lm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! This simple linear regression model provides a RMSE of around 7.34. Let's try and boost the model now!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Boosting for predicted revenue\n",
    "\n",
    "The initial model got an RMSE of around 7.34. Let's see if we can improve this using an iteration of boosting.\n",
    "\n",
    "You'll build another linear regression, but this time the target values are the errors from the base model, calculated as follows:\n",
    "\n",
    "y_train_error = pred_train - y_train\n",
    "y_test_error = pred_test - y_test\n",
    "\n",
    "For this model you'll use 'popularity' feature instead, hoping that it can provide more informative patterns than with the 'budget' feature alone. This is available to you as X_train_pop and X_test_pop. As in the previous exercise, the input features have been standardized for you.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Fit a linear regression model to the previous errors using X_train_pop and y_train_error.\n",
    "    \n",
    "    Calculate the predicted errors on the test set, X_test_pop.\n",
    "    \n",
    "    Calculate the RMSE, like in the previous exercise, using y_test_error and pred_error.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Fit a linear regression model to the previous errors\n",
    "reg_error = LinearRegression()\n",
    "reg_error.fit(X_train_pop, y_train_error)\n",
    "\n",
    "# Calculate the predicted errors on the test set\n",
    "pred_error = reg_error.predict(X_test_pop)\n",
    "\n",
    "# Evaluate the updated performance\n",
    "rmse_error = np.sqrt(mean_squared_error(y_test_error, pred_error))\n",
    "print('RMSE: {:.3f}'.format(rmse_error))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Excellent! Fitting a linear regression to try to fix the errors of the previous model provided a lower RMSE of around 7.28. This is boosting in action!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood job! Your first AdaBoost ensemble model produced a RMSE of around 7.18 - better than the custom model!\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Your first AdaBoost model\n",
    "\n",
    "In the previous lesson you built models to predict the log-revenue of movies. You started with a simple linear regression and got an RMSE of 7.34. Then, you tried to improve it with an iteration of boosting, getting to a lower RMSE of 7.28.\n",
    "\n",
    "In this exercise, you'll build your first AdaBoost model - an AdaBoostRegressor - in an attempt to improve performance even further.\n",
    "\n",
    "The movies dataset has been loaded and split into train and test sets. Here you'll be using the 'budget' and 'popularity' features, which were already standardized for you using StandardScaler() from sklearn.preprocessing module.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    Instantiate the default linear regression model.\n",
    "    \n",
    "    Build and fit an AdaBoostRegressor, using the linear regression as the base model and 12 estimators.\n",
    "    \n",
    "    Calculate the predictions on the test set.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# Instantiate the default linear regression model\n",
    "reg_lm = LinearRegression()\n",
    "\n",
    "# Build and fit an AdaBoost regressor\n",
    "reg_ada = AdaBoostRegressor(reg_lm, n_estimators=12, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! Your first AdaBoost ensemble model produced a RMSE of around 7.18 - better than the custom model!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAmazing! Using a decision tree instead of a linear regression as the base estimator reduced the RMSE to around 5.44!\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Tree-based AdaBoost regression\n",
    "\n",
    "AdaBoost models are usually built with decision trees as the base estimators. Let's give this a try now and see if model performance improves even further.\n",
    "\n",
    "We'll use twelve estimators as before to have a fair comparison. There's no need to instantiate the decision tree as it is the base estimator by default.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build and fit an AdaBoostRegressor using 12 estimators. You do not have to specify a base estimator.\n",
    "    \n",
    "    Calculate the predictions on the test set.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build and fit a tree-based AdaBoost regressor\n",
    "reg_ada = AdaBoostRegressor(n_estimators=12, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Amazing! Using a decision tree instead of a linear regression as the base estimator reduced the RMSE to around 5.44!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGood job! Improving our model could get us to a RMSE close to 5.15!\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Making the most of AdaBoost\n",
    "\n",
    "As you have seen, for predicting movie revenue, AdaBoost gives the best results with decision trees as the base estimator.\n",
    "\n",
    "In this exercise, you'll specify some parameters to extract even more performance. In particular, you'll use a lower learning rate to have a smoother update of the hyperparameters. Therefore, the number of estimators should increase. Additionally, the following features have been added to the data: 'runtime', 'vote_average', and 'vote_count'.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build an AdaBoostRegressor using 100 estimators and a learning rate of 0.01.\n",
    "\n",
    "    Fit reg_ada to the training set and calculate the predictions on the test set.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build and fit an AdaBoost regressor\n",
    "reg_ada = AdaBoostRegressor(n_estimators=100, learning_rate=0.01, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job! Improving our model could get us to a RMSE close to 5.15!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64295 entries, 0 to 64294\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   App                     64295 non-null  object \n",
      " 1   Translated_Review       37427 non-null  object \n",
      " 2   Sentiment               37432 non-null  object \n",
      " 3   Sentiment_Polarity      37432 non-null  float64\n",
      " 4   Sentiment_Subjectivity  37432 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 2.5+ MB\n",
      "None                         App Translated_Review Sentiment  Sentiment_Polarity  \\\n",
      "count                 64295             37427     37432        37432.000000   \n",
      "unique                 1074             27994         3                 NaN   \n",
      "top     Angry Birds Classic              Good  Positive                 NaN   \n",
      "freq                    320               247     23998                 NaN   \n",
      "mean                    NaN               NaN       NaN            0.182146   \n",
      "std                     NaN               NaN       NaN            0.351301   \n",
      "min                     NaN               NaN       NaN           -1.000000   \n",
      "25%                     NaN               NaN       NaN            0.000000   \n",
      "50%                     NaN               NaN       NaN            0.150000   \n",
      "75%                     NaN               NaN       NaN            0.400000   \n",
      "max                     NaN               NaN       NaN            1.000000   \n",
      "\n",
      "        Sentiment_Subjectivity  \n",
      "count             37432.000000  \n",
      "unique                     NaN  \n",
      "top                        NaN  \n",
      "freq                       NaN  \n",
      "mean                  0.492704  \n",
      "std                   0.259949  \n",
      "min                   0.000000  \n",
      "25%                   0.357143  \n",
      "50%                   0.514286  \n",
      "75%                   0.650000  \n",
      "max                   1.000000  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIHCAYAAABt18EpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABES0lEQVR4nO3deXgNd///8ddJOImILIjEEonEGpTaQ2lpKkoXqovWEqrauklLbkruW213VavVWkt7t0UXLVq0trSEUJXailgqdymlCIokIiQk8/uj35xfz8SWCOeI5+O65rozn3mfmfcc9/DqZM7nWAzDMAQAAADAxsXRDQAAAADOhpAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwATqZ3794KDg52dBsAcEcjJAO4o+3cuVOPP/64goKC5O7ursqVK+uBBx7Q1KlTb+pxjx49qtGjR2v79u039Tg3S2ZmpkaPHq2EhIQCve748eMaMmSIateuLQ8PD5UuXVqNGzfWa6+9ptTU1JvSa0HNnTtXkyZNcnQbABzMYhiG4egmAMARNmzYoLZt26pq1aqKiopSQECADh8+rJ9++kn79+/Xvn37btqxt2zZoqZNm2rWrFnq3bu33baLFy8qNzdXbm5uN+34N+rPP/+Un5+fRo0apdGjR1/XazZv3qyOHTsqIyNDPXr0UOPGjSX99V58+eWXatmypb7//vub2PX1eeihh7Rr1y4dPHjQ0a0AcKASjm4AABxl3Lhx8vb21ubNm+Xj42O37cSJE45pSlLJkiUdduybJTU1VV26dJGrq6u2bdum2rVr220fN26c/vvf/zqoOwDIj8ctANyx9u/fr7p16+YLyJJUoUKFfGOfffaZGjdurFKlSqls2bLq1q2bDh8+bFdz3333qV69etqzZ4/atm0rDw8PVa5cWRMmTLDVJCQkqGnTppKkPn36yGKxyGKxaPbs2ZLyP5N88OBBWSwWvf3225o+fbpCQkLk4eGh9u3b6/DhwzIMQ//5z39UpUoVlSpVSo8++qhOnz6dr/8VK1aodevWKl26tMqUKaNOnTpp9+7ddjW9e/eWp6enjhw5os6dO8vT01N+fn4aMmSIcnJybP34+flJksaMGWPr/2p3lN9//30dOXJE77zzTr6ALEn+/v4aMWKE3dh7772nunXrys3NTZUqVdKAAQPyPZIRHByc70689Nefw3333WdbT0hIkMVi0fz58zVu3DhVqVJF7u7uuv/+++1+Y3Dfffdp2bJl+v33323n9fc/i6lTp6pu3bry8PCQr6+vmjRporlz517xvAHcvriTDOCOFRQUpMTERO3atUv16tW7au24ceP06quv6sknn9Rzzz2nkydPaurUqWrTpo22bdtmF7TPnDmjDh066LHHHtOTTz6pr776SsOGDVP9+vX14IMPqk6dOho7dqxGjhyp559/Xq1bt5YktWzZ8qo9fP7558rOzlZ0dLROnz6tCRMm6Mknn1S7du2UkJCgYcOGad++fZo6daqGDBmijz/+2PbaTz/9VFFRUYqMjNSbb76pzMxMzZgxQ/fcc4+2bdtmFwRzcnIUGRmp5s2b6+2339aqVas0ceJEhYaGqn///vLz89OMGTPUv39/denSRY899pgk6a677rpi799++61KlSqlxx9//KrnmGf06NEaM2aMIiIi1L9/fyUnJ2vGjBnavHmzfvzxx0LfbX/jjTfk4uKiIUOGKC0tTRMmTFD37t21ceNGSdK///1vpaWl6Y8//tC7774rSfL09JQk/fe//9VLL72kxx9/XC+//LIuXLigpKQkbdy4Uc8880yh+gHgxAwAuEN9//33hqurq+Hq6mqEh4cbr7zyivHdd98Z2dnZdnUHDx40XF1djXHjxtmN79y50yhRooTd+L333mtIMj755BPbWFZWlhEQEGB07drVNrZ582ZDkjFr1qx8fUVFRRlBQUG29QMHDhiSDD8/PyM1NdU2Hhsba0gyGjRoYFy8eNE2/vTTTxtWq9W4cOGCYRiGcfbsWcPHx8fo16+f3XFSUlIMb29vu/GoqChDkjF27Fi72rvvvtto3Lixbf3kyZOGJGPUqFH5+r8cX19fo0GDBtdVe+LECcNqtRrt27c3cnJybOPTpk0zJBkff/yxbSwoKMiIiorKt497773XuPfee23ra9asMSQZderUMbKysmzjkydPNiQZO3futI116tTJ7v3P8+ijjxp169a9rnMAcPvjcQsAd6wHHnhAiYmJeuSRR7Rjxw5NmDBBkZGRqly5sr799ltb3cKFC5Wbm6snn3xSf/75p20JCAhQjRo1tGbNGrv9enp6qkePHrZ1q9WqZs2a6bfffruhfp944gl5e3vb1ps3by5J6tGjh0qUKGE3np2drSNHjkiSVq5cqdTUVD399NN2/bu6uqp58+b5+pekF1980W69devWN9R/enq6ypQpc121q1atUnZ2tgYNGiQXl///z1S/fv3k5eWlZcuWFbqPPn36yGq12tbz7uJfz7n5+Pjojz/+0ObNmwt9fAC3Dx63AHBHa9q0qRYuXKjs7Gzt2LFDixYt0rvvvqvHH39c27dvV1hYmH799VcZhqEaNWpcdh/mX/1XqVJFFovFbszX11dJSUk31GvVqlXt1vMCc2Bg4GXHz5w5I0n69ddfJUnt2rW77H69vLzs1t3d3W3PHOfx9fW17a8wvLy8dPbs2euq/f333yVJtWrVshu3Wq0KCQmxbS8M83vo6+srSdd1bsOGDdOqVavUrFkzVa9eXe3bt9czzzyjVq1aFbofAM6LkAwA+iuANW3aVE2bNlXNmjXVp08fLViwQKNGjVJubq4sFotWrFghV1fXfK/Ne2Y1z+VqJMm4wRk3r7Tfax0vNzdX0l/PJQcEBOSr+/td6Kvt70bUrl1b27dvV3Z2tt2d3Btl/o+RPDk5OZc9jxv5s6lTp46Sk5O1dOlSxcXF6euvv9Z7772nkSNHasyYMQVrHIDTIyQDgEmTJk0kSceOHZMkhYaGyjAMVatWTTVr1iySY1wp3N0MoaGhkv6asSMiIqJI9lnQ/h9++GElJibq66+/1tNPP33V2qCgIElScnKyQkJCbOPZ2dk6cOCA3Tn4+vpe9ktIfv/9d7vXFsTVzq106dJ66qmn9NRTTyk7O1uPPfaYxo0bp9jYWLm7uxfqeACcE88kA7hjrVmz5rJ3EJcvXy7p//+6/7HHHpOrq6vGjBmTr94wDJ06darAxy5durQk3ZJvmYuMjJSXl5def/11Xbx4Md/2kydPFnifHh4ekq6//xdffFEVK1bUP//5T/3vf//Lt/3EiRN67bXXJEkRERGyWq2aMmWK3fv90UcfKS0tTZ06dbKNhYaG6qefflJ2drZtbOnSpfmm5iuI0qVLKy0tLd+4+c/ZarUqLCxMhmFc9n0FcHvjTjKAO1Z0dLQyMzPVpUsX1a5dW9nZ2dqwYYPmzZun4OBg9enTR9JfQey1115TbGysDh48qM6dO6tMmTI6cOCAFi1apOeff15Dhgwp0LFDQ0Pl4+OjmTNnqkyZMipdurSaN2+uatWqFfl5enl5acaMGerZs6caNWqkbt26yc/PT4cOHdKyZcvUqlUrTZs2rUD7LFWqlMLCwjRv3jzVrFlTZcuWVb169a44lZ6vr68WLVqkjh07qmHDhnbfuPfzzz/riy++UHh4uCTJz89PsbGxGjNmjDp06KBHHnlEycnJeu+999S0aVO7D0U+99xz+uqrr9ShQwc9+eST2r9/vz777DPb3fPCaNy4sebNm6eYmBg1bdpUnp6eevjhh9W+fXsFBASoVatW8vf31y+//KJp06apU6dO1/2hRAC3EUdNqwEAjrZixQrj2WefNWrXrm14enoaVqvVqF69uhEdHW0cP348X/3XX39t3HPPPUbp0qWN0qVLG7Vr1zYGDBhgJCcn22ruvffey04TZp7WzTAM45tvvjHCwsKMEiVK2E0Hd6Up4N566y271+dNa7ZgwQK78VmzZhmSjM2bN+erj4yMNLy9vQ13d3cjNDTU6N27t7Flyxa7PkuXLp2v/1GjRhnmfzI2bNhgNG7c2LBardc9HdzRo0eNwYMHGzVr1jTc3d0NDw8Po3Hjxsa4ceOMtLQ0u9pp06YZtWvXNkqWLGn4+/sb/fv3N86cOZNvnxMnTjQqV65suLm5Ga1atTK2bNlyxSngzO9V3nv796n4MjIyjGeeecbw8fExJNn+LN5//32jTZs2Rrly5Qw3NzcjNDTUGDp0aL6+ARQPFsO4wU+SAAAAAMUMzyQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATBz6ZSLjx4/XwoULtXfvXpUqVUotW7bUm2++afuWK0m67777tHbtWrvXvfDCC5o5c6Zt/dChQ+rfv7/WrFkjT09PRUVFafz48SpR4v+fXkJCgmJiYrR7924FBgZqxIgR6t27t91+p0+frrfeekspKSlq0KCBpk6dqmbNml3XueTm5uro0aMqU6bMLf26WQAAAFwfwzB09uxZVapUSS4u17hX7MhJmiMjI41Zs2YZu3btMrZv32507NjRqFq1qpGRkWGruffee41+/foZx44dsy1/n7j90qVLRr169YyIiAhj27ZtxvLly43y5csbsbGxtprffvvN8PDwMGJiYow9e/YYU6dONVxdXY24uDhbzZdffmlYrVbj448/Nnbv3m3069fP8PHxuewXClzO4cOHDUksLCwsLCwsLCxOvhw+fPia2c6pvkzk5MmTqlChgtauXas2bdpI+utOcsOGDTVp0qTLvmbFihV66KGHdPToUfn7+0uSZs6cqWHDhunkyZOyWq0aNmyYli1bpl27dtle161bN6WmpiouLk6S1Lx5czVt2tT21ay5ubkKDAxUdHS0hg8ffs3e09LS5OPjo8OHD8vLy+tG3gYAAADcBOnp6QoMDFRqaqq8vb2vWuvQxy3M0tLSJElly5a1G//888/12WefKSAgQA8//LBeffVVeXh4SJISExNVv359W0CWpMjISPXv31+7d+/W3XffrcTEREVERNjtMzIyUoMGDZIkZWdna+vWrYqNjbVtd3FxUUREhBITEy/ba1ZWlrKysmzrZ8+elSR5eXkRkgEAAJzY9Twa6zQhOTc3V4MGDVKrVq1Ur1492/gzzzyjoKAgVapUSUlJSRo2bJiSk5O1cOFCSVJKSopdQJZkW09JSblqTXp6us6fP68zZ84oJyfnsjV79+69bL/jx4/XmDFjbuykAQAA4JScJiQPGDBAu3bt0vr16+3Gn3/+edvP9evXV8WKFXX//fdr//79Cg0NvdVt2sTGxiomJsa2nnf7HgAAALc/pwjJAwcO1NKlS7Vu3TpVqVLlqrXNmzeXJO3bt0+hoaEKCAjQpk2b7GqOHz8uSQoICLD9b97Y32u8vLxUqlQpubq6ytXV9bI1efswc3Nzk5ub2/WfJAAAAG4bDp0n2TAMDRw4UIsWLdLq1atVrVq1a75m+/btkqSKFStKksLDw7Vz506dOHHCVrNy5Up5eXkpLCzMVhMfH2+3n5UrVyo8PFySZLVa1bhxY7ua3NxcxcfH22oAAABw53DoneQBAwZo7ty5+uabb1SmTBnbM8Te3t4qVaqU9u/fr7lz56pjx44qV66ckpKSNHjwYLVp00Z33XWXJKl9+/YKCwtTz549NWHCBKWkpGjEiBEaMGCA7U7viy++qGnTpumVV17Rs88+q9WrV2v+/PlatmyZrZeYmBhFRUWpSZMmatasmSZNmqRz586pT58+t/6NAQAAgEM5dAq4K32ycNasWerdu7cOHz6sHj16aNeuXTp37pwCAwPVpUsXjRgxwm4Gid9//139+/dXQkKCSpcuraioKL3xxhv5vkxk8ODB2rNnj6pUqaJXX30135eJTJs2zfZlIg0bNtSUKVNsj3dcS3p6ury9vZWWlsbsFgAAAE6oIHnNqeZJvp0RkgEAAJxbQfKaQ59JBgAAAJwRIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgEmJa5fgTmUZc/mvDYfjGaP4okwAAG4m7iQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgIlDQ/L48ePVtGlTlSlTRhUqVFDnzp2VnJxsV3PhwgUNGDBA5cqVk6enp7p27arjx4/b1Rw6dEidOnWSh4eHKlSooKFDh+rSpUt2NQkJCWrUqJHc3NxUvXp1zZ49O18/06dPV3BwsNzd3dW8eXNt2rSpyM8ZAAAAzs+hIXnt2rUaMGCAfvrpJ61cuVIXL15U+/btde7cOVvN4MGDtWTJEi1YsEBr167V0aNH9dhjj9m25+TkqFOnTsrOztaGDRs0Z84czZ49WyNHjrTVHDhwQJ06dVLbtm21fft2DRo0SM8995y+++47W828efMUExOjUaNG6eeff1aDBg0UGRmpEydO3Jo3AwAAAE7DYhiG4egm8pw8eVIVKlTQ2rVr1aZNG6WlpcnPz09z587V448/Lknau3ev6tSpo8TERLVo0UIrVqzQQw89pKNHj8rf31+SNHPmTA0bNkwnT56U1WrVsGHDtGzZMu3atct2rG7duik1NVVxcXGSpObNm6tp06aaNm2aJCk3N1eBgYGKjo7W8OHDr9l7enq6vL29lZaWJi8vr6J+axzCMsbi6BZwBcYop7lsAQC4bRQkrznVM8lpaWmSpLJly0qStm7dqosXLyoiIsJWU7t2bVWtWlWJiYmSpMTERNWvX98WkCUpMjJS6enp2r17t63m7/vIq8nbR3Z2trZu3WpX4+LiooiICFsNAAAA7hwlHN1AntzcXA0aNEitWrVSvXr1JEkpKSmyWq3y8fGxq/X391dKSoqt5u8BOW973rar1aSnp+v8+fM6c+aMcnJyLluzd+/ey/ablZWlrKws23p6enoBzxgAAADOymnuJA8YMEC7du3Sl19+6ehWrsv48ePl7e1tWwIDAx3dEgAAAIqIU4TkgQMHaunSpVqzZo2qVKliGw8ICFB2drZSU1Pt6o8fP66AgABbjXm2i7z1a9V4eXmpVKlSKl++vFxdXS9bk7cPs9jYWKWlpdmWw4cPF/zEAQAA4JQcGpINw9DAgQO1aNEirV69WtWqVbPb3rhxY5UsWVLx8fG2seTkZB06dEjh4eGSpPDwcO3cudNuFoqVK1fKy8tLYWFhtpq/7yOvJm8fVqtVjRs3tqvJzc1VfHy8rcbMzc1NXl5edgsAAACKB4c+kzxgwADNnTtX33zzjcqUKWN7htjb21ulSpWSt7e3+vbtq5iYGJUtW1ZeXl6Kjo5WeHi4WrRoIUlq3769wsLC1LNnT02YMEEpKSkaMWKEBgwYIDc3N0nSiy++qGnTpumVV17Rs88+q9WrV2v+/PlatmyZrZeYmBhFRUWpSZMmatasmSZNmqRz586pT58+t/6NAQAAgEM5NCTPmDFDknTffffZjc+aNUu9e/eWJL377rtycXFR165dlZWVpcjISL333nu2WldXVy1dulT9+/dXeHi4SpcuraioKI0dO9ZWU61aNS1btkyDBw/W5MmTVaVKFX344YeKjIy01Tz11FM6efKkRo4cqZSUFDVs2FBxcXH5PswHAACA4s+p5km+nTFPMm4l5kkGAKDgbtt5kgEAAABnQEgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwcGpLXrVunhx9+WJUqVZLFYtHixYvttvfu3VsWi8Vu6dChg13N6dOn1b17d3l5ecnHx0d9+/ZVRkaGXU1SUpJat24td3d3BQYGasKECfl6WbBggWrXri13d3fVr19fy5cvL/LzBQAAwO3BoSH53LlzatCggaZPn37Fmg4dOujYsWO25YsvvrDb3r17d+3evVsrV67U0qVLtW7dOj3//PO27enp6Wrfvr2CgoK0detWvfXWWxo9erQ++OADW82GDRv09NNPq2/fvtq2bZs6d+6szp07a9euXUV/0gAAAHB6FsMwDEc3IUkWi0WLFi1S586dbWO9e/dWampqvjvMeX755ReFhYVp8+bNatKkiSQpLi5OHTt21B9//KFKlSppxowZ+ve//62UlBRZrVZJ0vDhw7V48WLt3btXkvTUU0/p3LlzWrp0qW3fLVq0UMOGDTVz5szr6j89PV3e3t5KS0uTl5dXId4B52MZY3F0C7gCY5RTXLYAANxWCpLXnP6Z5ISEBFWoUEG1atVS//79derUKdu2xMRE+fj42AKyJEVERMjFxUUbN2601bRp08YWkCUpMjJSycnJOnPmjK0mIiLC7riRkZFKTEy8Yl9ZWVlKT0+3WwAAAFA8OHVI7tChgz755BPFx8frzTff1Nq1a/Xggw8qJydHkpSSkqIKFSrYvaZEiRIqW7asUlJSbDX+/v52NXnr16rJ234548ePl7e3t20JDAy8sZMFAACA0yjh6Aauplu3braf69evr7vuukuhoaFKSEjQ/fff78DOpNjYWMXExNjW09PTCcoAAADFhFPfSTYLCQlR+fLltW/fPklSQECATpw4YVdz6dIlnT59WgEBAbaa48eP29XkrV+rJm/75bi5ucnLy8tuAQAAQPFwW4XkP/74Q6dOnVLFihUlSeHh4UpNTdXWrVttNatXr1Zubq6aN29uq1m3bp0uXrxoq1m5cqVq1aolX19fW018fLzdsVauXKnw8PCbfUoAAABwQg4NyRkZGdq+fbu2b98uSTpw4IC2b9+uQ4cOKSMjQ0OHDtVPP/2kgwcPKj4+Xo8++qiqV6+uyMhISVKdOnXUoUMH9evXT5s2bdKPP/6ogQMHqlu3bqpUqZIk6ZlnnpHValXfvn21e/duzZs3T5MnT7Z7VOLll19WXFycJk6cqL1792r06NHasmWLBg4ceMvfEwAAADieQ6eAS0hIUNu2bfONR0VFacaMGercubO2bdum1NRUVapUSe3bt9d//vMfuw/ZnT59WgMHDtSSJUvk4uKirl27asqUKfL09LTVJCUlacCAAdq8ebPKly+v6OhoDRs2zO6YCxYs0IgRI3Tw4EHVqFFDEyZMUMeOHa/7XJgCDrcSU8ABAFBwBclrTjNP8u2OkIxbiZAMAEDBFat5kgEAAIBbjZAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAk0KF5JCQEJ06dSrfeGpqqkJCQm64KQAAAMCRChWSDx48qJycnHzjWVlZOnLkyA03BQAAADhSiYIUf/vtt7afv/vuO3l7e9vWc3JyFB8fr+Dg4CJrDgAAAHCEAoXkzp07S5IsFouioqLstpUsWVLBwcGaOHFikTUHAAAAOEKBQnJubq4kqVq1atq8ebPKly9/U5oCAAAAHKlAITnPgQMHiroPAAAAwGkUKiRLUnx8vOLj43XixAnbHeY8H3/88Q03BgAAADhKoULymDFjNHbsWDVp0kQVK1aUxWIp6r4AAAAAhylUSJ45c6Zmz56tnj17FnU/AAAAgMMVap7k7OxstWzZsqh7AQAAAJxCoULyc889p7lz5xZ1LwAAAIBTKNTjFhcuXNAHH3ygVatW6a677lLJkiXttr/zzjtF0hwAAADgCIUKyUlJSWrYsKEkadeuXXbb+BAfAAAAbneFCslr1qwp6j4AAAAAp1GoZ5IBAACA4qxQd5Lbtm171ccqVq9eXeiGAAAAAEcrVEjOex45z8WLF7V9+3bt2rVLUVFRRdEXAAAA4DCFCsnvvvvuZcdHjx6tjIyMG2oIAAAAcLQifSa5R48e+vjjj4tylwAAAMAtV6QhOTExUe7u7kW5SwAAAOCWK9TjFo899pjdumEYOnbsmLZs2aJXX321SBoDAAAAHKVQIdnb29tu3cXFRbVq1dLYsWPVvn37ImkMAAAAcJRCheRZs2YVdR8AAACA0yhUSM6zdetW/fLLL5KkunXr6u677y6SpgAAAABHKlRIPnHihLp166aEhAT5+PhIklJTU9W2bVt9+eWX8vPzK8oeAQAAgFuqULNbREdH6+zZs9q9e7dOnz6t06dPa9euXUpPT9dLL71U1D0CAAAAt1Sh7iTHxcVp1apVqlOnjm0sLCxM06dP54N7AAAAuO0V6k5ybm6uSpYsmW+8ZMmSys3NveGmAAAAAEcqVEhu166dXn75ZR09etQ2duTIEQ0ePFj3339/kTUHAAAAOEKhQvK0adOUnp6u4OBghYaGKjQ0VNWqVVN6erqmTp1a1D0CAAAAt1ShnkkODAzUzz//rFWrVmnv3r2SpDp16igiIqJImwMAAAAcoUB3klevXq2wsDClp6fLYrHogQceUHR0tKKjo9W0aVPVrVtXP/zww83qFQAAALglChSSJ02apH79+snLyyvfNm9vb73wwgt65513iqw5AAAAwBEKFJJ37NihDh06XHF7+/bttXXr1htuCgAAAHCkAoXk48ePX3bqtzwlSpTQyZMnb7gpAAAAwJEKFJIrV66sXbt2XXF7UlKSKlaseMNNAQAAAI5UoJDcsWNHvfrqq7pw4UK+befPn9eoUaP00EMPFVlzAAAAgCNYDMMwrrf4+PHjatSokVxdXTVw4EDVqlVLkrR3715Nnz5dOTk5+vnnn+Xv73/TGnZW6enp8vb2Vlpa2mU/2Hg7soyxOLoFXIEx6rovWwAA8H8KktcKNE+yv7+/NmzYoP79+ys2NlZ5+dpisSgyMlLTp0+/IwMyAAAAipcCf5lIUFCQli9frjNnzmjfvn0yDEM1atSQr6/vzegPAAAAuOUK9Y17kuTr66umTZsWZS8AAACAUyjQB/cAAACAOwEhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYODQkr1u3Tg8//LAqVaoki8WixYsX2203DEMjR45UxYoVVapUKUVEROjXX3+1qzl9+rS6d+8uLy8v+fj4qG/fvsrIyLCrSUpKUuvWreXu7q7AwEBNmDAhXy8LFixQ7dq15e7urvr162v58uVFfr4AAAC4PTg0JJ87d04NGjTQ9OnTL7t9woQJmjJlimbOnKmNGzeqdOnSioyM1IULF2w13bt31+7du7Vy5UotXbpU69at0/PPP2/bnp6ervbt2ysoKEhbt27VW2+9pdGjR+uDDz6w1WzYsEFPP/20+vbtq23btqlz587q3Lmzdu3adfNOHgAAAE7LYhiG4egmJMlisWjRokXq3LmzpL/uIleqVEn//Oc/NWTIEElSWlqa/P39NXv2bHXr1k2//PKLwsLCtHnzZjVp0kSSFBcXp44dO+qPP/5QpUqVNGPGDP373/9WSkqKrFarJGn48OFavHix9u7dK0l66qmndO7cOS1dutTWT4sWLdSwYUPNnDnzuvpPT0+Xt7e30tLS5OXlVVRvi0NZxlgc3QKuwBjlFJctAAC3lYLkNad9JvnAgQNKSUlRRESEbczb21vNmzdXYmKiJCkxMVE+Pj62gCxJERERcnFx0caNG201bdq0sQVkSYqMjFRycrLOnDljq/n7cfJq8o5zOVlZWUpPT7dbAAAAUDw4bUhOSUmRJPn7+9uN+/v727alpKSoQoUKdttLlCihsmXL2tVcbh9/P8aVavK2X8748ePl7e1tWwIDAwt6igAAAHBSThuSnV1sbKzS0tJsy+HDhx3dEgAAAIqI04bkgIAASdLx48ftxo8fP27bFhAQoBMnTthtv3Tpkk6fPm1Xc7l9/P0YV6rJ2345bm5u8vLyslsAAABQPDhtSK5WrZoCAgIUHx9vG0tPT9fGjRsVHh4uSQoPD1dqaqq2bt1qq1m9erVyc3PVvHlzW826det08eJFW83KlStVq1Yt+fr62mr+fpy8mrzjAAAA4M7i0JCckZGh7du3a/v27ZL++rDe9u3bdejQIVksFg0aNEivvfaavv32W+3cuVO9evVSpUqVbDNg1KlTRx06dFC/fv20adMm/fjjjxo4cKC6deumSpUqSZKeeeYZWa1W9e3bV7t379a8efM0efJkxcTE2Pp4+eWXFRcXp4kTJ2rv3r0aPXq0tmzZooEDB97qtwQAAABOwKFTwCUkJKht27b5xqOiojR79mwZhqFRo0bpgw8+UGpqqu655x699957qlmzpq329OnTGjhwoJYsWSIXFxd17dpVU6ZMkaenp60mKSlJAwYM0ObNm1W+fHlFR0dr2LBhdsdcsGCBRowYoYMHD6pGjRqaMGGCOnbseN3nwhRwuJWYAg4AgIIrSF5zmnmSb3eEZNxKhGQAAAquWMyTDAAAADgKIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCkhKMbAIBixWJxdAe4GsNwdAcAbhPcSQYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmTh2SR48eLYvFYrfUrl3btv3ChQsaMGCAypUrJ09PT3Xt2lXHjx+328ehQ4fUqVMneXh4qEKFCho6dKguXbpkV5OQkKBGjRrJzc1N1atX1+zZs2/F6QEAAMBJOXVIlqS6devq2LFjtmX9+vW2bYMHD9aSJUu0YMECrV27VkePHtVjjz1m256Tk6NOnTopOztbGzZs0Jw5czR79myNHDnSVnPgwAF16tRJbdu21fbt2zVo0CA999xz+u67727peQIAAMB5lHB0A9dSokQJBQQE5BtPS0vTRx99pLlz56pdu3aSpFmzZqlOnTr66aef1KJFC33//ffas2ePVq1aJX9/fzVs2FD/+c9/NGzYMI0ePVpWq1UzZ85UtWrVNHHiRElSnTp1tH79er377ruKjIy8pecKAMCdymJxdAe4EsNwdAeO4fR3kn/99VdVqlRJISEh6t69uw4dOiRJ2rp1qy5evKiIiAhbbe3atVW1alUlJiZKkhITE1W/fn35+/vbaiIjI5Wenq7du3fbav6+j7yavH0AAADgzuPUd5KbN2+u2bNnq1atWjp27JjGjBmj1q1ba9euXUpJSZHVapWPj4/da/z9/ZWSkiJJSklJsQvIedvztl2tJj09XefPn1epUqUu21tWVpaysrJs6+np6Td0rgAAAHAeTh2SH3zwQdvPd911l5o3b66goCDNnz//iuH1Vhk/frzGjBnj0B4AAABwczj94xZ/5+Pjo5o1a2rfvn0KCAhQdna2UlNT7WqOHz9ue4Y5ICAg32wXeevXqvHy8rpqEI+NjVVaWpptOXz48I2eHgAAAJzEbRWSMzIytH//flWsWFGNGzdWyZIlFR8fb9uenJysQ4cOKTw8XJIUHh6unTt36sSJE7aalStXysvLS2FhYbaav+8jryZvH1fi5uYmLy8vuwUAAADFg1OH5CFDhmjt2rU6ePCgNmzYoC5dusjV1VVPP/20vL291bdvX8XExGjNmjXaunWr+vTpo/DwcLVo0UKS1L59e4WFhalnz57asWOHvvvuO40YMUIDBgyQm5ubJOnFF1/Ub7/9pldeeUV79+7Ve++9p/nz52vw4MGOPHUAAAA4kFM/k/zHH3/o6aef1qlTp+Tn56d77rlHP/30k/z8/CRJ7777rlxcXNS1a1dlZWUpMjJS7733nu31rq6uWrp0qfr376/w8HCVLl1aUVFRGjt2rK2mWrVqWrZsmQYPHqzJkyerSpUq+vDDD5n+DQAA4A5mMYw7dfa7opWeni5vb2+lpaUVm0cvLGOYtNJZGaO4bJ0Wk706N/7Jc1pcOs6rOF02BclrTv24BQAAAOAIhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACACSEZAAAAMCEkAwAAACaEZAAAAMCEkAwAAACYEJIBAAAAE0IyAAAAYEJIBgAAAEwIyQAAAIAJIRkAAAAwISQDAAAAJoRkAAAAwISQbDJ9+nQFBwfL3d1dzZs316ZNmxzdEgAAAG4xQvLfzJs3TzExMRo1apR+/vlnNWjQQJGRkTpx4oSjWwMAAMAtREj+m3feeUf9+vVTnz59FBYWppkzZ8rDw0Mff/yxo1sDAADALVTC0Q04i+zsbG3dulWxsbG2MRcXF0VERCgxMTFffVZWlrKysmzraWlpkqT09PSb3+ytcsHRDeBKitX/z4BbiWsHKLDidNnk/ftpGMY1awnJ/+fPP/9UTk6O/P397cb9/f21d+/efPXjx4/XmDFj8o0HBgbetB6BPN5veDu6BeD25M21AxRUcbxszp49K+9rnBghuZBiY2MVExNjW8/NzdXp06dVrlw5WSwWB3YGs/T0dAUGBurw4cPy8vJydDvAbYNrBygcrh3nZRiGzp49q0qVKl2zlpD8f8qXLy9XV1cdP37cbvz48eMKCAjIV+/m5iY3Nze7MR8fn5vZIm6Ql5cXf1kBhcC1AxQO145zutYd5Dx8cO//WK1WNW7cWPHx8bax3NxcxcfHKzw83IGdAQAA4FbjTvLfxMTEKCoqSk2aNFGzZs00adIknTt3Tn369HF0awAAALiFCMl/89RTT+nkyZMaOXKkUlJS1LBhQ8XFxeX7MB9uL25ubho1alS+x2MAXB3XDlA4XDvFg8W4njkwAAAAgDsIzyQDAAAAJoRkAAAAwISQDAAAAJgQkgEAAAATQjIAAABgQkgGAAAATJgnGQAAoBDS09Ovu5avp779cCcZxdoPP/ygHj16KDw8XEeOHJEkffrpp1q/fr2DOwOcG9cOcG0+Pj7y9fW96pJXg9sPd5JRbH399dfq2bOnunfvrm3btikrK0uSlJaWptdff13Lly93cIeAc+LaAa7PmjVrHN0CbiK+cQ/F1t13363BgwerV69eKlOmjHbs2KGQkBBt27ZNDz74oFJSUhzdIuCUuHYAgDvJKMaSk5PVpk2bfOPe3t5KTU299Q0BtwmuHaDwMjMzdejQIWVnZ9uN33XXXQ7qCIVFSEaxFRAQoH379ik4ONhufP369QoJCXFMU8BtgGsHKLiTJ0+qT58+WrFixWW35+Tk3OKOcKP44B6KrX79+unll1/Wxo0bZbFYdPToUX3++ecaMmSI+vfv7+j2AKfFtQMU3KBBg5SamqqNGzeqVKlSiouL05w5c1SjRg19++23jm4PhcCdZBRbw4cPV25uru6//35lZmaqTZs2cnNz05AhQxQdHe3o9gCnxbUDFNzq1av1zTffqEmTJnJxcVFQUJAeeOABeXl5afz48erUqZOjW0QB8cE9FHvZ2dnat2+fMjIyFBYWJk9PT0e3BNwWuHaA6+fl5aWkpCQFBwcrKChIc+fOVatWrXTgwAHVrVtXmZmZjm4RBcTjFii2PvvsM2VmZspqtSosLEzNmjXjH3ngOnDtAAVXq1YtJScnS5IaNGig999/X0eOHNHMmTNVsWJFB3eHwuBOMootPz8/nT9/Xo888oh69OihyMhIubq6OrotwOlx7QAF99lnn+nSpUvq3bu3tm7dqg4dOuj06dOyWq2aPXu2nnrqKUe3iAIiJKPYunTpkuLi4vTFF1/om2++kYeHh5544gl1795dLVu2dHR7gNPi2gFuXGZmpvbu3auqVauqfPnyjm4HhUBIxh0hMzNTixYt0ty5c7Vq1SpVqVJF+/fvd3RbgNPj2gGu7eLFi6pdu7aWLl2qOnXqOLodFBFmt8AdwcPDQ5GRkTpz5ox+//13/fLLL45uCbgtcO0A11ayZElduHDB0W2giPHBPRRrmZmZ+vzzz9WxY0dVrlxZkyZNUpcuXbR7925HtwY4Na4doGAGDBigN998U5cuXXJ0KygiPG6BYqtbt25aunSpPDw89OSTT6p79+4KDw93dFuA0+PaAQquS5cuio+Pl6enp+rXr6/SpUvbbV+4cKGDOkNh8bgFii1XV1fNnz+fT+YDBcS1AxScj4+Punbt6ug2UIS4kwwAAACYcCcZxcqUKVP0/PPPy93dXVOmTLlq7UsvvXSLugKcH9cOcGPatWunhQsXysfHx248PT1dnTt31urVqx3TGAqNO8koVqpVq6YtW7aoXLlyqlat2hXrLBaLfvvtt1vYGeDcuHaAG+Pi4qKUlBRVqFDBbvzEiROqXLmyLl686KDOUFjcSUaxcuDAgcv+DODquHaAwklKSrL9vGfPHqWkpNjWc3JyFBcXp8qVKzuiNdwgpoBDsTV27FhlZmbmGz9//rzGjh3rgI6A2wPXDnD9GjZsqLvvvlsWi0Xt2rVTw4YNbUvjxo312muvaeTIkY5uE4XA4xYotlxdXXXs2LF8v/o6deqUKlSooJycHAd1Bjg3rh3g+v3+++8yDEMhISHatGmT/Pz8bNusVqsqVKjALDG3KR63QLFlGIYsFku+8R07dqhs2bIO6Ai4PXDtANcvKChIkpSbm+vgTlDUCMkodnx9fWWxWGSxWFSzZk27f+xzcnKUkZGhF1980YEdAs6JawcovE8++eSq23v16nWLOkFR4XELFDtz5syRYRh69tlnNWnSJHl7e9u2Wa1WBQcH8+1hwGVw7QCF5+vra7d+8eJFZWZmymq1ysPDQ6dPn3ZQZygsQjKKrbVr16ply5YqWbKko1sBbitcO0DR+PXXX9W/f38NHTpUkZGRjm4HBURIRrGSnp4uLy8v289Xk1cH4MouXLig7OxsuzGuHeD6bdmyRT169NDevXsd3QoKiGeSUaz4+vraPpXv4+Nz2Q8f5X0oiU/oA5eXmZmpV155RfPnz9epU6fybefaAa5fiRIldPToUUe3gUIgJKNYWb16te3T92vWrHFwN8DtaejQoVqzZo1mzJihnj17avr06Tpy5Ijef/99vfHGG45uD3BK3377rd26YRg6duyYpk2bplatWjmoK9wIHrcAANipWrWqPvnkE913333y8vLSzz//rOrVq+vTTz/VF198oeXLlzu6RcDpuLjYfz+bxWKRn5+f2rVrp4kTJ6pixYoO6gyFxTfuodiKi4vT+vXrbevTp09Xw4YN9cwzz+jMmTMO7AxwbqdPn1ZISIikv54/zvtU/j333KN169Y5sjXAaeXm5totOTk5SklJ0dy5cwnItylCMoqtoUOH2j68t3PnTsXExKhjx446cOCAYmJiHNwd4LxCQkJ04MABSVLt2rU1f/58SdKSJUvk4+PjwM4A55edna3k5GRdunTJ0a3gBhGSUWwdOHBAYWFhkqSvv/5aDz/8sF5//XVNnz5dK1ascHB3gPPq06ePduzYIUkaPny4pk+fLnd3dw0ePFhDhw51cHeAc8rMzNSzzz4rDw8P1a1bV4cOHZIkRUdH8yz/bYqQjGLLarUqMzNTkrRq1Sq1b99eklS2bNlrTg8H3MkGDx6sl156SZIUERGhvXv3au7cudq2bZtefvllB3cHOKfY2FglJSUpISFB7u7utvGIiAjNmzfPgZ2hsJjdAsXWPffco5iYGLVq1UqbNm2y/SX1v//9T1WqVHFwd8DtIygoSEFBQY5uA3Bqixcv1rx589SiRQu76Ufr1q2r/fv3O7AzFBYhGcXWtGnT9I9//ENfffWVZsyYocqVK0uSVqxYoQ4dOji4O8B5TZky5bLjFotF7u7uql69utq0aSNXV9db3BngvE6ePKkKFSrkGz937txl5+yH82MKOACAnWrVqunkyZPKzMyUr6+vJOnMmTPy8PCQp6enTpw4oZCQEK1Zs0aBgYEO7hZwDm3atNETTzyh6OholSlTRklJSapWrZqio6P166+/Ki4uztEtooC4k4xiLScnR4sXL9Yvv/wi6a9fez3yyCPcAQOu4vXXX9cHH3ygDz/8UKGhoZKkffv26YUXXtDzzz+vVq1aqVu3bho8eLC++uorB3cLOIfXX39dDz74oPbs2aNLly5p8uTJ2rNnjzZs2KC1a9c6uj0UAneSUWzt27dPHTt21JEjR1SrVi1JUnJysgIDA7Vs2TLbP/4A7IWGhurrr79Ww4YN7ca3bdumrl276rffftOGDRvUtWtXHTt2zDFNAk5o//79euONN7Rjxw5lZGSoUaNGGjZsmOrXr+/o1lAIhGQUWx07dpRhGPr8889tX1V96tQp9ejRQy4uLlq2bJmDOwSck4eHh9atW6cmTZrYjW/evFn33nuvMjMzdfDgQdWrV08ZGRkO6hIAbi6mgEOxtXbtWk2YMMEWkCWpXLlyeuONN/jVF3AVbdu21QsvvKBt27bZxrZt26b+/furXbt2kv76gp5q1ao5qkXAabi4uMjV1fWqS4kSPN16O+JPDcWWm5ubzp49m288IyNDVqvVAR0Bt4ePPvpIPXv2VOPGjVWyZElJ0qVLl3T//ffro48+kiR5enpq4sSJjmwTcAqLFi264rbExERNmTJFubm5t7AjFBUet0Cx1atXL/3888/66KOP1KxZM0nSxo0b1a9fPzVu3FizZ892bIOAk9u7d6/+97//SZJq1aple7YfwNUlJydr+PDhWrJkibp3766xY8cy1/htiDvJKLamTJmi3r17q2XLlrZfdV26dEmPPPKIJk+e7ODuAOcXEhIii8Wi0NBQfl0MXIejR49q1KhRmjNnjiIjI7V9+3bVq1fP0W2hkPhbD8VObm6u3nrrLX377bfKzs5W586dFRUVJYvFojp16qh69eqObhFwapmZmYqOjtacOXMk/fUtlSEhIYqOjlblypU1fPhwB3cIOJe0tDS9/vrrmjp1qho2bKj4+Hi1bt3a0W3hBvHBPRQ748aN07/+9S95enqqcuXKWr58uRYvXqyHH36YgAxch9jYWO3YsUMJCQlyd3e3jUdERNi+3h3AXyZMmKCQkBAtXbpUX3zxhTZs2EBALiZ4JhnFTo0aNTRkyBC98MILkqRVq1apU6dOOn/+vFxc+O9C4FqCgoI0b948tWjRQmXKlNGOHTsUEhKiffv2qVGjRkpPT3d0i4DTcHFxUalSpRQREXHVL6pauHDhLewKRYHHLVDsHDp0SB07drStR0REyGKx6OjRo6pSpYoDOwNuDydPnlSFChXyjZ87d04Wi8UBHQHOq1evXlwXxRQhGcXOpUuX7H5FLEklS5bUxYsXHdQRcHtp0qSJli1bpujoaEmyBYAPP/xQ4eHhjmwNcDrMlFR8EZJR7BiGod69e8vNzc02duHCBb344osqXbq0bYxffQGX9/rrr+vBBx/Unj17dOnSJU2ePFl79uzRhg0b+CIeAHcMnklGsdOnT5/rqps1a9ZN7gS4fe3fv19vvPGGduzYoYyMDDVq1EjDhg1T/fr1Hd0aANwShGQAAADAhMctAACS/vqU/rU+gGSxWHTp0qVb1BEAOA4hGQAgSVq0aNEVtyUmJmrKlCnKzc29hR0BgOPwuAUA4IqSk5M1fPhwLVmyRN27d9fYsWMVFBTk6LYA4KbjmxUAAPkcPXpU/fr1U/369XXp0iVt375dc+bMISADuGMQkgEANmlpaRo2bJiqV6+u3bt3Kz4+XkuWLFG9evUc3RoA3FI8kwwAkCRNmDBBb775pgICAvTFF1/o0UcfdXRLAOAwPJMMAJD01+wWpUqVUkREhFxdXa9YxxfxALgTcCcZACBJ6tWr1zWngAOAOwV3kgEAAAATPrgHAAAAmBCSAQAAABNCMgAAAGBCSAYA2CQkJMhisSg1NdXRrQCAQxGSAcAJnTx5Uv3791fVqlXl5uamgIAARUZG6scffyyyY9x3330aNGiQ3VjLli117NgxeXt7F9lxCqt3797q3Lmzo9sAcIdiCjgAcEJdu3ZVdna25syZo5CQEB0/flzx8fE6derUTT2u1WpVQEDATT0GANwOuJMMAE4mNTVVP/zwg9588021bdtWQUFBatasmWJjY/XII4/Yap577jn5+fnJy8tL7dq1044dO2z7GD16tBo2bKhPP/1UwcHB8vb2Vrdu3XT27FlJf92lXbt2rSZPniyLxSKLxaKDBw/me9xi9uzZ8vHx0dKlS1WrVi15eHjo8ccfV2ZmpubMmaPg4GD5+vrqpZdeUk5Oju34WVlZGjJkiCpXrqzSpUurefPmSkhIsG3P2+93332nOnXqyNPTUx06dNCxY8ds/c+ZM0fffPONrb+/vx4AbjZCMgA4GU9PT3l6emrx4sXKysq6bM0TTzyhEydOaMWKFdq6dasaNWqk+++/X6dPn7bV7N+/X4sXL9bSpUu1dOlSrV27Vm+88YYkafLkyQoPD1e/fv107NgxHTt2TIGBgZc9VmZmpqZMmaIvv/xScXFxSkhIUJcuXbR8+XItX75cn376qd5//3199dVXttcMHDhQiYmJ+vLLL5WUlKQnnnhCHTp00K+//mq337fffluffvqp1q1bp0OHDmnIkCGSpCFDhujJJ5+0Bedjx46pZcuWN/zeAsD1IiQDgJMpUaKEZs+erTlz5sjHx0etWrXSv/71LyUlJUmS1q9fr02bNmnBggVq0qSJatSoobfffls+Pj52QTU3N1ezZ89WvXr11Lp1a/Xs2VPx8fGSJG9vb1mtVnl4eCggIEABAQFX/CrqixcvasaMGbr77rvVpk0bPf7441q/fr0++ugjhYWF6aGHHlLbtm21Zs0aSdKhQ4c0a9YsLViwQK1bt1ZoaKiGDBmie+65R7NmzbLb78yZM9WkSRM1atRIAwcOtPXn6empUqVK2Z7HDggIkNVqvSnvNwBcDs8kA4AT6tq1qzp16qQffvhBP/30k1asWKEJEyboww8/1Llz55SRkaFy5crZveb8+fPav3+/bT04OFhlypSxrVesWFEnTpwocC8eHh4KDQ21rfv7+ys4OFienp52Y3n73rlzp3JyclSzZk27/WRlZdn1bN5vYfsDgJuBkAwATsrd3V0PPPCAHnjgAb366qt67rnnNGrUKP3jH/9QxYoVL/uMro+Pj+3nkiVL2m2zWCzKzc0tcB+X28/V9p2RkSFXV1dt3bo1393pvwfry+3DMIwC9wcANwMhGQBuE2FhYVq8eLEaNWqklJQUlShRQsHBwYXen9VqtfuwXVG5++67lZOToxMnTqh169aF3s/N6g8ArgfPJAOAkzl16pTatWunzz77TElJSTpw4IAWLFigCRMm6NFHH1VERITCw8PVuXNnff/99zp48KA2bNigf//739qyZct1Hyc4OFgbN27UwYMH9eeffxbqLvPl1KxZU927d1evXr20cOFCHThwQJs2bdL48eO1bNmyAvWXlJSk5ORk/fnnn7p48WKR9AcA14OQDABOxtPTU82bN9e7776rNm3aqF69enr11VfVr18/TZs2TRaLRcuXL1ebNm3Up08f1axZU926ddPvv/8uf3//6z7OkCFD5OrqqrCwMPn5+enQoUNFdg6zZs1Sr1699M9//lO1atVS586dtXnzZlWtWvW699GvXz/VqlVLTZo0kZ+fX5F+kQoAXIvF4AEwAAAAwA53kgEAAAATQjIAAABgQkgGAAAATAjJAAAAgAkhGQAAADAhJAMAAAAmhGQAAADAhJAMAAAAmBCSAQAAABNCMgAAAGBCSAYAAABMCMkAAACAyf8DzDLJOhe64RIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nCorrect! After checking the head of the target and the frequency of values we can see that there are many missing reviews.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "Revisiting Google app reviews\n",
    "\n",
    "We're now going to leverage gradient boosting to perform sentiment analysis!\n",
    "\n",
    "Remember the app ratings dataset from the first chapter? We'll now work with a related dataset for user reviews. This dataset contains the first 100 most relevant reviews for each app. Our goal is to build a model based on these reviews that predicts the Sentiment as being 'Positive', 'Neutral', or 'Negative'.\n",
    "\n",
    "The dataset is available to you as reviews, and the target here is the 'Sentiment' column. Explore the data in the IPython Shell, and then select the correct statement from the options below.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "Possible answers:\n",
    "\n",
    "    Most of the reviews are 'Negative'.\n",
    "\n",
    "    There are some reviews with NaN values. {Answer}\n",
    "\n",
    "    The target is balanced.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "reviews = pd.read_csv(path_data+'googleplaystore_user_reviews.csv')\n",
    "print(reviews.info(), reviews.describe(include='all'))\n",
    "\n",
    "# Count the occurrences of each sentiment\n",
    "sentiment_counts = reviews['Sentiment'].value_counts()\n",
    "\n",
    "# Plot the count using matplotlib\n",
    "plt.figure(figsize=(8, 5))\n",
    "sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n",
    "plt.title('Sentiment Counts')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Correct! After checking the head of the target and the frequency of values we can see that there are many missing reviews.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "Sentiment analysis with GBM\n",
    "\n",
    "Let's now use scikit-learn's GradientBoostingClassifier on the reviews dataset to predict the sentiment of a review given its text.\n",
    "\n",
    "We will not pass the raw text as input for the model. The following pre-processing has been done for you:\n",
    "\n",
    "    Remove reviews with missing values.\n",
    "    Select data from the top 5 apps.\n",
    "    Select a random subsample of 500 reviews.\n",
    "    Remove \"stop words\" from the reviews.\n",
    "    Transform the reviews into a matrix, in which each feature represents the frequency of a word in a review.\n",
    "\n",
    "Do you want a deeper understanding of text mining? Then go check the course Introduction to Natural Language Processing in Python!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build a GradientBoostingClassifier with 100 estimators and a learning rate of 0.1.\n",
    "   \n",
    "    Calculate the predictions on the test set.\n",
    "   \n",
    "    Compute the accuracy to evaluate the model.\n",
    "   \n",
    "    Calculate and print the confusion matrix.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build and fit a Gradient Boosting classifier\n",
    "clf_gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=500)\n",
    "clf_gbm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_gbm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance based on the accuracy\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy: {:.3f}'.format(acc))\n",
    "\n",
    "# Get and show the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print(cm)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Positive review for you! The gradient boosting classifier was able to predict the sentiment of the reviews with an accuracy of 92%!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "Movie revenue prediction with CatBoost\n",
    "\n",
    "Let's finish up this chapter on boosting by returning to the movies dataset! In this exercise, you'll build a CatBoostRegressor to predict the log-revenue. Remember that our best model so far is the AdaBoost model with a RMSE of 5.15.\n",
    "\n",
    "Will CatBoost beat AdaBoost? We'll try to use a similar set of parameters to have a fair comparison.\n",
    "\n",
    "Recall that these are the features we have used so far: 'budget', 'popularity', 'runtime', 'vote_average', and 'vote_count'. catboost has been imported for you as cb.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build and fit a CatBoostRegressor using 100 estimators, a learning rate of 0.1, and a max depth of 3.\n",
    "    Calculate the predictions for the test set and print the RMSE.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "import catboost as cb\n",
    "\n",
    "# Build and fit a CatBoost regressor\n",
    "reg_cat = cb.CatBoostRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=500)\n",
    "reg_cat.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_cat.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse_cat = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE (CatBoost): {:.3f}'.format(rmse_cat))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Excellent! The CatBoost regressor was able to predict movie revenue with a RMSE of around 5.12, an improvement over the previous 5.15. CatBoost trained faster as well!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 11\n",
    "\n",
    "\"\"\"\n",
    "Boosting contest: Light vs Extreme\n",
    "\n",
    "While the performance of the CatBoost model is relatively good, let's try two other flavors of boosting and see which performs better: the \"Light\" or the \"Extreme\" approach.\n",
    "\n",
    "CatBoost is highly recommended when there are categorical features. In this case, all features are numeric, therefore one of the other approaches might produce better results.\n",
    "\n",
    "As we are building regressors, we'll use an additional parameter, objective, which specifies the learning function to be used. To apply a squared error, we'll set objective to 'reg:squarederror' for XGBoost and 'mean_squared_error' for LightGBM.\n",
    "\n",
    "In addition, we'll specify the parameter n_jobs for XGBoost to improve its computation runtime.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Build an XGBRegressor using the parameters: max_depth = 3, learning_rate = 0.1, n_estimators = 100, and n_jobs=2.\n",
    "    Build an LGBMRegressor using the parameters: max_depth = 3, learning_rate = 0.1, and n_estimators = 100.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Build and fit an XGBoost regressor\n",
    "reg_xgb = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, n_jobs=2, objective='reg:squarederror', random_state=500)\n",
    "reg_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Build and fit a LightGBM regressor\n",
    "reg_lgb = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, objective='mean_squared_error', seed=500)\n",
    "reg_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions and evaluate both regressors\n",
    "pred_xgb = reg_xgb.predict(X_test)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
    "pred_lgb = reg_lgb.predict(X_test)\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_test, pred_lgb))\n",
    "\n",
    "print('Extreme: {:.3f}, Light: {:.3f}'.format(rmse_xgb, rmse_lgb))\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Pretty tight! While XGBoost got a better score, LightGBM is faster and lighter. CatBoost was a good contestant as well!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
