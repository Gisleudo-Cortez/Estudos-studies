{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:58:56.803807Z",
     "iopub.status.busy": "2023-06-01T18:58:56.802774Z",
     "iopub.status.idle": "2023-06-01T18:58:56.807982Z",
     "shell.execute_reply": "2023-06-01T18:58:56.807102Z",
     "shell.execute_reply.started": "2023-06-01T18:58:56.803750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:58:58.412472Z",
     "iopub.status.busy": "2023-06-01T18:58:58.412095Z",
     "iopub.status.idle": "2023-06-01T18:59:01.395629Z",
     "shell.execute_reply": "2023-06-01T18:59:01.394938Z",
     "shell.execute_reply.started": "2023-06-01T18:58:58.412448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment  Target\n",
       "0  When I first tuned in on this morning news, I ...       neg      -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who would have thought that a movie about a ma...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment  Target\n",
       "0  Who would have thought that a movie about a ma...       pos       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = '/home/nero/Documents/Estudos/DataCamp/Python/Linear_Classifiers_in_Python/datasets/train.xlsx'\n",
    "\n",
    "data_train = pd.read_excel(data_path)\n",
    "data_train['Target'] = np.where(data_train['Sentiment'] == 'pos', 1, -1)\n",
    "\n",
    "data_path = '/home/nero/Documents/Estudos/DataCamp/Python/Linear_Classifiers_in_Python/datasets/test.xlsx'\n",
    "data_test = pd.read_excel(data_path)\n",
    "data_test['Target'] = np.where(data_test['Sentiment'] == 'pos', 1, -1)\n",
    "\n",
    "display(data_train.head(1), data_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:59:23.074566Z",
     "iopub.status.busy": "2023-06-01T18:59:23.073699Z",
     "iopub.status.idle": "2023-06-01T18:59:23.081609Z",
     "shell.execute_reply": "2023-06-01T18:59:23.080322Z",
     "shell.execute_reply.started": "2023-06-01T18:59:23.074520Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = data_train['Reviews'][:200]\n",
    "y_train = data_train['Target'][:200]\n",
    "\n",
    "X_test = data_test['Reviews'][:200]\n",
    "y_test = data_test['Target'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:59:25.942080Z",
     "iopub.status.busy": "2023-06-01T18:59:25.941246Z",
     "iopub.status.idle": "2023-06-01T18:59:25.947309Z",
     "shell.execute_reply": "2023-06-01T18:59:25.946092Z",
     "shell.execute_reply.started": "2023-06-01T18:59:25.942024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = [str(x) for x in X_train]\n",
    "X_test = [str(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:59:28.009484Z",
     "iopub.status.busy": "2023-06-01T18:59:28.007850Z",
     "iopub.status.idle": "2023-06-01T18:59:28.016803Z",
     "shell.execute_reply": "2023-06-01T18:59:28.015855Z",
     "shell.execute_reply.started": "2023-06-01T18:59:28.009442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:57:05.605031Z",
     "iopub.status.busy": "2023-06-01T18:57:05.604725Z",
     "iopub.status.idle": "2023-06-01T18:57:13.350599Z",
     "shell.execute_reply": "2023-06-01T18:57:13.350064Z",
     "shell.execute_reply.started": "2023-06-01T18:57:05.605004Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "text_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "\n",
    "text_tfidf_2 = tfidf_vec.fit_transform(X_test)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:57:20.887448Z",
     "iopub.status.busy": "2023-06-01T18:57:20.887059Z",
     "iopub.status.idle": "2023-06-01T18:57:20.892391Z",
     "shell.execute_reply": "2023-06-01T18:57:20.891625Z",
     "shell.execute_reply.started": "2023-06-01T18:57:20.887414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = text_tfidf\n",
    "X_test = text_tfidf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T18:57:24.173310Z",
     "iopub.status.busy": "2023-06-01T18:57:24.172133Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "KNN classification\n",
    "\n",
    "In this exercise you'll explore a subset of the Large Movie Review Dataset. The variables X_train, X_test, y_train, and y_test are already loaded into the environment. The X variables contain features based on the words in the movie reviews, and the y variables contain labels for whether the review sentiment is positive (+1) or negative (-1).\n",
    "\n",
    "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the scikit-learn Cheat Sheet and keep it handy!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create a KNN model with default hyperparameters.\n",
    "    Fit the model.\n",
    "    Print out the prediction for the test example 0.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create and fit the model\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test features, print the results\n",
    "pred = knn.predict(X_test)[0]\n",
    "print(\"Prediction for test example 0:\", pred)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice work! Looks like you remember how to use scikit-learn for supervised learning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Comparing models\n",
    "\n",
    "Compare k nearest neighbors classifiers with k=1 and k=5 on the handwritten digits data set, which is already loaded into the variables X_train, y_train, X_test, and y_test. You can set k with the n_neighbors parameter when creating the KNeighborsClassifier object, which is also already imported into the environment.\n",
    "\n",
    "Which model has a higher test accuracy?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "K = 5\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "Out[1]:\n",
    "KNeighborsClassifier(n_neighbors=1)\n",
    "In [2]:\n",
    "knn.score(X_test, y_test)\n",
    "Out[2]:\n",
    "0.9888888888888889\n",
    "In [3]:\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "Out[3]:\n",
    "KNeighborsClassifier()\n",
    "In [4]:\n",
    "knn.score(X_test, y_test)\n",
    "Out[4]:\n",
    "0.9933333333333333\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great! You've just done a bit of model selection!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T17:44:31.493659Z",
     "iopub.status.busy": "2023-06-01T17:44:31.493133Z",
     "iopub.status.idle": "2023-06-01T17:44:31.500153Z",
     "shell.execute_reply": "2023-06-01T17:44:31.499024Z",
     "shell.execute_reply.started": "2023-06-01T17:44:31.493591Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T17:45:27.887742Z",
     "iopub.status.busy": "2023-06-01T17:45:27.887301Z",
     "iopub.status.idle": "2023-06-01T17:45:33.050238Z",
     "shell.execute_reply": "2023-06-01T17:45:33.049677Z",
     "shell.execute_reply.started": "2023-06-01T17:45:27.887714Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9688888888888889\n",
      "0.9970304380103935\n",
      "0.9933333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nNicely done! Later in the course we'll look at the similarities and differences of logistic regression vs. SVMs.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Running LogisticRegression and SVC\n",
    "\n",
    "In this exercise, you'll apply logistic regression and a support vector machine to classify images of handwritten digits.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Apply logistic regression and SVM (using SVC()) to the handwritten digits data set using the provided train/validation split.\n",
    "    For each classifier, print out the training and validation accuracy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
    "\n",
    "# Apply logistic regression and print scores\n",
    "lr = LogisticRegression(max_iter = 10000)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "# Apply SVM and print scores\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print(svm.score(X_train, y_train))\n",
    "print(svm.score(X_test, y_test))\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nicely done! Later in the course we'll look at the similarities and differences of logistic regression vs. SVMs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Sentiment analysis for movie reviews\n",
    "\n",
    "In this exercise you'll explore the probabilities outputted by logistic regression on a subset of the Large Movie Review Dataset.\n",
    "\n",
    "The variables X and y are already loaded into the environment. X contains features based on the number of times words appear in the movie reviews, and y contains labels for whether the review sentiment is positive (+1) or negative (-1).\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Train a logistic regression model on the movie review data.\n",
    "    Predict the probabilities of negative vs. positive for the two given reviews.\n",
    "    Feel free to write your own reviews and get probabilities for those too!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Instantiate logistic regression and train\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict sentiment for a glowing review\n",
    "review1 = \"LOVED IT! This movie was amazing. Top 10 this year.\"\n",
    "review1_features = get_features(review1)\n",
    "print(\"Review:\", review1)\n",
    "print(\"Probability of positive review:\", lr.predict_proba(review1_features)[0,1])\n",
    "\n",
    "# Predict sentiment for a poor review\n",
    "review2 = \"Total junk! I'll never watch a film by that director again, no matter how good the reviews.\"\n",
    "review2_features = get_features(review2)\n",
    "print(\"Review:\", review2)\n",
    "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic! The second probability would have been even lower, but the word \"good\" trips it up a bit, since that's considered a \"positive\" word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Visualizing decision boundaries\n",
    "\n",
    "In this exercise, you'll visualize the decision boundaries of various classifier types.\n",
    "\n",
    "A subset of scikit-learn's built-in wine dataset is already loaded into X, along with binary labels in y.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Create the following classifier objects with default hyperparameters: LogisticRegression, LinearSVC, SVC, KNeighborsClassifier.\n",
    "    Fit each of the classifiers on the provided data using a for loop.\n",
    "    Call the plot_4_classifers() function (similar to the code here), passing in X, y, and a list containing the four classifiers.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the classifiers\n",
    "classifiers = [LogisticRegression(), LinearSVC(), SVC(), KNeighborsClassifier()]\n",
    "\n",
    "# Fit the classifiers\n",
    "for c in classifiers:\n",
    "    c.fit(X, y)\n",
    "\n",
    "# Plot the classifiers\n",
    "plot_4_classifiers(X, y, classifiers)\n",
    "plt.show()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Nice! As you can see, logistic regression and linear SVM are linear classifiers whereas KNN is not. The default SVM is also non-linear, but this is hard to see in the plot because it performs poorly with default hyperparameters. With better hyperparameters, it performs well.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 08\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 09\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 10\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 11\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
