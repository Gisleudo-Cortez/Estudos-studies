{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this to shorten the data import from the files\n",
    "import os\n",
    "cwd = os.path.dirname(os.getcwd())+'/'\n",
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'datasets/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a data pipeline?\n",
    "\n",
    "Which statement below most closely defines a data pipeline?\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    A tool that backs up data in a database by taking a snapshot of the data each morning\n",
    "    \n",
    "    \n",
    "    A manual effort that involves copying data from one file to another when a client requests certain information\n",
    "    \n",
    "    \n",
    "    An automated process that extracts data from a source system, transforms it into a desired model, and loads the data into a file, database, or other data storage tool {Answer}\n",
    "\n",
    "**Nicely done! Data pipelines are automated processes that enhance or manipulate data from source systems, ensuring that it is ready to be used in downstream workflows. This manipulation of data is the main differentiator between database backups and data pipelines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of a data pipeline\n",
    "\n",
    "Data pipelines are typically composed of three different operations - extracting data, transforming it, and loading the transformed data into a data storage tool. Identifying these components are crucial when designing and building your own pipelines.\n",
    "\n",
    "![Answer](images/ch01-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producers and consumers of data pipelines\n",
    "\n",
    "Data pipelines are everywhere! In this course, you'll learn how to design and build great data pipelines. It's always good to keep in mind who, and what, will be using the data pipelines that you build. This can help you tailor your solution appropriately through the design and development of a data pipeline.\n",
    "\n",
    "![Answer](images/ch01-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture diagrams for data pipelines\n",
    "\n",
    "Select all the benefits of using an architecture diagram when designing a data pipeline.\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "    Architecture diagrams help Data Engineers communicate technical details to stakeholders{Answer}\n",
    "\n",
    "\n",
    "    Building an architecture diagram helps to identify null records in source data\n",
    "\n",
    "\n",
    "    Architecture diagrams help data teams understand different storage media within a data pipeline{Answer}\n",
    "\n",
    "\n",
    "    Creating an architecture diagram helps to identify technological or security vulnerabilities within a data pipeline{Answer}\n",
    "\n",
    "\n",
    "    Building an architecture diagrams allows for an engineer to determine possible overlap with past solutions{Answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading architecture diagrams\n",
    "\n",
    "Based on the architecture diagram shown below, determine the type of data pipeline that is being designed.\n",
    "\n",
    "![An architecture diagram of a data pipeline.](images/DC%201.2%20-%20Architecture%20Diagram%20for%20Exercise.png)\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    An ELT (extract, load, transform) pipeline\n",
    "    \n",
    "    \n",
    "    A TEL (transform, extract, load) pipeline\n",
    "    \n",
    "    \n",
    "    An ETL (extract, transform, load) pipeline {Answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline design process\n",
    "\n",
    "Creating and socializing an architecture diagram is not only a great way to communicate data pipeline design decisions with non-technical stakeholders, but it allows for data engineers to develop a better understanding of the pipeline end-to-end.\n",
    "\n",
    "![Answer](images/ch01-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building quality data pipelines\n",
    "\n",
    "Select the option below that is not a characteristic of a strong data pipeline.\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "\n",
    "    Independence: data pipelines should produce similar data, independent of the date that it is invoked. {Answer}\n",
    "    \n",
    "    \n",
    "    Resiliency: it's important to design data pipelines such that they retry on common errors, and handle failures gracefully.\n",
    "    \n",
    "    \n",
    "    Scalability: the best data pipelines can handle large amounts of data and a high frequency of invocation.\n",
    "    \n",
    "    \n",
    "    Transparency: data pipelines should be built to avoid black-box operations on data, and should be thoroughly tested and validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting data throughout a pipeline\n",
    "\n",
    "Data persistence is an important component in every data pipeline. Choose the options below that are benefits of persisting data throughout a data pipeline.\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "    Persisting data throughout a data pipeline makes it easy to rerun a pipeline from the last point of failure{Answer}\n",
    "\n",
    "\n",
    "    It's easier to document the flow of data through a pipeline when it is persisted between components{Answer}\n",
    "\n",
    "\n",
    "    Storing data after acquisition from a source system ensures it is available for later use, even if the data is not easy to reacquire from the source system{Answer}\n",
    "\n",
    "\n",
    "    Data persistence prevents incomplete or \"bad\" data from making it through transformations and into a data lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualities of sound data pipelines\n",
    "\n",
    "Building a great data pipeline is tricky! The format, type, and availability of data can change, making it difficult for a data engineer to build and implement a solution. However, the best data pipelines all have similar qualities. In this exercise, you'll test your knowledge of these characteristics.\n",
    "\n",
    "![Answer](images/ch01-04.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
