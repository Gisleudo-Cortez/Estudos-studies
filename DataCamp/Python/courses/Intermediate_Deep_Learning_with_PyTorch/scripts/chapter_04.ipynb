{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0 - Name: NVIDIA GeForce MX110, Memory Capacity: 2002.9375 MB\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# run this to shorten the data import from the files\n",
    "path_data = '/home/nero/Documents/Estudos/DataCamp/Python/courses/Intermediate_Deep_Learning_with_PyTorch/datasets/'\n",
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    # Get the name and properties of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i} - Name: {gpu_properties.name}, \"\n",
    "              f\"Memory Capacity: {gpu_properties.total_memory / (1024 ** 2)} MB\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n",
    "\n",
    "# Set the default device to GPU (\"cuda\") if available, otherwise use CPU (\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWell done! You've built a DataLoader that can serve multiple inputs to a model. The next task is to craft a model architecture capable of processing all of these inputs!\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 01\n",
    "\n",
    "\"\"\"\n",
    "Two-input dataset\n",
    "\n",
    "Building a multi-input model starts with crafting a custom dataset that can supply all the inputs to the model. In this exercise, you will build the Omniglot dataset that serves triplets consisting of:\n",
    "\n",
    "    The image of a character to be classified,\n",
    "    The one-hot encoded alphabet vector of length 30, with zeros everywhere but for a single one denoting the ID of the alphabet the character comes from,\n",
    "    The target label, an integer between 0 and 963.\n",
    "\n",
    "You are provided with train_samples, a list of 3-tuples comprising an image's file path, its alphabet vector, and the target label. Also, the following imports have already been done for you, so let's get to it!\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Assign transform and samples to class attributes with the same names.\n",
    "---\n",
    "\n",
    "    Implement the .__len()__ method such that it return the number of samples stored in the class' samples attribute.\n",
    "---\n",
    "\n",
    "    Unpack the sample at index idx assigning its contents to img_path, alphabet, and label.\n",
    "    Transform the loaded image with self.transform() and assign it to img_transformed.\n",
    "---\n",
    "Question\n",
    "\n",
    "Nice done! With your implementation of OmniglotDataset ready, you can actually create the dataset and DataLoader, just like you did it before.\n",
    "\n",
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((64, 64)),\n",
    "    ]),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, shuffle=True, batch_size=3,\n",
    ")\n",
    "\n",
    "What will dataloader_train produce? To answer, feel free to execute the code above and peek at the first batch of data returned by the DataLoader!\n",
    "(Images, Alphabet Vectors, labels)\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, transform, samples):\n",
    "\t\t# Assign transform and samples to class attributes\n",
    "        self.transform = transform\n",
    "        self.samples = samples\n",
    "                    \n",
    "    def __len__(self):\n",
    "\t\t# Return number of samples\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      \t# Unpack the sample at index idx\n",
    "        img_path, alphabet, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        # Transform the image \n",
    "        img_transformed = self.transform(img)\n",
    "        return img_transformed, alphabet, label\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! You've built a DataLoader that can serve multiple inputs to a model. The next task is to craft a model architecture capable of processing all of these inputs!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39m    Define image, alphabet and classifier sub-networks as sequential models, assigning them to self.image_layer, self.alphabet_layer and self.classifier, respectively.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# solution\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mNet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m     32\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[39msuper\u001b[39m(Net, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# exercise 02\n",
    "\n",
    "\"\"\"\n",
    "Two-input model\n",
    "\n",
    "With the data ready, it's time to build the two-input model architecture! To do so, you will set up a model class with the following methods:\n",
    "\n",
    "    .__init__(), in which you will define sub-networks by grouping layers; this is where you define the two layers for processing the two inputs, and the classifier that returns a classification score for each class.\n",
    "\n",
    "    forward(), in which you will pass both inputs through corresponding pre-defined sub-networks, concatenate the outputs, and pass them to the classifier.\n",
    "\n",
    "torch.nn is already imported for you as nn. Let's do it!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Define image, alphabet and classifier sub-networks as sequential models, assigning them to self.image_layer, self.alphabet_layer and self.classifier, respectively.\n",
    "---\n",
    "\n",
    "    Pass the image and alphabet through the appropriate model layers.\n",
    "---\n",
    "\n",
    "    Concatenate the outputs from image and alphabet layers and assign the result to x.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define sub-networks as sequential models\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*32*32, 128)\n",
    "        )\n",
    "        self.alphabet_layer = nn.Sequential(\n",
    "            nn.Linear(30, 8),\n",
    "            nn.ELU(), \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 8, 964), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x_image, x_alphabet):\n",
    "\t\t# Pass the x_image and x_alphabet through appropriate layers\n",
    "        x_image = self.image_layer(x_image)\n",
    "        x_alphabet = self.alphabet_layer(x_alphabet)\n",
    "        # Concatenate x_image and x_alphabet\n",
    "        x = torch.cat((x_image, x_alphabet), dim=1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Fantastic job! With both the dataset and the model defined, let's take a look at the training loop for our two-input model!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 03\n",
    "\n",
    "\"\"\"\n",
    "Two-output Dataset and DataLoader\n",
    "\n",
    "In this and the following exercises, you will build a two-output model to predict both the character and the alphabet it comes from based on the character's image. As always, you will start with getting the data ready.\n",
    "\n",
    "The OmniglotDataset class you have created before is available for you to use along with updated samples. Let's use it to build the Dataset and the DataLoader.\n",
    "\n",
    "The following imports have already been done for you:\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Print the element of samples at index 100 and examine its structure.\n",
    "---\n",
    "\n",
    "    Use your OmniglotDataset to create dataset_train, passing the two image transforms you have used before: parse the image to a tensor and resize it to size (64, 64).\n",
    "---\n",
    "\n",
    "    Create dataloader_train from dataset_train; shuffle the training images and set batch size to 32.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "# Print the sample at index 100\n",
    "print(samples[100])\n",
    "\n",
    "# Create dataset_train\n",
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "      \ttransforms.Resize((64, 64)),\n",
    "    ]),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "# Create dataloader_train\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, shuffle=True, batch_size=32,\n",
    ")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Perfect! Notice how samples now contain, next to the image path, the target labels for the character and the alphabet. In the next exercise, you will examine the architecture of the two-output model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 04\n",
    "\n",
    "\"\"\"\n",
    "Two-output model architecture\n",
    "\n",
    "In this exercise, you will construct a multi-output neural network architecture capable of predicting the character and the alphabet.\n",
    "\n",
    "Recall the general structure: in the .__init__() method, you define layers to be used in the forward pass later. In the forward() method, you will first pass the input image through a couple of layers to obtain its embedding, which in turn is fed into two separate classifier layers, one for each output.\n",
    "\n",
    "torch.nn is already imported under its usual alias, so let's build a model!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Define self.classifier_alpha and self.classifier_char as linear layers with input shapes matching the output of image_layer, and output shapes corresponding to the number of alphabets (30) and the number of characters (964), respectively.\n",
    "---\n",
    "\n",
    "    Pass the image embedding x_image separately through each of the classifiers, assigning the results to output_alpha and output_char, respectively, and return them in this order.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*32*32, 128)\n",
    "        )\n",
    "        # Define the two classifier layers\n",
    "        self.classifier_alpha = nn.Linear(128, 30)\n",
    "        self.classifier_char = nn.Linear(128, 964)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_image = self.image_layer(x)\n",
    "        # Pass x_image through the classifiers and return both results\n",
    "        output_alpha = self.classifier_alpha(x_image)\n",
    "        output_char = self.classifier_char(x_image)\n",
    "        return output_alpha, output_char\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Good job defining the model architecture! It is now ready for training. Let's do that next!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 05\n",
    "\n",
    "\"\"\"\n",
    "Training multi-output models\n",
    "\n",
    "When training models with multiple outputs, it is crucial to ensure that the loss function is defined correctly.\n",
    "\n",
    "In this case, the model produces two outputs: predictions for the alphabet and the character. For each of these, there are corresponding ground truth labels, which will allow you to calculate two separate losses: one incurred from incorrect alphabet classifications, and the other from incorrect character classification. Since in both cases you are dealing with a multi-label classification task, the Cross-Entropy loss can be applied each time.\n",
    "\n",
    "Gradient descent can optimize only one loss function, however. You will thus define the total loss as the sum of alphabet and character losses.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Calculate the alphabet classification loss and assign it to loss_alpha.\n",
    "    Calculate the character classification loss and assign it to loss_char.\n",
    "    Compute the total loss as the sum of the two partial losses and assign it to loss.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for images, labels_alpha, labels_char in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs_alpha, outputs_char = net(images)\n",
    "        # Compute alphabet classification loss\n",
    "        loss_alpha = criterion(outputs_alpha, labels_alpha)\n",
    "        # Compute character classification loss\n",
    "        loss_char = criterion(outputs_char, labels_char)\n",
    "        # Compute total loss\n",
    "        loss = loss_alpha + loss_char\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done! Defining the total loss as the sum of the two task-specific losses is a simple way to obtain the single optimization objective required by gradient descent. There are, however, other ways to combine the partial losses. Let's explore this topic in the final lesson of this course!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 06\n",
    "\n",
    "\"\"\"\n",
    "Multi-output model evaluation\n",
    "\n",
    "In this exercise, you will practice model evaluation for multi-output models. Your task is to write a function called evaluate_model() that takes an alphabet-and-character-predicting model as input, runs the evaluation loop, and prints the model's accuracy in the two tasks.\n",
    "\n",
    "You can assume that the function will have access to dataloader_test. The following imports have already been run for you:\n",
    "\n",
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "Once you have implemented evaluate_model(), you will use it in the following exercise!\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    Define acc_alpha and acc_char as multi-class Accuracy() metrics for the two outputs, alphabets and characters, with the appropriate number of classes each (there are 30 alphabets and 964 characters in the dataset).\n",
    "---\n",
    "\n",
    "    Define the evaluation loop by iterating over test images, labels_alpha, and labels_char.\n",
    "    Inside the for-loop, obtain model results for the test data batch and assign them to outputs_alpha, outputs_char.\n",
    "---\n",
    "\n",
    "    Update the two accuracy metrics with the current batch's data.\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "\n",
    "def evaluate_model(model):\n",
    "    # Define accuracy metrics\n",
    "    acc_alpha = Accuracy(task=\"multiclass\", num_classes=30)\n",
    "    acc_char = Accuracy(task=\"multiclass\", num_classes=964)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels_alpha, labels_char in dataloader_test:\n",
    "            # Obtain model outputs\n",
    "            outputs_alpha, outputs_char = model(images)\n",
    "            _, pred_alpha = torch.max(outputs_alpha, 1)\n",
    "            _, pred_char = torch.max(outputs_char, 1)\n",
    "\t\t\t# Update both accuracy metrics\n",
    "            acc_alpha(pred_alpha, labels_alpha)\n",
    "            acc_char(pred_char, labels_char)\n",
    "    \n",
    "    print(f\"Alphabet: {acc_alpha.compute()}\")\n",
    "    print(f\"Character: {acc_char.compute()}\")\n",
    "\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Great job implementing the evaluating function! Let's use it to evaluate a range of models trained with different loss functions in the next exercise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise 07\n",
    "\n",
    "\"\"\"\n",
    "Loss weighting\n",
    "\n",
    "Three versions of the two-output model for alphabet and character prediction that you built before have been trained: model_a, model_b, and model_c. For all three, the loss was defined as follows:\n",
    "\n",
    "loss_alpha = criterion(outputs_alpha, labels_alpha)\n",
    "loss_char = criterion(outputs_char, labels_char)\n",
    "loss = ((1 - char_weight) * loss_alpha) + (char_weight * loss_char)\n",
    "\n",
    "However, each of the three models was trained with a different char_weight: 0.1, 0.5, or 0.9.\n",
    "\n",
    "Use the function you have defined in the previous, evaluate_model(), to check the accuracy of each model. Which char_weight was used to train which model?\n",
    "\"\"\"\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution\n",
    "models = [model_a, model_b, model_c]\n",
    "\n",
    "for model in models:\n",
    "    evaluate_model(model)\n",
    "\n",
    "\"\"\"Alphabet: 0.2808536887168884\n",
    "Character: 0.1869264841079712\n",
    "Alphabet: 0.35044848918914795\n",
    "Character: 0.01783689111471176\n",
    "Alphabet: 0.30363956093788147\n",
    "Character: 0.23837509751319885\"\"\"\n",
    "#----------------------------------#\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\"\"\"\n",
    "Well done, that was a tricky one! Notice how the model with 90% of its focus on alphabet recognition (char_weight=0.1) does very poorly on the character task. As we increase char_weight to 0.5, the alphabet accuracy drops slightly due to the increased focus on characters, but when it reaches char_weight=0.9, the alphabet accuracy increases slightly with the character accuracy, highlighting the synergy between the tasks.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
